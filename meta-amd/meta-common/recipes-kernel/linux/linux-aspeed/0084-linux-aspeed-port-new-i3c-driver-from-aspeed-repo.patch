From f86c6491dc26e929c3d6344d03bce7e7da1bc241 Mon Sep 17 00:00:00 2001
From: Mahesh Kurapati <mahesh.kurapati@amd.com>
Date: Wed, 13 Mar 2024 06:25:19 -0500
Subject: [PATCH 1/2] linux-aspeed : port new i3c driver from aspeed repo

ported the i3c driver from aspeed linux repo branch aspeed-master-v5.15.

This commit also has the patch to fix the bus_ids for i3c4 and i3c5.
https://github.com/torvalds/linux/commit/7dc2e0a875645a79f5c1c063019397e8e94008f5

Signed-off-by: Mahesh Kurapati <mahesh.kurapati@amd.com>
---
 drivers/clk/clk-ast2600.c                     |   31 +-
 drivers/i3c/Kconfig                           |   67 +
 drivers/i3c/Makefile                          |    6 +
 drivers/i3c/device.c                          |  302 +-
 drivers/i3c/i3c-ast-bridge-ic.c               |  279 ++
 drivers/i3c/i3c-hub.c                         |  699 ++++
 drivers/i3c/i3c-ibi-mqueue.c                  |  246 ++
 drivers/i3c/i3c-mux-imx3102.c                 |  227 ++
 drivers/i3c/i3c-slave-eeprom.c                |  175 +
 drivers/i3c/i3c-slave-mqueue.c                |  206 ++
 drivers/i3c/i3cdev.c                          |  208 +-
 drivers/i3c/internals.h                       |   13 +
 drivers/i3c/master.c                          | 1304 +++++--
 drivers/i3c/master/Kconfig                    |   51 +-
 drivers/i3c/master/Makefile                   |    4 +-
 drivers/i3c/master/aspeed-i3c-global.c        |  117 -
 drivers/i3c/master/ast2600-i3c-global.c       |  141 +
 drivers/i3c/master/ast2600-i3c-master.c       | 3036 +++++++++++++++++
 drivers/i3c/master/dw-i3c-master.c            |  660 +---
 drivers/i3c/master/i3c-master-cdns.c          |    2 +
 drivers/i3c/master/mipi-i3c-hci/Makefile      |    6 +
 drivers/i3c/master/mipi-i3c-hci/cmd.h         |   67 +
 drivers/i3c/master/mipi-i3c-hci/cmd_v1.c      |  378 ++
 drivers/i3c/master/mipi-i3c-hci/cmd_v2.c      |  316 ++
 drivers/i3c/master/mipi-i3c-hci/core.c        |  793 +++++
 drivers/i3c/master/mipi-i3c-hci/dat.h         |   32 +
 drivers/i3c/master/mipi-i3c-hci/dat_v1.c      |  182 +
 drivers/i3c/master/mipi-i3c-hci/dct.h         |   16 +
 drivers/i3c/master/mipi-i3c-hci/dct_v1.c      |   36 +
 drivers/i3c/master/mipi-i3c-hci/dma.c         |  784 +++++
 drivers/i3c/master/mipi-i3c-hci/ext_caps.c    |  308 ++
 drivers/i3c/master/mipi-i3c-hci/ext_caps.h    |   19 +
 drivers/i3c/master/mipi-i3c-hci/hci.h         |  144 +
 drivers/i3c/master/mipi-i3c-hci/ibi.h         |   42 +
 drivers/i3c/master/mipi-i3c-hci/pio.c         | 1041 ++++++
 .../i3c/master/mipi-i3c-hci/xfer_mode_rate.h  |   79 +
 drivers/i3c/master/svc-i3c-master.c           | 1476 ++++++++
 drivers/i3c/mctp/Kconfig                      |   14 +
 drivers/i3c/mctp/Makefile                     |    3 +
 drivers/i3c/mctp/i3c-mctp.c                   |  629 ++++
 drivers/i3c/mctp/i3c-target-mctp.c            |  389 +++
 drivers/misc/amd-apml/apml_sbtsi.c            |    4 +-
 drivers/misc/amd-apml/sbrmi.c                 |    6 +-
 include/linux/i3c/ccc.h                       |   31 +
 include/linux/i3c/device.h                    |   85 +-
 include/linux/i3c/master.h                    |   92 +-
 include/linux/i3c/mctp/i3c-mctp.h             |   50 +
 include/linux/i3c/target.h                    |   23 +
 48 files changed, 13690 insertions(+), 1129 deletions(-)
 create mode 100644 drivers/i3c/i3c-ast-bridge-ic.c
 create mode 100644 drivers/i3c/i3c-hub.c
 create mode 100644 drivers/i3c/i3c-ibi-mqueue.c
 create mode 100644 drivers/i3c/i3c-mux-imx3102.c
 create mode 100644 drivers/i3c/i3c-slave-eeprom.c
 create mode 100644 drivers/i3c/i3c-slave-mqueue.c
 delete mode 100644 drivers/i3c/master/aspeed-i3c-global.c
 create mode 100644 drivers/i3c/master/ast2600-i3c-global.c
 create mode 100644 drivers/i3c/master/ast2600-i3c-master.c
 create mode 100644 drivers/i3c/master/mipi-i3c-hci/Makefile
 create mode 100644 drivers/i3c/master/mipi-i3c-hci/cmd.h
 create mode 100644 drivers/i3c/master/mipi-i3c-hci/cmd_v1.c
 create mode 100644 drivers/i3c/master/mipi-i3c-hci/cmd_v2.c
 create mode 100644 drivers/i3c/master/mipi-i3c-hci/core.c
 create mode 100644 drivers/i3c/master/mipi-i3c-hci/dat.h
 create mode 100644 drivers/i3c/master/mipi-i3c-hci/dat_v1.c
 create mode 100644 drivers/i3c/master/mipi-i3c-hci/dct.h
 create mode 100644 drivers/i3c/master/mipi-i3c-hci/dct_v1.c
 create mode 100644 drivers/i3c/master/mipi-i3c-hci/dma.c
 create mode 100644 drivers/i3c/master/mipi-i3c-hci/ext_caps.c
 create mode 100644 drivers/i3c/master/mipi-i3c-hci/ext_caps.h
 create mode 100644 drivers/i3c/master/mipi-i3c-hci/hci.h
 create mode 100644 drivers/i3c/master/mipi-i3c-hci/ibi.h
 create mode 100644 drivers/i3c/master/mipi-i3c-hci/pio.c
 create mode 100644 drivers/i3c/master/mipi-i3c-hci/xfer_mode_rate.h
 create mode 100644 drivers/i3c/master/svc-i3c-master.c
 create mode 100644 drivers/i3c/mctp/Kconfig
 create mode 100644 drivers/i3c/mctp/Makefile
 create mode 100644 drivers/i3c/mctp/i3c-mctp.c
 create mode 100644 drivers/i3c/mctp/i3c-target-mctp.c
 create mode 100644 include/linux/i3c/mctp/i3c-mctp.h
 create mode 100644 include/linux/i3c/target.h

diff --git a/drivers/clk/clk-ast2600.c b/drivers/clk/clk-ast2600.c
index 46819eb7b6cb..b92a0bfce625 100644
--- a/drivers/clk/clk-ast2600.c
+++ b/drivers/clk/clk-ast2600.c
@@ -4,6 +4,7 @@

 #define pr_fmt(fmt) "clk-ast2600: " fmt

+#include <linux/bitfield.h>
 #include <linux/mfd/syscon.h>
 #include <linux/of_address.h>
 #include <linux/of_device.h>
@@ -15,7 +16,7 @@

 #include "clk-aspeed.h"

-#define ASPEED_G6_NUM_CLKS		71
+#define ASPEED_G6_NUM_CLKS		75

 #define ASPEED_G6_SILICON_REV		0x014
 #define CHIP_REVISION_ID			GENMASK(23, 16)
@@ -33,6 +34,17 @@
 #define ASPEED_G6_CLK_SELECTION2	0x304
 #define ASPEED_G6_CLK_SELECTION4	0x310
 #define ASPEED_G6_CLK_SELECTION5	0x314
+#define   I3C_CLK_SELECTION		BIT(31)
+#define     I3C_CLK_SELECT_HCLK		0
+#define     I3C_CLK_SELECT_APLL_DIV	1
+#define   APLL_DIV_SELECTION		GENMASK(30, 28)
+#define     APLL_DIV_2			0b001
+#define     APLL_DIV_3			0b010
+#define     APLL_DIV_4			0b011
+#define     APLL_DIV_5			0b100
+#define     APLL_DIV_6			0b101
+#define     APLL_DIV_7			0b110
+#define     APLL_DIV_8			0b111

 #define ASPEED_HPLL_PARAM		0x200
 #define ASPEED_APLL_PARAM		0x210
@@ -776,15 +788,24 @@ static void __init aspeed_g6_cc(struct regmap *map)

 	//* i3c clock */
 	regmap_read(map, ASPEED_G6_CLK_SELECTION5, &val);
-	if(val & BIT(31)) {
-		val = (val >> 28) & 0x7;
+
+	/* i3c core clock 100MHz (APLL 800MHz / 8) */
+	val &= ~(I3C_CLK_SELECTION | APLL_DIV_SELECTION);
+	val |= FIELD_PREP(I3C_CLK_SELECTION, I3C_CLK_SELECT_APLL_DIV);
+	val |= FIELD_PREP(APLL_DIV_SELECTION, APLL_DIV_8);
+	regmap_write(map, ASPEED_G6_CLK_SELECTION5, val);
+
+	if (FIELD_GET(I3C_CLK_SELECTION, val) == I3C_CLK_SELECT_APLL_DIV) {
+		val = FIELD_GET(APLL_DIV_SELECTION, val);
 		if(val)
 			div = val + 1;
 		else
 			div = val + 2;
-		hw = clk_hw_register_fixed_factor(NULL, "i3cclk", "apll", 0, 1, div);
+		hw = clk_hw_register_fixed_factor(NULL, "i3cclk", "apll", 0, 1,
+							div);
 	} else {
-		hw = clk_hw_register_fixed_factor(NULL, "i3cclk", "ahb", 0, 1, 1);
+		hw = clk_hw_register_fixed_factor(NULL, "i3cclk", "ahb", 0, 1,
+							1);
 	}
 	aspeed_g6_clk_data->hws[ASPEED_CLK_I3C] = hw;

diff --git a/drivers/i3c/Kconfig b/drivers/i3c/Kconfig
index 01642768ab5f..6623c1109275 100644
--- a/drivers/i3c/Kconfig
+++ b/drivers/i3c/Kconfig
@@ -21,9 +21,13 @@ menuconfig I3C

 if I3C

+source "drivers/i3c/mctp/Kconfig"
 config I3CDEV
 	tristate "I3C device interface"
 	depends on I3C
+    depends on MACH_ASPEED_G6
+    select AST2600_I3C_MASTER
+    select CRC8
 	help
 	  Say Y here to use i3c-* device files, usually found in the /dev
 	  directory on your system.  They make it possible to have user-space
@@ -35,5 +39,68 @@ config I3CDEV
 	  Note that this application programming interface is EXPERIMENTAL
 	  and hence SUBJECT TO CHANGE WITHOUT NOTICE while it stabilizes.

+config I3C_HUB
+	tristate "I3C HUB support"
+	depends on I3C
+	select REGMAP_I3C
+	help
+	  This enables support for I3C HUB. Say Y here to use I3C HUB driver to
+	  configure I3C HUB device.
+
+	  I3C HUB drivers will be loaded automatically when I3C device with BCR
+	  equals to 0xC2 (HUB device) is detected on the bus.
+
+
+if I3CDEV
+config I3CDEV_FORCE_CREATE
+	bool "force create I3C device interface"
+	default y
+	help
+	  Say 'y' to force create I3C devices under /dev/bus/i3c/ regardless of
+	  driver binding.  This option is to help development so it shall be
+	  turned off in production.
+
+config I3CDEV_XFER_HDR_DDR
+	bool "transfer with HDR-DDR mode"
+	default y
+	help
+	  Say 'y' to use the HDR-DDR mode to transfer data if the device support it.
+	  This option is to help development so it shall be turned off in production.
+endif # I3CDEV
+
+config I3C_AST_BRIDGE_IC
+	bool "Aspeed Bridge IC driver"
+	default y
+	help
+	  Say y to enable Aspeed bridge IC device driver.
+
+config I3C_MUX_IMX3102
+	bool "IMX/IML3102 I3C multiplexer driver"
+	default y
+	select REGMAP_I3C
+	help
+	  Say y to enable Renesas IMX3102 I3C 2:1 multiplexer.
+
+choice
+	prompt "I3C secondary master / slave mode driver selection"
+	default I3C_SLAVE_MQUEUE
+
+config I3C_SLAVE_MQUEUE
+	bool "I3C mqueue (message queue) secondary master and slave driver"
+	help
+	  Some protocols over I3C are designed for bi-directional transferring
+	  messages by using I3C Master Write protocol. This driver is used to
+	  receive and queue messages from the remote I3C main master device.
+
+	  Userspace can get the messages by reading sysfs file that this driver
+	  exposes.
+
+config I3C_SLAVE_EEPROM
+	bool "I3C EEPROM secondary master and slave driver"
+	help
+	  This driver makes the slave mode I3C controller simulate the EEPROM.
+endchoice
+
 source "drivers/i3c/master/Kconfig"
+
 endif # I3C
diff --git a/drivers/i3c/Makefile b/drivers/i3c/Makefile
index 606d422841b2..3b6cb6063b69 100644
--- a/drivers/i3c/Makefile
+++ b/drivers/i3c/Makefile
@@ -3,3 +3,9 @@ i3c-y				:= device.o master.o
 obj-$(CONFIG_I3C)		+= i3c.o
 obj-$(CONFIG_I3CDEV)		+= i3cdev.o
 obj-$(CONFIG_I3C)		+= master/
+obj-$(CONFIG_I3C_AST_BRIDGE_IC) += i3c-ast-bridge-ic.o
+obj-$(CONFIG_I3C_SLAVE_MQUEUE) 	+= i3c-slave-mqueue.o
+obj-$(CONFIG_I3C_SLAVE_EEPROM) 	+= i3c-slave-eeprom.o
+obj-$(CONFIG_I3C_MUX_IMX3102) 	+= i3c-mux-imx3102.o
+obj-$(CONFIG_I3C)		+= mctp/
+obj-$(CONFIG_I3C_HUB)		+= i3c-hub.o
diff --git a/drivers/i3c/device.c b/drivers/i3c/device.c
index 3c0e8872cd09..26f2d745fc38 100644
--- a/drivers/i3c/device.c
+++ b/drivers/i3c/device.c
@@ -38,10 +38,8 @@ int i3c_device_do_priv_xfers(struct i3c_device *dev,
 		return 0;

 	for (i = 0; i < nxfers; i++) {
-		if (!xfers[i].len || !xfers[i].data.in){
-		    pr_err( "i3c_device_do_priv_xfers:Error " " i=%d, Num xfer=%d, len=%d\n", i, nxfers, xfers[i].len );
-		    return -EINVAL;
-		}
+		if (!xfers[i].len || !xfers[i].data.in)
+			return -EINVAL;
 	}

 	i3c_bus_normaluse_lock(dev->bus);
@@ -52,6 +50,73 @@ int i3c_device_do_priv_xfers(struct i3c_device *dev,
 }
 EXPORT_SYMBOL_GPL(i3c_device_do_priv_xfers);

+/**
+ * i3c_device_send_hdr_cmds() - send HDR commands to a specific device
+ *
+ * @dev: device to which these commands should be sent
+ * @cmds: array of commands
+ * @ncmds: number of commands
+ *
+ * Send one or several HDR commands to @dev.
+ *
+ * This function can sleep and thus cannot be called in atomic context.
+ *
+ * Return: 0 in case of success, a negative error core otherwise.
+ */
+int i3c_device_send_hdr_cmds(struct i3c_device *dev, struct i3c_hdr_cmd *cmds,
+			     int ncmds)
+{
+	struct i3c_master_controller *master;
+	enum i3c_hdr_mode mode;
+	int ret, i;
+
+	if (ncmds < 1)
+		return 0;
+
+	mode = cmds[0].mode;
+	for (i = 1; i < ncmds; i++) {
+		if (mode != cmds[i].mode)
+			return -EINVAL;
+	}
+
+	master = i3c_dev_get_master(dev->desc);
+	if (!master)
+		return -EINVAL;
+
+	i3c_bus_normaluse_lock(&master->bus);
+	for (i = 0; i < ncmds; i++)
+		cmds[i].addr = dev->desc->info.dyn_addr;
+
+	ret = i3c_master_send_hdr_cmds_locked(master, cmds, ncmds);
+	i3c_bus_normaluse_unlock(&master->bus);
+
+	return ret;
+}
+EXPORT_SYMBOL_GPL(i3c_device_send_hdr_cmds);
+
+/**
+ * i3c_device_generate_ibi() - request In-Band Interrupt
+ *
+ * @dev: target device
+ * @data: IBI payload
+ * @len: payload length in bytes
+ *
+ * Request In-Band Interrupt with or without data payload.
+ *
+ * Return: 0 in case of success, a negative error code otherwise.
+ */
+int i3c_device_generate_ibi(struct i3c_device *dev, const u8 *data, int len)
+{
+	int ret;
+
+	i3c_bus_normaluse_lock(dev->bus);
+	ret = i3c_dev_generate_ibi_locked(dev->desc, data, len);
+	i3c_bus_normaluse_unlock(dev->bus);
+
+	return ret;
+}
+EXPORT_SYMBOL_GPL(i3c_device_generate_ibi);
+
 /**
  * i3c_device_get_info() - get I3C device information
  *
@@ -178,6 +243,33 @@ void i3c_device_free_ibi(struct i3c_device *dev)
 }
 EXPORT_SYMBOL_GPL(i3c_device_free_ibi);

+/**
+ * i3c_device_send_ccc_cmd() - send ccc to the target device
+ * @dev: device on which you want to release IBI resources
+ * @ccc_id: CCC ID you want to send.  Only support SETAASA, RSTDAA for now.
+ *
+ * This function provides a interface to send CCC from high layer driver.
+ * This is needed for the bus topologic with I3C MUX or switch devices.
+ * The I3C MUX may not enable the local/slave port by default.  The master
+ * controller needs to attach the I3C MUX device, and program the mode
+ * registers to enable the local/slave port.  Then the devices hehind
+ * the MUX may need for CCC for initialization (e.g. SETAASA to bring them
+ * from I2C mode to I3C mode)
+ */
+int i3c_device_send_ccc_cmd(struct i3c_device *dev, u8 ccc_id)
+{
+	int ret;
+
+	if (dev->desc) {
+		i3c_bus_normaluse_lock(dev->bus);
+		ret = i3c_dev_send_ccc_cmd_locked(dev->desc, ccc_id);
+		i3c_bus_normaluse_unlock(dev->bus);
+	}
+
+	return ret;
+}
+EXPORT_SYMBOL_GPL(i3c_device_send_ccc_cmd);
+
 /**
  * i3cdev_to_dev() - Returns the device embedded in @i3cdev
  * @i3cdev: I3C device
@@ -215,40 +307,34 @@ i3c_device_match_id(struct i3c_device *i3cdev,
 {
 	struct i3c_device_info devinfo;
 	const struct i3c_device_id *id;
+	u16 manuf, part, ext_info;
+	bool rndpid;

 	i3c_device_get_info(i3cdev, &devinfo);

-	/*
-	 * The lower 32bits of the provisional ID is just filled with a random
-	 * value, try to match using DCR info.
-	 */
-	if (!I3C_PID_RND_LOWER_32BITS(devinfo.pid)) {
-		u16 manuf = I3C_PID_MANUF_ID(devinfo.pid);
-		u16 part = I3C_PID_PART_ID(devinfo.pid);
-		u16 ext_info = I3C_PID_EXTRA_INFO(devinfo.pid);
-
-		/* First try to match by manufacturer/part ID. */
-		for (id = id_table; id->match_flags != 0; id++) {
-			if ((id->match_flags & I3C_MATCH_MANUF_AND_PART) !=
-			    I3C_MATCH_MANUF_AND_PART)
-				continue;
-
-			if (manuf != id->manuf_id || part != id->part_id)
-				continue;
-
-			if ((id->match_flags & I3C_MATCH_EXTRA_INFO) &&
-			    ext_info != id->extra_info)
-				continue;
-
-			return id;
-		}
-	}
+	manuf = I3C_PID_MANUF_ID(devinfo.pid);
+	part = I3C_PID_PART_ID(devinfo.pid);
+	ext_info = I3C_PID_EXTRA_INFO(devinfo.pid);
+	rndpid = I3C_PID_RND_LOWER_32BITS(devinfo.pid);

-	/* Fallback to DCR match. */
 	for (id = id_table; id->match_flags != 0; id++) {
 		if ((id->match_flags & I3C_MATCH_DCR) &&
-		    id->dcr == devinfo.dcr)
-			return id;
+		    id->dcr != devinfo.dcr)
+			continue;
+
+		if ((id->match_flags & I3C_MATCH_MANUF) &&
+		    id->manuf_id != manuf)
+			continue;
+
+		if ((id->match_flags & I3C_MATCH_PART) &&
+		    (rndpid || id->part_id != part))
+			continue;
+
+		if ((id->match_flags & I3C_MATCH_EXTRA_INFO) &&
+		    (rndpid || id->extra_info != ext_info))
+			continue;
+
+		return id;
 	}

 	return NULL;
@@ -270,6 +356,11 @@ int i3c_driver_register_with_owner(struct i3c_driver *drv, struct module *owner)
 	drv->driver.owner = owner;
 	drv->driver.bus = &i3c_bus_type;

+	if (!drv->probe) {
+		pr_err("Trying to register an i3c driver without probe callback\n");
+		return -EINVAL;
+	}
+
 	return driver_register(&drv->driver);
 }
 EXPORT_SYMBOL_GPL(i3c_driver_register_with_owner);
@@ -286,3 +377,150 @@ void i3c_driver_unregister(struct i3c_driver *drv)
 	driver_unregister(&drv->driver);
 }
 EXPORT_SYMBOL_GPL(i3c_driver_unregister);
+
+/**
+ * i3c_device_getstatus_ccc() - receive device status
+ *
+ * @dev: I3C device to get the status for
+ * @info: I3C device info to fill the status in
+ *
+ * Receive I3C device status from I3C master device via corresponding CCC
+ * command
+ *
+ * Return: 0 in case of success, a negative error code otherwise.
+ */
+int i3c_device_getstatus_ccc(struct i3c_device *dev, struct i3c_device_info *info)
+{
+	int ret = -EINVAL;
+
+	i3c_bus_normaluse_lock(dev->bus);
+	if (dev->desc)
+		ret = i3c_dev_getstatus_locked(dev->desc, &dev->desc->info);
+	i3c_bus_normaluse_unlock(dev->bus);
+	i3c_device_get_info(dev, info);
+
+	return ret;
+}
+EXPORT_SYMBOL_GPL(i3c_device_getstatus_ccc);
+
+/**
+ * i3c_device_control_pec() - enable or disable PEC support in HW
+ *
+ * @dev: I3C device to get the status for
+ * @pec: flag telling whether PEC support shall be enabled or disabled
+ *
+ * Try to enable or disable HW support for PEC (Packet Error Check).
+ * In case no HW support for PEC, software implementation could be used.
+ *
+ * Return: 0 in case of success, -EOPNOTSUPP in case PEC is not supported by HW,
+ *         other negative error codes when PEC enabling failed.
+ */
+int i3c_device_control_pec(struct i3c_device *dev, bool pec)
+{
+	return i3c_dev_control_pec(dev->desc, pec);
+}
+EXPORT_SYMBOL_GPL(i3c_device_control_pec);
+
+/**
+ * i3c_device_setmrl_ccc() - set maximum read length
+ *
+ * @dev: I3C device to set the length for
+ * @info: I3C device info to fill the length in
+ * @read_len: maximum read length value to be set
+ * @ibi_len: maximum ibi payload length to be set
+ *
+ * Set I3C device maximum read length from I3C master device via corresponding CCC command
+ *
+ * Return: 0 in case of success, a negative error code otherwise.
+ */
+int i3c_device_setmrl_ccc(struct i3c_device *dev, struct i3c_device_info *info, u16 read_len,
+			  u8 ibi_len)
+{
+	struct i3c_master_controller *master = i3c_dev_get_master(dev->desc);
+	int ret = -EINVAL;
+
+	i3c_bus_normaluse_lock(dev->bus);
+	if (master)
+		ret = i3c_master_setmrl_locked(master, &dev->desc->info, read_len, ibi_len);
+	i3c_bus_normaluse_unlock(dev->bus);
+	i3c_device_get_info(dev, info);
+
+	return ret;
+}
+EXPORT_SYMBOL_GPL(i3c_device_setmrl_ccc);
+
+/**
+ * i3c_device_setmwl_ccc() - set maximum write length
+ *
+ * @dev: I3C device to set the length for
+ * @info: I3C device info to fill the length in
+ * @write_len: maximum write length value to be set
+ *
+ * Set I3C device maximum write length from I3C master device via corresponding CCC command
+ *
+ * Return: 0 in case of success, a negative error code otherwise.
+ */
+int i3c_device_setmwl_ccc(struct i3c_device *dev, struct i3c_device_info *info, u16 write_len)
+{
+	struct i3c_master_controller *master = i3c_dev_get_master(dev->desc);
+	int ret = -EINVAL;
+
+	i3c_bus_normaluse_lock(dev->bus);
+	if (master)
+		ret = i3c_master_setmwl_locked(master, &dev->desc->info, write_len);
+	i3c_bus_normaluse_unlock(dev->bus);
+	i3c_device_get_info(dev, info);
+
+	return ret;
+}
+EXPORT_SYMBOL_GPL(i3c_device_setmwl_ccc);
+
+/**
+ * i3c_device_getmrl_ccc() - get maximum read length
+ *
+ * @dev: I3C device to get the length for
+ * @info: I3C device info to fill the length in
+ *
+ * Receive I3C device maximum read length from I3C master device via corresponding CCC command
+ *
+ * Return: 0 in case of success, a negative error code otherwise.
+ */
+int i3c_device_getmrl_ccc(struct i3c_device *dev, struct i3c_device_info *info)
+{
+	struct i3c_master_controller *master = i3c_dev_get_master(dev->desc);
+	int ret = -EINVAL;
+
+	i3c_bus_normaluse_lock(dev->bus);
+	if (master)
+		ret = i3c_master_getmrl_locked(master, &dev->desc->info);
+	i3c_bus_normaluse_unlock(dev->bus);
+	i3c_device_get_info(dev, info);
+
+	return ret;
+}
+EXPORT_SYMBOL_GPL(i3c_device_getmrl_ccc);
+
+/**
+ * i3c_device_getmwl_ccc() - get maximum write length
+ *
+ * @dev: I3C device to get the length for
+ * @info: I3C device info to fill the length in
+ *
+ * Receive I3C device maximum write length from I3C master device via corresponding CCC command
+ *
+ * Return: 0 in case of success, a negative error code otherwise.
+ */
+int i3c_device_getmwl_ccc(struct i3c_device *dev, struct i3c_device_info *info)
+{
+	struct i3c_master_controller *master = i3c_dev_get_master(dev->desc);
+	int ret = -EINVAL;
+
+	i3c_bus_normaluse_lock(dev->bus);
+	if (master)
+		ret = i3c_master_getmwl_locked(master, &dev->desc->info);
+	i3c_bus_normaluse_unlock(dev->bus);
+	i3c_device_get_info(dev, info);
+
+	return ret;
+}
+EXPORT_SYMBOL_GPL(i3c_device_getmwl_ccc);
diff --git a/drivers/i3c/i3c-ast-bridge-ic.c b/drivers/i3c/i3c-ast-bridge-ic.c
new file mode 100644
index 000000000000..cd2a8225ef3f
--- /dev/null
+++ b/drivers/i3c/i3c-ast-bridge-ic.c
@@ -0,0 +1,279 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Copyright (c) 2021 Aspeed Technology Inc.
+ *
+ * Aspeed Bridge IC driver
+ *
+ */
+
+#include <linux/i3c/device.h>
+#include <linux/i3c/master.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/of.h>
+#include <linux/sysfs.h>
+#include "internals.h"
+#include <linux/delay.h>
+#define MQ_MSGBUF_SIZE		256
+#define MQ_QUEUE_SIZE		4
+#define MQ_QUEUE_NEXT(x)	(((x) + 1) & (MQ_QUEUE_SIZE - 1))
+
+#define IBI_QUEUE_STATUS_PEC_ERR	BIT(30)
+#define IBI_STATUS_LAST_FRAG	BIT(24)
+#define PID_MANUF_ID_ASPEED	0x03f6
+#define POLLIING_INTERVAL_MS	2000
+
+struct mq_msg {
+	int len;
+	u8 *buf;
+};
+
+struct astbic {
+	struct bin_attribute bin;
+	struct kernfs_node *kn;
+
+	struct i3c_device *i3cdev;
+
+	spinlock_t lock;
+	int in;
+	int out;
+	struct mutex mq_lock;
+	struct mq_msg *curr;
+	int truncated;
+	struct mq_msg queue[MQ_QUEUE_SIZE];
+};
+
+static u8 mdb_table[] = {
+	0xbf, /* Aspeed BIC */
+	0,
+};
+
+static void i3c_ibi_mqueue_callback(struct i3c_device *dev,
+				    const struct i3c_ibi_payload *payload)
+{
+	struct astbic *mq = dev_get_drvdata(&dev->dev);
+	struct mq_msg *msg;
+	u8 *buf = (u8 *)payload->data;
+	struct i3c_device_info info;
+	u32 status;
+	const u8 *mdb;
+
+	mutex_lock(&mq->mq_lock);
+	i3c_device_get_info(dev, &info);
+	msg = mq->curr;
+
+	/* first DW is IBI status */
+	status = *(u32 *)buf;
+
+	/* then the raw data */
+	buf += sizeof(status);
+	memcpy(&msg->buf[msg->len], buf, payload->len - sizeof(status));
+	msg->len += payload->len - sizeof(status);
+	if (status & IBI_QUEUE_STATUS_PEC_ERR) {
+		for (mdb = mdb_table; *mdb != 0; mdb++)
+			if (buf[0] == *mdb)
+				break;
+		if (!(*mdb)) {
+			dev_err(&dev->dev, "ibi crc/pec error: mdb = %x", buf[0]);
+			mutex_unlock(&mq->mq_lock);
+			return;
+		}
+	}
+	/* if last fragment, notify and update pointers */
+	if (status & IBI_STATUS_LAST_FRAG) {
+		/* check pending-read-notification */
+		if (IS_MDB_PENDING_READ_NOTIFY(msg->buf[0])) {
+			struct i3c_priv_xfer xfers[1] = {
+				{
+					.rnw = true,
+					.len = info.max_read_len,
+					.data.in = msg->buf,
+				},
+			};
+
+			i3c_device_do_priv_xfers(dev, xfers, 1);
+
+			msg->len = xfers[0].len;
+		}
+
+		mq->in = MQ_QUEUE_NEXT(mq->in);
+		mq->curr = &mq->queue[mq->in];
+		mq->curr->len = 0;
+
+		if (mq->out == mq->in)
+			mq->out = MQ_QUEUE_NEXT(mq->out);
+		kernfs_notify(mq->kn);
+	}
+	mutex_unlock(&mq->mq_lock);
+}
+
+static ssize_t i3c_astbic_bin_read(struct file *filp, struct kobject *kobj,
+				   struct bin_attribute *attr, char *buf,
+				   loff_t pos, size_t count)
+{
+	struct astbic *mq;
+	struct mq_msg *msg;
+	unsigned long flags;
+	bool more = false;
+	ssize_t ret = 0;
+
+	mq = dev_get_drvdata(container_of(kobj, struct device, kobj));
+
+	spin_lock_irqsave(&mq->lock, flags);
+	if (mq->out != mq->in) {
+		msg = &mq->queue[mq->out];
+
+		if (msg->len <= count) {
+			ret = msg->len;
+			memcpy(buf, msg->buf, ret);
+		} else {
+			ret = -EOVERFLOW; /* Drop this HUGE one. */
+		}
+
+		mq->out = MQ_QUEUE_NEXT(mq->out);
+		if (mq->out != mq->in)
+			more = true;
+	}
+	spin_unlock_irqrestore(&mq->lock, flags);
+
+	if (more)
+		kernfs_notify(mq->kn);
+
+	return ret;
+}
+
+static ssize_t i3c_astbic_bin_write(struct file *filp, struct kobject *kobj,
+				    struct bin_attribute *attr, char *buf,
+				    loff_t pos, size_t count)
+{
+	struct astbic *astbic;
+	// struct i3c_device *i3c;
+	struct i3c_priv_xfer xfers = {
+		.rnw = false,
+		.len = count,
+	};
+	int ret = -EACCES;
+
+	astbic = dev_get_drvdata(container_of(kobj, struct device, kobj));
+	if (!astbic) {
+		count = -1;
+		goto out;
+	}
+
+	xfers.data.out = buf;
+	ret = i3c_device_do_priv_xfers(astbic->i3cdev, &xfers, 1);
+out:
+	return (!ret) ? count : ret;
+}
+
+static void i3c_ast_bridgeic_remove(struct i3c_device *i3cdev)
+{
+	struct device *dev = &i3cdev->dev;
+	struct astbic *astbic;
+
+	astbic = dev_get_drvdata(dev);
+
+	i3c_device_disable_ibi(i3cdev);
+	i3c_device_free_ibi(i3cdev);
+
+	kernfs_put(astbic->kn);
+	sysfs_remove_bin_file(&dev->kobj, &astbic->bin);
+	devm_kfree(dev, astbic);
+}
+
+static int i3c_ast_bridgeic_probe(struct i3c_device *i3cdev)
+{
+	struct device *dev = &i3cdev->dev;
+	struct astbic *astbic;
+	struct i3c_ibi_setup ibireq = {};
+	int ret, i;
+	struct i3c_device_info info;
+	void *buf;
+
+	if (dev->type == &i3c_masterdev_type)
+		return -ENOTSUPP;
+
+	astbic = devm_kzalloc(dev, sizeof(*astbic), GFP_KERNEL);
+	if (!astbic)
+		return -ENOMEM;
+
+	BUILD_BUG_ON(!is_power_of_2(MQ_QUEUE_SIZE));
+
+	buf = devm_kmalloc_array(dev, MQ_QUEUE_SIZE, MQ_MSGBUF_SIZE,
+				 GFP_KERNEL);
+	if (!buf)
+		return -ENOMEM;
+
+	for (i = 0; i < MQ_QUEUE_SIZE; i++) {
+		astbic->queue[i].buf = (u8 *)buf + i * MQ_MSGBUF_SIZE;
+		astbic->queue[i].len = 0;
+	}
+	spin_lock_init(&astbic->lock);
+	mutex_init(&astbic->mq_lock);
+	astbic->curr = &astbic->queue[0];
+
+	astbic->i3cdev = i3cdev;
+
+	sysfs_bin_attr_init(&astbic->bin);
+	astbic->bin.attr.name = "mqueue";
+	astbic->bin.attr.mode = 0600;
+	astbic->bin.read = i3c_astbic_bin_read;
+	astbic->bin.write = i3c_astbic_bin_write;
+	astbic->bin.size = MQ_MSGBUF_SIZE * MQ_QUEUE_SIZE;
+	ret = sysfs_create_bin_file(&dev->kobj, &astbic->bin);
+
+	astbic->kn = kernfs_find_and_get(dev->kobj.sd, astbic->bin.attr.name);
+	if (!astbic->kn) {
+		sysfs_remove_bin_file(&dev->kobj, &astbic->bin);
+		return -EFAULT;
+	}
+
+	i3c_device_get_info(i3cdev, &info);
+
+	ret = i3c_device_setmrl_ccc(i3cdev, &info, MQ_MSGBUF_SIZE,
+					    min(MQ_MSGBUF_SIZE, __UINT8_MAX__));
+	if (ret) {
+		ret = i3c_device_getmrl_ccc(i3cdev, &info);
+		if (ret)
+			return ret;
+	}
+
+	dev_set_drvdata(dev, astbic);
+
+	ibireq.handler = i3c_ibi_mqueue_callback;
+	ibireq.max_payload_len = MQ_MSGBUF_SIZE;
+	ibireq.num_slots = MQ_QUEUE_SIZE;
+
+	ret = i3c_device_request_ibi(astbic->i3cdev, &ibireq);
+	ret |= i3c_device_enable_ibi(astbic->i3cdev);
+	if (ret) {
+		kernfs_put(astbic->kn);
+		sysfs_remove_bin_file(&dev->kobj, &astbic->bin);
+		return ret;
+	}
+	return 0;
+}
+
+static const struct i3c_device_id i3c_ast_bridgeic_ids[] = {
+	I3C_DEVICE(0x3f6, 0x7341, (void *)0),
+	I3C_DEVICE(0x3f6, 0x8000, (void *)0),
+	I3C_DEVICE(0x3f6, 0x8001, (void *)0),
+	I3C_DEVICE(0x3f6, 0x0503, (void *)0),
+	I3C_DEVICE(0x3f6, 0xA001, (void *)0),
+	{ /* sentinel */ },
+};
+MODULE_DEVICE_TABLE(i3c, i3c_ast_bridgeic_ids);
+
+static struct i3c_driver astbic_driver = {
+	.driver = {
+		.name = "i3c-ast-bridgeic",
+	},
+	.probe = i3c_ast_bridgeic_probe,
+	.remove = i3c_ast_bridgeic_remove,
+	.id_table = i3c_ast_bridgeic_ids,
+};
+module_i3c_driver(astbic_driver);
+
+MODULE_AUTHOR("Andy Chung <Andy_Chung@wiwynn.com>");
+MODULE_DESCRIPTION("I3C Aspeed bridge IC driver");
+MODULE_LICENSE("GPL v2");
diff --git a/drivers/i3c/i3c-hub.c b/drivers/i3c/i3c-hub.c
new file mode 100644
index 000000000000..59576b244531
--- /dev/null
+++ b/drivers/i3c/i3c-hub.c
@@ -0,0 +1,699 @@
+// SPDX-License-Identifier: GPL-2.0
+/* Copyright (C) 2021 Intel Corporation.*/
+
+#include <linux/bitfield.h>
+#include <linux/debugfs.h>
+#include <linux/module.h>
+#include <linux/property.h>
+#include <linux/regmap.h>
+
+#include <linux/i3c/device.h>
+#include <linux/i3c/master.h>
+
+#define I3C_HUB_TP_MAX_COUNT				0x08
+
+/* I3C HUB REGISTERS */
+
+/*
+ * In this driver Controller - Target convention is used. All the abbreviations are
+ * based on this convention. For instance: CP - Controller Port, TP - Target Port.
+ */
+
+/* Device Information Registers */
+#define I3C_HUB_DEV_INFO_0				0x00
+#define I3C_HUB_DEV_INFO_1				0x01
+#define I3C_HUB_PID_5					0x02
+#define I3C_HUB_PID_4					0x03
+#define I3C_HUB_PID_3					0x04
+#define I3C_HUB_PID_2					0x05
+#define I3C_HUB_PID_1					0x06
+#define I3C_HUB_PID_0					0x07
+#define I3C_HUB_BCR					0x08
+#define I3C_HUB_DCR					0x09
+#define I3C_HUB_DEV_CAPAB				0x0A
+#define I3C_HUB_DEV_REV					0x0B
+
+/* Device Configuration Registers */
+#define I3C_HUB_PROTECTION_CODE				0x10
+#define  REGISTERS_LOCK_CODE				0x00
+#define  REGISTERS_UNLOCK_CODE				0x69
+#define  CP1_REGISTERS_UNLOCK_CODE			0x6A
+
+#define I3C_HUB_CP_CONF					0x11
+#define I3C_HUB_TP_ENABLE				0x12
+#define  TPn_ENABLE(n)					BIT(n)
+
+#define I3C_HUB_DEV_CONF				0x13
+#define I3C_HUB_IO_STRENGTH				0x14
+#define I3C_HUB_NET_OPER_MODE_CONF			0x15
+#define I3C_HUB_LDO_CONF				0x16
+#define  CP0_LDO_VOLTAGE_MASK				GENMASK(1, 0)
+#define  CP0_LDO_VOLTAGE(x)				(((x) << 0) & CP0_LDO_VOLTAGE_MASK)
+#define  CP1_LDO_VOLTAGE_MASK				GENMASK(3, 2)
+#define  CP1_LDO_VOLTAGE(x)				(((x) << 2) & CP1_LDO_VOLTAGE_MASK)
+#define  TP0145_LDO_VOLTAGE_MASK			GENMASK(5, 4)
+#define  TP0145_LDO_VOLTAGE(x)				(((x) << 4) & TP0145_LDO_VOLTAGE_MASK)
+#define  TP2367_LDO_VOLTAGE_MASK			GENMASK(7, 6)
+#define  TP2367_LDO_VOLTAGE(x)				(((x) << 6) & TP2367_LDO_VOLTAGE_MASK)
+#define  LDO_VOLTAGE_1_0V				0x00
+#define  LDO_VOLTAGE_1_1V				0x01
+#define  LDO_VOLTAGE_1_2V				0x02
+#define  LDO_VOLTAGE_1_8V				0x03
+
+#define I3C_HUB_TP_IO_MODE_CONF				0x17
+#define I3C_HUB_TP_SMBUS_AGNT_EN			0x18
+#define  TPn_SMBUS_MODE_EN(n)				BIT(n)
+
+#define I3C_HUB_LDO_AND_PULLUP_CONF			0x19
+#define  CP0_LDO_EN					BIT(0)
+#define  CP1_LDO_EN					BIT(1)
+/*
+ * I3C HUB does not provide a way to control LDO or pull-up for individual ports. It is possible
+ * for group of ports TP0/TP1/TP4/TP5 and TP2/TP3/TP6/TP7.
+ */
+#define  TP0145_LDO_EN					BIT(2)
+#define  TP2367_LDO_EN					BIT(3)
+#define  TP0145_PULLUP_CONF_MASK			GENMASK(7, 6)
+#define  TP0145_PULLUP_CONF(x)				(((x) << 6) & TP0145_PULLUP_CONF_MASK)
+#define  TP2367_PULLUP_CONF_MASK			GENMASK(5, 4)
+#define  TP2367_PULLUP_CONF(x)				(((x) << 4) & TP2367_PULLUP_CONF_MASK)
+#define  PULLUP_250R					0x00
+#define  PULLUP_500R					0x01
+#define  PULLUP_1K					0x02
+#define  PULLUP_2K					0x03
+
+#define I3C_HUB_CP_IBI_CONF				0x1A
+#define I3C_HUB_TP_IBI_CONF				0x1B
+#define I3C_HUB_IBI_MDB_CUSTOM				0x1C
+#define I3C_HUB_JEDEC_CONTEXT_ID			0x1D
+#define I3C_HUB_TP_GPIO_MODE_EN				0x1E
+#define  TPn_GPIO_MODE_EN(n)				BIT(n)
+
+/* Device Status and IBI Registers */
+#define I3C_HUB_DEV_AND_IBI_STS				0x20
+#define I3C_HUB_TP_SMBUS_AGNT_IBI_STS			0x21
+
+/* Controller Port Control/Status Registers */
+#define I3C_HUB_CP_MUX_SET				0x38
+#define I3C_HUB_CP_MUX_STS				0x39
+
+/* Target Ports Control Registers */
+#define I3C_HUB_TP_SMBUS_AGNT_TRANS_START		0x50
+#define I3C_HUB_TP_NET_CON_CONF				0x51
+#define  TPn_NET_CON(n)					BIT(n)
+
+#define I3C_HUB_TP_PULLUP_EN				0x53
+#define  TPn_PULLUP_EN(n)				BIT(n)
+
+#define I3C_HUB_TP_SCL_OUT_EN				0x54
+#define I3C_HUB_TP_SDA_OUT_EN				0x55
+#define I3C_HUB_TP_SCL_OUT_LEVEL			0x56
+#define I3C_HUB_TP_SDA_OUT_LEVEL			0x57
+#define I3C_HUB_TP_IN_DETECT_MODE_CONF			0x58
+#define I3C_HUB_TP_SCL_IN_DETECT_IBI_EN			0x59
+#define I3C_HUB_TP_SDA_IN_DETECT_IBI_EN			0x5A
+
+/* Target Ports Status Registers */
+#define I3C_HUB_TP_SCL_IN_LEVEL_STS			0x60
+#define I3C_HUB_TP_SDA_IN_LEVEL_STS			0x61
+#define I3C_HUB_TP_SCL_IN_DETECT_FLG			0x62
+#define I3C_HUB_TP_SDA_IN_DETECT_FLG			0x63
+
+/* SMBus Agent Configuration and Status Registers */
+#define I3C_HUB_TP0_SMBUS_AGNT_STS			0x64
+#define I3C_HUB_TP1_SMBUS_AGNT_STS			0x65
+#define I3C_HUB_TP2_SMBUS_AGNT_STS			0x66
+#define I3C_HUB_TP3_SMBUS_AGNT_STS			0x67
+#define I3C_HUB_TP4_SMBUS_AGNT_STS			0x68
+#define I3C_HUB_TP5_SMBUS_AGNT_STS			0x69
+#define I3C_HUB_TP6_SMBUS_AGNT_STS			0x6A
+#define I3C_HUB_TP7_SMBUS_AGNT_STS			0x6B
+#define I3C_HUB_ONCHIP_TD_AND_SMBUS_AGNT_CONF		0x6C
+
+/* Special Function Registers */
+#define I3C_HUB_LDO_AND_CPSEL_STS			0x79
+#define I3C_HUB_BUS_RESET_SCL_TIMEOUT			0x7A
+#define I3C_HUB_ONCHIP_TD_PROTO_ERR_FLG			0x7B
+#define I3C_HUB_DEV_CMD					0x7C
+#define I3C_HUB_ONCHIP_TD_STS				0x7D
+#define I3C_HUB_ONCHIP_TD_ADDR_CONF			0x7E
+#define I3C_HUB_PAGE_PTR				0x7F
+
+/* LDO DT settings */
+#define I3C_HUB_DT_LDO_DISABLED				0x00
+#define I3C_HUB_DT_LDO_1_0V				0x01
+#define I3C_HUB_DT_LDO_1_1V				0x02
+#define I3C_HUB_DT_LDO_1_2V				0x03
+#define I3C_HUB_DT_LDO_1_8V				0x04
+#define I3C_HUB_DT_LDO_NOT_DEFINED			0xFF
+
+/* Pull-up DT settings */
+#define I3C_HUB_DT_PULLUP_DISABLED			0x00
+#define I3C_HUB_DT_PULLUP_250R				0x01
+#define I3C_HUB_DT_PULLUP_500R				0x02
+#define I3C_HUB_DT_PULLUP_1K				0x03
+#define I3C_HUB_DT_PULLUP_2K				0x04
+#define I3C_HUB_DT_PULLUP_NOT_DEFINED			0xFF
+
+/* TP DT setting */
+#define I3C_HUB_DT_TP_MODE_DISABLED			0x00
+#define I3C_HUB_DT_TP_MODE_I3C				0x01
+#define I3C_HUB_DT_TP_MODE_I3C_PERF			0x02
+#define I3C_HUB_DT_TP_MODE_SMBUS			0x03
+#define I3C_HUB_DT_TP_MODE_GPIO				0x04
+#define I3C_HUB_DT_TP_MODE_NOT_DEFINED			0xFF
+
+/* TP pull-up status */
+#define I3C_HUB_DT_TP_PULLUP_DISABLED			0x00
+#define I3C_HUB_DT_TP_PULLUP_ENABLED			0x01
+#define I3C_HUB_DT_TP_PULLUP_NOT_DEFINED		0xFF
+
+struct tp_setting {
+	u8 mode;
+	u8 pullup_en;
+};
+
+struct dt_settings {
+	u8 cp0_ldo;
+	u8 cp1_ldo;
+	u8 tp0145_ldo;
+	u8 tp2367_ldo;
+	u8 tp0145_pullup;
+	u8 tp2367_pullup;
+	struct tp_setting tp[I3C_HUB_TP_MAX_COUNT];
+};
+
+struct i3c_hub {
+	struct i3c_device *i3cdev;
+	struct regmap *regmap;
+	struct dt_settings settings;
+
+	/* Offset for reading HUB's register. */
+	u8 reg_addr;
+	struct dentry *debug_dir;
+};
+
+struct hub_setting {
+	const char * const name;
+	const u8 value;
+};
+
+static const struct hub_setting ldo_settings[] = {
+	{"disabled",	I3C_HUB_DT_LDO_DISABLED},
+	{"1.0V",	I3C_HUB_DT_LDO_1_0V},
+	{"1.1V",	I3C_HUB_DT_LDO_1_1V},
+	{"1.2V",	I3C_HUB_DT_LDO_1_2V},
+	{"1.8V",	I3C_HUB_DT_LDO_1_8V},
+};
+
+static const struct hub_setting pullup_settings[] = {
+	{"disabled",	I3C_HUB_DT_PULLUP_DISABLED},
+	{"250R",	I3C_HUB_DT_PULLUP_250R},
+	{"500R",	I3C_HUB_DT_PULLUP_500R},
+	{"1k",		I3C_HUB_DT_PULLUP_1K},
+	{"2k",		I3C_HUB_DT_PULLUP_2K},
+};
+
+static const struct hub_setting tp_mode_settings[] = {
+	{"disabled",	I3C_HUB_DT_TP_MODE_DISABLED},
+	{"i3c",		I3C_HUB_DT_TP_MODE_I3C},
+	{"i3c-perf",	I3C_HUB_DT_TP_MODE_I3C_PERF},
+	{"smbus",	I3C_HUB_DT_TP_MODE_SMBUS},
+	{"gpio",	I3C_HUB_DT_TP_MODE_GPIO},
+};
+
+static const struct hub_setting tp_pullup_settings[] = {
+	{"disabled",	I3C_HUB_DT_TP_PULLUP_DISABLED},
+	{"enabled",	I3C_HUB_DT_TP_PULLUP_ENABLED},
+};
+
+static u8 i3c_hub_ldo_dt_to_reg(u8 dt_value)
+{
+	switch (dt_value) {
+	case I3C_HUB_DT_LDO_1_1V:
+		return LDO_VOLTAGE_1_1V;
+	case I3C_HUB_DT_LDO_1_2V:
+		return LDO_VOLTAGE_1_2V;
+	case I3C_HUB_DT_LDO_1_8V:
+		return LDO_VOLTAGE_1_8V;
+	default:
+		return LDO_VOLTAGE_1_0V;
+	}
+}
+
+static u8 i3c_hub_pullup_dt_to_reg(u8 dt_value)
+{
+	switch (dt_value) {
+	case I3C_HUB_DT_PULLUP_250R:
+		return PULLUP_250R;
+	case I3C_HUB_DT_PULLUP_500R:
+		return PULLUP_500R;
+	case I3C_HUB_DT_PULLUP_1K:
+		return PULLUP_1K;
+	default:
+		return PULLUP_2K;
+	}
+}
+
+static int i3c_hub_of_get_setting(const struct device_node *node, const char *setting_name,
+				  const struct hub_setting settings[], const u8 settings_count,
+				  u8 *setting_value)
+{
+	const char *sval;
+	int ret;
+	int i;
+
+	ret = of_property_read_string(node, setting_name, &sval);
+	if (ret)
+		return ret;
+
+	for (i = 0; i < settings_count; ++i) {
+		const struct hub_setting * const setting = &settings[i];
+
+		if (!strcmp(setting->name, sval)) {
+			*setting_value = setting->value;
+			return 0;
+		}
+	}
+
+	return -EINVAL;
+}
+
+static void i3c_hub_tp_of_get_setting(struct device *dev, const struct device_node *node,
+				      struct tp_setting tp_setting[])
+{
+	struct device_node *tp_node;
+	int id;
+
+	for_each_available_child_of_node(node, tp_node) {
+		int ret;
+
+		if (!tp_node->name || of_node_cmp(tp_node->name, "target-port"))
+			continue;
+
+		if (!tp_node->full_name ||
+		    (sscanf(tp_node->full_name, "target-port@%i", &id) != 1)) {
+			dev_warn(dev, "Invalid target port node found in DT - %s\n",
+				 tp_node->full_name);
+			continue;
+		}
+
+		if (id >= I3C_HUB_TP_MAX_COUNT) {
+			dev_warn(dev, "Invalid target port index found in DT - %i\n", id);
+			continue;
+		}
+		ret = i3c_hub_of_get_setting(tp_node, "mode", tp_mode_settings,
+					     ARRAY_SIZE(tp_mode_settings), &tp_setting[id].mode);
+		if (ret)
+			dev_warn(dev, "Invalid or not specified setting for target port[%i].mode\n",
+				 id);
+
+		ret = i3c_hub_of_get_setting(tp_node, "pullup", tp_pullup_settings,
+					     ARRAY_SIZE(tp_pullup_settings),
+					     &tp_setting[id].pullup_en);
+		if (ret)
+			dev_warn(dev,
+				 "Invalid or not specified setting for target port[%i].pullup\n",
+				 id);
+	}
+}
+
+static void i3c_hub_of_get_configuration(struct device *dev, const struct device_node *node)
+{
+	struct i3c_hub *priv = dev_get_drvdata(dev);
+	int ret;
+
+	ret = i3c_hub_of_get_setting(node, "cp0-ldo", ldo_settings, ARRAY_SIZE(ldo_settings),
+				     &priv->settings.cp0_ldo);
+	if (ret)
+		dev_warn(dev, "Invalid or not specified setting for cp0-ldo\n");
+
+	ret = i3c_hub_of_get_setting(node, "cp1-ldo", ldo_settings, ARRAY_SIZE(ldo_settings),
+				     &priv->settings.cp1_ldo);
+	if (ret)
+		dev_warn(dev, "Invalid or not specified setting for cp1-ldo\n");
+
+	ret = i3c_hub_of_get_setting(node, "tp0145-ldo", ldo_settings, ARRAY_SIZE(ldo_settings),
+				     &priv->settings.tp0145_ldo);
+	if (ret)
+		dev_warn(dev, "Invalid or not specified setting for tp0145-ldo\n");
+
+	ret = i3c_hub_of_get_setting(node, "tp2367-ldo", ldo_settings, ARRAY_SIZE(ldo_settings),
+				     &priv->settings.tp2367_ldo);
+	if (ret)
+		dev_warn(dev, "Invalid or not specified setting for tp2367-ldo\n");
+
+	ret = i3c_hub_of_get_setting(node, "tp0145-pullup", pullup_settings,
+				     ARRAY_SIZE(pullup_settings), &priv->settings.tp0145_pullup);
+	if (ret)
+		dev_warn(dev, "Invalid or not specified setting for tp0145-pullup\n");
+
+	ret = i3c_hub_of_get_setting(node, "tp2367-pullup", pullup_settings,
+				     ARRAY_SIZE(pullup_settings), &priv->settings.tp2367_pullup);
+	if (ret)
+		dev_warn(dev, "Invalid or not specified setting for tp2367-pullup\n");
+
+	i3c_hub_tp_of_get_setting(dev, node, priv->settings.tp);
+}
+
+static void i3c_hub_of_default_configuration(struct device *dev)
+{
+	struct i3c_hub *priv = dev_get_drvdata(dev);
+	int id;
+
+	priv->settings.cp0_ldo = I3C_HUB_DT_LDO_NOT_DEFINED;
+	priv->settings.cp1_ldo = I3C_HUB_DT_LDO_NOT_DEFINED;
+	priv->settings.tp0145_ldo = I3C_HUB_DT_LDO_NOT_DEFINED;
+	priv->settings.tp2367_ldo = I3C_HUB_DT_LDO_NOT_DEFINED;
+	priv->settings.tp0145_pullup = I3C_HUB_DT_PULLUP_NOT_DEFINED;
+	priv->settings.tp2367_pullup = I3C_HUB_DT_PULLUP_NOT_DEFINED;
+
+	for (id = 0; id < I3C_HUB_TP_MAX_COUNT; ++id) {
+		priv->settings.tp[id].mode = I3C_HUB_DT_TP_MODE_NOT_DEFINED;
+		priv->settings.tp[id].pullup_en = I3C_HUB_DT_TP_PULLUP_NOT_DEFINED;
+	}
+}
+
+static int i3c_hub_hw_configure_pullup(struct device *dev)
+{
+	struct i3c_hub *priv = dev_get_drvdata(dev);
+	u8 mask = 0, value = 0;
+
+	if (priv->settings.tp0145_pullup != I3C_HUB_DT_PULLUP_NOT_DEFINED) {
+		mask |= TP0145_PULLUP_CONF_MASK;
+		value |= TP0145_PULLUP_CONF(i3c_hub_pullup_dt_to_reg(priv->settings.tp0145_pullup));
+	}
+
+	if (priv->settings.tp2367_pullup != I3C_HUB_DT_PULLUP_NOT_DEFINED) {
+		mask |= TP2367_PULLUP_CONF_MASK;
+		value |= TP2367_PULLUP_CONF(i3c_hub_pullup_dt_to_reg(priv->settings.tp2367_pullup));
+	}
+
+	return regmap_update_bits(priv->regmap, I3C_HUB_LDO_AND_PULLUP_CONF, mask, value);
+}
+
+static int i3c_hub_hw_configure_ldo(struct device *dev)
+{
+	struct i3c_hub *priv = dev_get_drvdata(dev);
+	u8 mask_all = 0, val_all = 0;
+	u8 ldo_dis = 0, ldo_en = 0;
+	u32 reg_val;
+	u8 val;
+	int ret;
+
+	/* Get LDOs configuration to figure out what is going to be changed */
+	ret = regmap_read(priv->regmap, I3C_HUB_LDO_CONF, &reg_val);
+	if (ret)
+		return ret;
+
+	if (priv->settings.cp0_ldo != I3C_HUB_DT_LDO_NOT_DEFINED) {
+		val = CP0_LDO_VOLTAGE(i3c_hub_ldo_dt_to_reg(priv->settings.cp0_ldo));
+		if ((reg_val & CP0_LDO_VOLTAGE_MASK) != val)
+			ldo_dis |= CP0_LDO_EN;
+		if (priv->settings.cp0_ldo != I3C_HUB_DT_LDO_DISABLED)
+			ldo_en |= CP0_LDO_EN;
+		mask_all |= CP0_LDO_VOLTAGE_MASK;
+		val_all |= val;
+	}
+	if (priv->settings.cp1_ldo != I3C_HUB_DT_LDO_NOT_DEFINED) {
+		val = CP1_LDO_VOLTAGE(i3c_hub_ldo_dt_to_reg(priv->settings.cp1_ldo));
+		if ((reg_val & CP1_LDO_VOLTAGE_MASK) != val)
+			ldo_dis |= CP1_LDO_EN;
+		if (priv->settings.cp1_ldo != I3C_HUB_DT_LDO_DISABLED)
+			ldo_en |= CP1_LDO_EN;
+		mask_all |= CP1_LDO_VOLTAGE_MASK;
+		val_all |= val;
+	}
+	if (priv->settings.tp0145_ldo != I3C_HUB_DT_LDO_NOT_DEFINED) {
+		val = TP0145_LDO_VOLTAGE(i3c_hub_ldo_dt_to_reg(priv->settings.tp0145_ldo));
+		if ((reg_val & TP0145_LDO_VOLTAGE_MASK) != val)
+			ldo_dis |= TP0145_LDO_EN;
+		if (priv->settings.tp0145_ldo != I3C_HUB_DT_LDO_DISABLED)
+			ldo_en |= TP0145_LDO_EN;
+		mask_all |= TP0145_LDO_VOLTAGE_MASK;
+		val_all |= val;
+	}
+	if (priv->settings.tp2367_ldo != I3C_HUB_DT_LDO_NOT_DEFINED) {
+		val = TP2367_LDO_VOLTAGE(i3c_hub_ldo_dt_to_reg(priv->settings.tp2367_ldo));
+		if ((reg_val & TP2367_LDO_VOLTAGE_MASK) != val)
+			ldo_dis |= TP2367_LDO_EN;
+		if (priv->settings.tp2367_ldo != I3C_HUB_DT_LDO_DISABLED)
+			ldo_en |= TP2367_LDO_EN;
+		mask_all |= TP2367_LDO_VOLTAGE_MASK;
+		val_all |= val;
+	}
+
+	/* Disable all LDOs if LDO configuration is going to be changed. */
+	ret = regmap_update_bits(priv->regmap, I3C_HUB_LDO_AND_PULLUP_CONF, ldo_dis, 0);
+	if (ret)
+		return ret;
+
+	/* Set LDOs configuration */
+	ret = regmap_update_bits(priv->regmap, I3C_HUB_LDO_CONF, mask_all, val_all);
+	if (ret)
+		return ret;
+
+	/* Re-enable LDOs if needed */
+	return regmap_update_bits(priv->regmap, I3C_HUB_LDO_AND_PULLUP_CONF, ldo_en, ldo_en);
+}
+
+static int i3c_hub_hw_configure_tp(struct device *dev)
+{
+	struct i3c_hub *priv = dev_get_drvdata(dev);
+	u8 pullup_mask = 0, pullup_val = 0;
+	u8 smbus_mask = 0, smbus_val = 0;
+	u8 gpio_mask = 0, gpio_val = 0;
+	u8 i3c_mask = 0, i3c_val = 0;
+	int ret;
+	int i;
+
+	/* TBD: Read type of HUB from register I3C_HUB_DEV_INFO_0 to learn target ports count. */
+	for (i = 0; i < I3C_HUB_TP_MAX_COUNT; ++i) {
+		if (priv->settings.tp[i].mode != I3C_HUB_DT_TP_MODE_NOT_DEFINED) {
+			i3c_mask |= TPn_NET_CON(i);
+			smbus_mask |= TPn_SMBUS_MODE_EN(i);
+			gpio_mask |= TPn_GPIO_MODE_EN(i);
+
+			if (priv->settings.tp[i].mode == I3C_HUB_DT_TP_MODE_I3C)
+				i3c_val |= TPn_NET_CON(i);
+			else if (priv->settings.tp[i].mode == I3C_HUB_DT_TP_MODE_SMBUS)
+				smbus_val |= TPn_SMBUS_MODE_EN(i);
+			else if (priv->settings.tp[i].mode == I3C_HUB_DT_TP_MODE_GPIO)
+				gpio_val |= TPn_GPIO_MODE_EN(i);
+		}
+		if (priv->settings.tp[i].pullup_en != I3C_HUB_DT_TP_PULLUP_NOT_DEFINED) {
+			pullup_mask |= TPn_PULLUP_EN(i);
+			if (priv->settings.tp[i].pullup_en == I3C_HUB_DT_TP_PULLUP_ENABLED)
+				pullup_val |= TPn_PULLUP_EN(i);
+		}
+	}
+
+	ret = regmap_update_bits(priv->regmap, I3C_HUB_TP_NET_CON_CONF, i3c_mask, i3c_val);
+	if (ret)
+		return ret;
+
+	ret = regmap_update_bits(priv->regmap, I3C_HUB_TP_SMBUS_AGNT_EN, smbus_mask, smbus_val);
+	if (ret)
+		return ret;
+
+	ret = regmap_update_bits(priv->regmap, I3C_HUB_TP_GPIO_MODE_EN, gpio_mask, gpio_val);
+	if (ret)
+		return ret;
+
+	/* Enable TP here in case TP was configured */
+	ret = regmap_update_bits(priv->regmap, I3C_HUB_TP_ENABLE, i3c_mask | smbus_mask | gpio_mask,
+				 i3c_val | smbus_val | gpio_val);
+	if (ret)
+		return ret;
+
+	return regmap_update_bits(priv->regmap, I3C_HUB_TP_PULLUP_EN, pullup_mask, pullup_val);
+}
+
+static int i3c_hub_configure_hw(struct device *dev)
+{
+	int ret;
+
+	ret = i3c_hub_hw_configure_pullup(dev);
+	if (ret)
+		return ret;
+
+	ret = i3c_hub_hw_configure_ldo(dev);
+	if (ret)
+		return ret;
+
+	return i3c_hub_hw_configure_tp(dev);
+}
+
+static const struct i3c_device_id i3c_hub_ids[] = {
+	I3C_CLASS(I3C_DCR_HUB, NULL),
+	{ },
+};
+
+static int fops_access_reg_get(void *ctx, u64 *val)
+{
+	struct i3c_hub *priv = ctx;
+	u32 reg_val;
+	int ret;
+
+	ret = regmap_read(priv->regmap, priv->reg_addr, &reg_val);
+	if (ret)
+		return ret;
+
+	*val = reg_val & 0xFF;
+	return 0;
+}
+
+static int fops_access_reg_set(void *ctx, u64 val)
+{
+	struct i3c_hub *priv = ctx;
+
+	return regmap_write(priv->regmap, priv->reg_addr, val & 0xFF);
+}
+DEFINE_DEBUGFS_ATTRIBUTE(fops_access_reg, fops_access_reg_get, fops_access_reg_set, "0x%llX\n");
+
+static int i3c_hub_debugfs_init(struct i3c_hub *priv, const char *hub_id)
+{
+	struct dentry  *entry, *dt_conf_dir, *reg_dir;
+	int i;
+
+	entry = debugfs_create_dir(hub_id, NULL);
+	if (IS_ERR(entry))
+		return PTR_ERR(entry);
+
+	priv->debug_dir = entry;
+
+	entry = debugfs_create_dir("dt-conf", priv->debug_dir);
+	if (IS_ERR(entry))
+		goto err_remove;
+
+	dt_conf_dir = entry;
+
+	debugfs_create_u8("cp0-ldo", 0400, dt_conf_dir, &priv->settings.cp0_ldo);
+	debugfs_create_u8("cp1-ldo", 0400, dt_conf_dir, &priv->settings.cp1_ldo);
+	debugfs_create_u8("tp0145-ldo", 0400, dt_conf_dir, &priv->settings.tp0145_ldo);
+	debugfs_create_u8("tp2367-ldo", 0400, dt_conf_dir, &priv->settings.tp2367_ldo);
+	debugfs_create_u8("tp0145-pullup", 0400, dt_conf_dir, &priv->settings.tp0145_pullup);
+	debugfs_create_u8("tp2367-pullup", 0400, dt_conf_dir, &priv->settings.tp2367_pullup);
+
+	for (i = 0; i < I3C_HUB_TP_MAX_COUNT; ++i) {
+		char file_name[32];
+
+		sprintf(file_name, "tp%i.mode", i);
+		debugfs_create_u8(file_name, 0400, dt_conf_dir, &priv->settings.tp[i].mode);
+		sprintf(file_name, "tp%i.pullup_en", i);
+		debugfs_create_u8(file_name, 0400, dt_conf_dir, &priv->settings.tp[i].pullup_en);
+	}
+
+	entry = debugfs_create_dir("reg", priv->debug_dir);
+	if (IS_ERR(entry))
+		goto err_remove;
+
+	reg_dir = entry;
+
+	entry = debugfs_create_file_unsafe("access", 0600, reg_dir, priv, &fops_access_reg);
+	if (IS_ERR(entry))
+		goto err_remove;
+
+	debugfs_create_u8("offset", 0600, reg_dir, &priv->reg_addr);
+
+	return 0;
+
+err_remove:
+	debugfs_remove_recursive(priv->debug_dir);
+	return PTR_ERR(entry);
+}
+
+static int i3c_hub_probe(struct i3c_device *i3cdev)
+{
+	struct regmap_config i3c_hub_regmap_config = {
+		.reg_bits = 8,
+		.val_bits = 8,
+	};
+	struct device *dev = &i3cdev->dev;
+	struct device_node *node;
+	struct regmap *regmap;
+	struct i3c_hub *priv;
+	char hub_id[32];
+	int ret;
+
+	priv = devm_kzalloc(dev, sizeof(*priv), GFP_KERNEL);
+	if (!priv)
+		return -ENOMEM;
+
+	priv->i3cdev = i3cdev;
+	i3cdev_set_drvdata(i3cdev, priv);
+
+	sprintf(hub_id, "i3c-hub-%d-%llx", i3cdev->bus->id, i3cdev->desc->info.pid);
+	ret = i3c_hub_debugfs_init(priv, hub_id);
+	if (ret)
+		return dev_err_probe(dev, ret, "Failed to initialized DebugFS.\n");
+
+	i3c_hub_of_default_configuration(dev);
+
+	/* TBD: Support for multiple HUBs. */
+	/* Just get first hub node from DT */
+	node = of_get_child_by_name(dev->parent->of_node, "hub");
+	if (!node) {
+		dev_warn(dev, "Failed to find DT entry for the driver. Running with defaults.\n");
+	} else {
+		i3c_hub_of_get_configuration(dev, node);
+		of_node_put(node);
+	}
+
+	regmap = devm_regmap_init_i3c(i3cdev, &i3c_hub_regmap_config);
+	if (IS_ERR(regmap)) {
+		ret = PTR_ERR(regmap);
+		dev_err(dev, "Failed to register I3C HUB regmap\n");
+		goto error;
+	}
+
+	priv->regmap = regmap;
+
+	/* Unlock access to protected registers */
+	ret = regmap_write(priv->regmap, I3C_HUB_PROTECTION_CODE, REGISTERS_UNLOCK_CODE);
+	if (ret) {
+		dev_err(dev, "Failed to unlock HUB's protected registers\n");
+		goto error;
+	}
+
+	ret = i3c_hub_configure_hw(dev);
+	if (ret) {
+		dev_err(dev, "Failed to configure the HUB\n");
+		goto error;
+	}
+
+	/* Lock access to protected registers */
+	ret = regmap_write(priv->regmap, I3C_HUB_PROTECTION_CODE, REGISTERS_LOCK_CODE);
+	if (ret) {
+		dev_err(dev, "Failed to lock HUB's protected registers\n");
+		goto error;
+	}
+
+	/* TBD: Apply special/security lock here using DEV_CMD register */
+
+	return 0;
+
+error:
+	debugfs_remove_recursive(priv->debug_dir);
+	return ret;
+}
+
+static void i3c_hub_remove(struct i3c_device *i3cdev)
+{
+	struct i3c_hub *priv = i3cdev_get_drvdata(i3cdev);
+
+	debugfs_remove_recursive(priv->debug_dir);
+}
+
+static struct i3c_driver i3c_hub = {
+	.driver.name = "i3c-hub",
+	.id_table = i3c_hub_ids,
+	.probe = i3c_hub_probe,
+	.remove = i3c_hub_remove,
+};
+
+module_i3c_driver(i3c_hub);
+
+MODULE_AUTHOR("Zbigniew Lukwinski <zbigniew.lukwinski@linux.intel.com>");
+MODULE_DESCRIPTION("I3C HUB driver");
+MODULE_LICENSE("GPL");
diff --git a/drivers/i3c/i3c-ibi-mqueue.c b/drivers/i3c/i3c-ibi-mqueue.c
new file mode 100644
index 000000000000..8f1ddb9fa8f8
--- /dev/null
+++ b/drivers/i3c/i3c-ibi-mqueue.c
@@ -0,0 +1,246 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Copyright (c) 2021 Aspeed Technology Inc.
+ */
+
+#include <linux/i3c/device.h>
+#include <linux/i3c/master.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/of.h>
+#include <linux/slab.h>
+#include <linux/spinlock.h>
+#include <linux/sysfs.h>
+#include <linux/delay.h>
+#include "internals.h"
+
+#define MQ_MSGBUF_SIZE		256
+#define MQ_QUEUE_SIZE		4
+#define MQ_QUEUE_NEXT(x)	(((x) + 1) & (MQ_QUEUE_SIZE - 1))
+
+#define IBI_QUEUE_STATUS_PEC_ERR	BIT(30)
+#define IBI_STATUS_LAST_FRAG	BIT(24)
+#define PID_MANUF_ID_ASPEED	0x03f6
+
+struct mq_msg {
+	int len;
+	u8 *buf;
+};
+
+struct mq_queue {
+	struct bin_attribute bin;
+	struct kernfs_node *kn;
+
+	spinlock_t lock;
+	int in;
+	int out;
+
+	struct mq_msg *curr;
+	int truncated;
+	struct mq_msg queue[MQ_QUEUE_SIZE];
+};
+
+static u8 mdb_table[] = {
+	0xbf, /* Aspeed BIC */
+	0,
+};
+
+static void i3c_ibi_mqueue_callback(struct i3c_device *dev,
+				    const struct i3c_ibi_payload *payload)
+{
+	struct mq_queue *mq = dev_get_drvdata(&dev->dev);
+	struct mq_msg *msg = mq->curr;
+	u8 *buf = (u8 *)payload->data;
+	struct i3c_device_info info;
+	u32 status;
+	const u8 *mdb;
+
+	i3c_device_get_info(dev, &info);
+	/* first DW is IBI status */
+	status = *(u32 *)buf;
+
+	/* then the raw data */
+	buf += sizeof(status);
+	memcpy(&msg->buf[msg->len], buf, payload->len - sizeof(status));
+	msg->len += payload->len - sizeof(status);
+	if (status & IBI_QUEUE_STATUS_PEC_ERR) {
+		for (mdb = mdb_table; *mdb != 0; mdb++)
+			if (buf[0] == *mdb)
+				break;
+		if (!(*mdb)) {
+			dev_err(&dev->dev, "ibi crc/pec error: mdb = %x", buf[0]);
+			return;
+		}
+	}
+	/* if last fragment, notify and update pointers */
+	if (status & IBI_STATUS_LAST_FRAG) {
+		/* check pending-read-notification */
+		if (IS_MDB_PENDING_READ_NOTIFY(msg->buf[0])) {
+			struct i3c_priv_xfer xfers[1] = {
+				{
+					.rnw = true,
+					.len = info.max_read_len,
+					.data.in = msg->buf,
+				},
+			};
+
+			i3c_device_do_priv_xfers(dev, xfers, 1);
+
+			msg->len = xfers[0].len;
+		}
+
+		spin_lock(&mq->lock);
+		mq->in = MQ_QUEUE_NEXT(mq->in);
+		mq->curr = &mq->queue[mq->in];
+		mq->curr->len = 0;
+
+		if (mq->out == mq->in)
+			mq->out = MQ_QUEUE_NEXT(mq->out);
+		spin_unlock(&mq->lock);
+		kernfs_notify(mq->kn);
+	}
+}
+
+static ssize_t i3c_ibi_mqueue_bin_read(struct file *filp, struct kobject *kobj,
+				       struct bin_attribute *attr, char *buf,
+				       loff_t pos, size_t count)
+{
+	struct mq_queue *mq;
+	struct mq_msg *msg;
+	unsigned long flags;
+	bool more = false;
+	ssize_t ret = 0;
+
+	mq = dev_get_drvdata(container_of(kobj, struct device, kobj));
+
+	spin_lock_irqsave(&mq->lock, flags);
+	if (mq->out != mq->in) {
+		msg = &mq->queue[mq->out];
+
+		if (msg->len <= count) {
+			ret = msg->len;
+			memcpy(buf, msg->buf, ret);
+		} else {
+			ret = -EOVERFLOW; /* Drop this HUGE one. */
+		}
+
+		mq->out = MQ_QUEUE_NEXT(mq->out);
+		if (mq->out != mq->in)
+			more = true;
+	}
+	spin_unlock_irqrestore(&mq->lock, flags);
+
+	if (more)
+		kernfs_notify(mq->kn);
+
+	return ret;
+}
+
+static int i3c_ibi_mqueue_probe(struct i3c_device *i3cdev)
+{
+	struct device *dev = &i3cdev->dev;
+	struct mq_queue *mq;
+	struct i3c_ibi_setup ibireq = {};
+	int ret, i;
+	struct i3c_device_info info;
+	void *buf;
+
+	if (dev->type == &i3c_masterdev_type)
+		return -ENOTSUPP;
+
+	mq = devm_kzalloc(dev, sizeof(*mq), GFP_KERNEL);
+	if (!mq)
+		return -ENOMEM;
+
+	BUILD_BUG_ON(!is_power_of_2(MQ_QUEUE_SIZE));
+
+	buf = devm_kmalloc_array(dev, MQ_QUEUE_SIZE, MQ_MSGBUF_SIZE,
+				 GFP_KERNEL);
+	if (!buf)
+		return -ENOMEM;
+
+	for (i = 0; i < MQ_QUEUE_SIZE; i++) {
+		mq->queue[i].buf = buf + i * MQ_MSGBUF_SIZE;
+		mq->queue[i].len = 0;
+	}
+
+	i3c_device_get_info(i3cdev, &info);
+
+	ret = i3c_device_setmrl_ccc(i3cdev, &info, MQ_MSGBUF_SIZE,
+					    min(MQ_MSGBUF_SIZE, __UINT8_MAX__));
+	if (ret) {
+		ret = i3c_device_getmrl_ccc(i3cdev, &info);
+		if (ret)
+			return ret;
+	}
+
+	dev_set_drvdata(dev, mq);
+
+	spin_lock_init(&mq->lock);
+	mq->curr = &mq->queue[0];
+
+	sysfs_bin_attr_init(&mq->bin);
+	mq->bin.attr.name = "ibi-mqueue";
+	mq->bin.attr.mode = 0400;
+	mq->bin.read = i3c_ibi_mqueue_bin_read;
+	mq->bin.size = MQ_MSGBUF_SIZE * MQ_QUEUE_SIZE;
+
+	ret = sysfs_create_bin_file(&dev->kobj, &mq->bin);
+	if (ret)
+		return ret;
+
+	mq->kn = kernfs_find_and_get(dev->kobj.sd, mq->bin.attr.name);
+	if (!mq->kn) {
+		sysfs_remove_bin_file(&dev->kobj, &mq->bin);
+		return -EFAULT;
+	}
+
+	ibireq.handler = i3c_ibi_mqueue_callback;
+	ibireq.max_payload_len = MQ_MSGBUF_SIZE;
+	ibireq.num_slots = MQ_QUEUE_SIZE;
+
+	ret = i3c_device_request_ibi(i3cdev, &ibireq);
+	ret |= i3c_device_enable_ibi(i3cdev);
+
+	if (ret) {
+		kernfs_put(mq->kn);
+		sysfs_remove_bin_file(&dev->kobj, &mq->bin);
+		return ret;
+	}
+
+	return 0;
+}
+
+static void i3c_ibi_mqueue_remove(struct i3c_device *i3cdev)
+{
+	struct mq_queue *mq = dev_get_drvdata(&i3cdev->dev);
+
+	i3c_device_disable_ibi(i3cdev);
+	i3c_device_free_ibi(i3cdev);
+
+	kernfs_put(mq->kn);
+	sysfs_remove_bin_file(&i3cdev->dev.kobj, &mq->bin);
+}
+
+static const struct i3c_device_id i3c_ibi_mqueue_ids[] = {
+	I3C_DEVICE(0x3f6, 0x8000, (void *)0),
+	I3C_DEVICE(0x3f6, 0x8001, (void *)0),
+	I3C_DEVICE(0x3f6, 0x0503, (void *)0),
+	I3C_DEVICE(0x3f6, 0xA001, (void *)0),
+	{ /* sentinel */ },
+};
+MODULE_DEVICE_TABLE(i3c, i3c_ibi_mqueue_ids);
+
+static struct i3c_driver ibi_mqueue_driver = {
+	.driver = {
+		.name = "i3c-ibi-mqueue",
+	},
+	.probe = i3c_ibi_mqueue_probe,
+	.remove = i3c_ibi_mqueue_remove,
+	.id_table = i3c_ibi_mqueue_ids,
+};
+module_i3c_driver(ibi_mqueue_driver);
+
+MODULE_AUTHOR("Dylan Hung <dylan_hung@aspeedtech.com>");
+MODULE_DESCRIPTION("I3C IBI mqueue driver");
+MODULE_LICENSE("GPL v2");
diff --git a/drivers/i3c/i3c-mux-imx3102.c b/drivers/i3c/i3c-mux-imx3102.c
new file mode 100644
index 000000000000..b6972893cbd6
--- /dev/null
+++ b/drivers/i3c/i3c-mux-imx3102.c
@@ -0,0 +1,227 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Copyright (c) 2021 Aspeed Technology Inc.
+ *
+ * IMX3102: 2-to-1 multiplexier
+ *
+ * +------------------   +
+ * | SoC                 |
+ * |                     |
+ * | I3C controller #0 - | --+
+ * |                     |    \                  dev   dev
+ * |                     |     +---------+       |     |
+ * |                     |     | IMX3102 | ---+--+--+--+--- i3c bus
+ * |                     |     +---------+    |     |
+ * |                     |    /               dev   dev
+ * | I3C controller #1 - | --+
+ * |                     |
+ * +---------------------+
+ */
+
+#include <linux/i3c/device.h>
+#include <linux/i3c/master.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/of.h>
+#include <linux/slab.h>
+#include <linux/spinlock.h>
+#include <linux/sysfs.h>
+#include <linux/delay.h>
+#include <linux/regmap.h>
+#include "internals.h"
+
+#define IMX3102_DEVICE_TYPE_HI		0x0
+#define IMX3102_DEVICE_TYPE_LO		0x1
+
+#define IMX3102_PORT_CONF		0x40
+#define   IMX3102_PORT_CONF_M1_EN	BIT(7)
+#define   IMX3102_PORT_CONF_S_EN	BIT(6)
+#define IMX3102_PORT_SEL		0x41
+#define   IMX3102_PORT_SEL_M1		BIT(7)
+#define   IMX3102_PORT_SEL_S_EN		BIT(6)
+
+struct imx3102 {
+	struct regmap *regmap;
+
+	struct bin_attribute ownership;
+	struct bin_attribute reinit;
+	struct kernfs_node *kn;
+
+	struct i3c_device *i3cdev;
+};
+
+static ssize_t i3c_mux_imx3102_query(struct file *filp, struct kobject *kobj,
+				     struct bin_attribute *attr, char *buf,
+				     loff_t pos, size_t count)
+{
+	struct imx3102 *imx3102;
+	struct device *dev;
+	int ret;
+	u8 data[2];
+
+	imx3102 = dev_get_drvdata(container_of(kobj, struct device, kobj));
+	if (!imx3102)
+		return -1;
+
+	dev = &imx3102->i3cdev->dev;
+
+	ret = regmap_raw_read(imx3102->regmap, IMX3102_DEVICE_TYPE_HI, data, 2);
+	if (ret)
+		sprintf(buf, "N\n");
+	else
+		sprintf(buf, "Y\n");
+
+	return 2;
+}
+
+/* write whatever value to imx3102-mux to release the ownership */
+static ssize_t i3c_mux_imx3102_release_chan(struct file *filp,
+					    struct kobject *kobj,
+					    struct bin_attribute *attr,
+					    char *buf, loff_t pos, size_t count)
+{
+	struct imx3102 *imx3102;
+	struct device *dev;
+	struct regmap *regmap;
+	int ret;
+	u8 select;
+
+	imx3102 = dev_get_drvdata(container_of(kobj, struct device, kobj));
+	if (!imx3102) {
+		count = -1;
+		goto out;
+	}
+
+	dev = &imx3102->i3cdev->dev;
+	regmap = imx3102->regmap;
+	ret = regmap_raw_read(regmap, IMX3102_PORT_SEL, &select, 1);
+	if (ret)
+		goto out;
+
+	/* invert the bit to change the ownership */
+	select ^= IMX3102_PORT_SEL_M1;
+	regmap_raw_write(regmap, IMX3102_PORT_SEL, &select, 1);
+
+out:
+	return count;
+}
+
+static ssize_t i3c_mux_imx3102_bus_reinit(struct file *filp,
+					  struct kobject *kobj,
+					  struct bin_attribute *attr, char *buf,
+					  loff_t pos, size_t count)
+{
+	struct imx3102 *imx3102;
+	int ret;
+
+	imx3102 = dev_get_drvdata(container_of(kobj, struct device, kobj));
+	if (!imx3102) {
+		count = -1;
+		return count;
+	}
+
+	ret = i3c_device_send_ccc_cmd(imx3102->i3cdev, I3C_CCC_SETHID);
+	ret = i3c_device_send_ccc_cmd(imx3102->i3cdev, I3C_CCC_SETAASA);
+
+	return count;
+}
+
+static int i3c_mux_imx3102_probe(struct i3c_device *i3cdev)
+{
+	struct device *dev = &i3cdev->dev;
+	struct imx3102 *imx3102;
+	struct regmap *regmap;
+	struct regmap_config imx3102_i3c_regmap_config = {
+		.reg_bits = 8,
+		.pad_bits = 8,
+		.val_bits = 8,
+	};
+	int ret;
+	u8 data[2];
+
+	if (dev->type == &i3c_masterdev_type)
+		return -ENOTSUPP;
+
+	imx3102 = devm_kzalloc(dev, sizeof(*imx3102), GFP_KERNEL);
+	if (!imx3102)
+		return -ENOMEM;
+
+	imx3102->i3cdev = i3cdev;
+
+	/* register regmap */
+	regmap = devm_regmap_init_i3c(i3cdev, &imx3102_i3c_regmap_config);
+	if (IS_ERR(regmap)) {
+		dev_err(dev, "Failed to register i3c regmap %d\n",
+			(int)PTR_ERR(regmap));
+		return PTR_ERR(regmap);
+	}
+	imx3102->regmap = regmap;
+
+	sysfs_bin_attr_init(&imx3102->ownership);
+	imx3102->ownership.attr.name = "imx3102.ownership";
+	imx3102->ownership.attr.mode = 0600;
+	imx3102->ownership.read = i3c_mux_imx3102_query;
+	imx3102->ownership.write = i3c_mux_imx3102_release_chan;
+	imx3102->ownership.size = 2;
+	ret = sysfs_create_bin_file(&dev->kobj, &imx3102->ownership);
+
+	sysfs_bin_attr_init(&imx3102->reinit);
+	imx3102->reinit.attr.name = "imx3102.reinit";
+	imx3102->reinit.attr.mode = 0200;
+	imx3102->reinit.write = i3c_mux_imx3102_bus_reinit;
+	imx3102->reinit.size = 2;
+	ret = sysfs_create_bin_file(&dev->kobj, &imx3102->reinit);
+
+	imx3102->kn = kernfs_find_and_get(dev->kobj.sd, imx3102->ownership.attr.name);
+	dev_set_drvdata(dev, imx3102);
+
+	ret = regmap_raw_read(regmap, IMX3102_DEVICE_TYPE_HI, data, 2);
+	if (ret) {
+		dev_info(dev, "No ownership\n");
+		return 0;
+	}
+	dev_dbg(dev, "device ID %02x %02x\n", data[0], data[1]);
+
+	/* enable the slave port */
+	regmap_raw_read(regmap, IMX3102_PORT_CONF, &data[0], 2);
+	data[0] |= IMX3102_PORT_CONF_S_EN | IMX3102_PORT_CONF_M1_EN;
+	data[1] |= IMX3102_PORT_SEL_S_EN;
+	regmap_raw_write(regmap, IMX3102_PORT_CONF, data, 2);
+
+	/* send SETAASA to bring the devices behind the mux to I3C mode */
+	i3c_device_send_ccc_cmd(i3cdev, I3C_CCC_SETAASA);
+
+	return 0;
+}
+
+static void i3c_mux_imx3102_remove(struct i3c_device *i3cdev)
+{
+	struct device *dev = &i3cdev->dev;
+	struct imx3102 *imx3102;
+
+	imx3102 = dev_get_drvdata(dev);
+
+	kernfs_put(imx3102->kn);
+	sysfs_remove_bin_file(&dev->kobj, &imx3102->ownership);
+	devm_kfree(dev, imx3102);
+}
+
+static const struct i3c_device_id i3c_mux_imx3102_ids[] = {
+	I3C_DEVICE(0x266, 0x3102, (void *)0),
+	{ /* sentinel */ },
+};
+MODULE_DEVICE_TABLE(i3c, i3c_mux_imx3102_ids);
+
+static struct i3c_driver imx3102_driver = {
+	.driver = {
+		.name = "i3c-mux-imx3102",
+	},
+	.probe = i3c_mux_imx3102_probe,
+	.remove = i3c_mux_imx3102_remove,
+	.id_table = i3c_mux_imx3102_ids,
+};
+module_i3c_driver(imx3102_driver);
+
+MODULE_AUTHOR("Dylan Hung <dylan_hung@aspeedtech.com>");
+MODULE_DESCRIPTION("I3C IMX3102 multiplexer driver");
+MODULE_LICENSE("GPL v2");
diff --git a/drivers/i3c/i3c-slave-eeprom.c b/drivers/i3c/i3c-slave-eeprom.c
new file mode 100644
index 000000000000..abc1d693adb4
--- /dev/null
+++ b/drivers/i3c/i3c-slave-eeprom.c
@@ -0,0 +1,175 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Copyright (c) 2022 Aspeed Technology Inc.
+ */
+
+#include <linux/i3c/master.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/of.h>
+#include <linux/slab.h>
+#include <linux/spinlock.h>
+#include <linux/sysfs.h>
+
+struct eeprom_data {
+	struct bin_attribute bin;
+	struct work_struct prep_rdata;
+	spinlock_t buffer_lock;
+	u16 buffer_idx;
+	u16 address_mask;
+	u8 num_address_bytes;
+
+	struct i3c_master_controller *i3c_controller;
+	u8 buffer[];
+};
+
+static void i3c_slave_eeprom_prep_rdata(struct work_struct *work)
+{
+	struct eeprom_data *eeprom = container_of(work, struct eeprom_data, prep_rdata);
+	struct i3c_slave_payload read_data, notify;
+	u32 mdb = IBI_MDB_ID(0b101, 0x1f);
+
+	notify.len = 1;
+	notify.data = &mdb;
+
+	read_data.len = eeprom->address_mask - eeprom->buffer_idx + 1;
+	read_data.data = &eeprom->buffer[eeprom->buffer_idx];
+	i3c_master_put_read_data(eeprom->i3c_controller, &read_data, &notify);
+}
+
+static void i3c_slave_eeprom_callback(struct i3c_master_controller *master,
+				      const struct i3c_slave_payload *payload)
+{
+	struct eeprom_data *eeprom = dev_get_drvdata(&master->dev);
+	int wr_len;
+	u8 *buf = (u8 *)payload->data;
+
+	if (!payload->len)
+		return;
+
+	if (eeprom->num_address_bytes == 2)
+		eeprom->buffer_idx = ((u16)buf[0] << 8) | buf[1];
+	else
+		eeprom->buffer_idx = (u16)buf[0];
+
+	wr_len = payload->len - eeprom->num_address_bytes;
+
+	pr_debug("len = %d, index=%d, wr_len=%d\n", payload->len,
+		 eeprom->buffer_idx, wr_len);
+
+	if (wr_len > 0) {
+		if (eeprom->buffer_idx + wr_len > eeprom->address_mask) {
+			u16 len = eeprom->address_mask - eeprom->buffer_idx + 1;
+
+			memcpy(&eeprom->buffer[eeprom->buffer_idx],
+			       &buf[eeprom->num_address_bytes], len);
+			memcpy(&eeprom->buffer[0],
+			       &buf[eeprom->num_address_bytes + len],
+			       wr_len - len);
+		} else {
+			memcpy(&eeprom->buffer[eeprom->buffer_idx],
+			       &buf[eeprom->num_address_bytes], wr_len);
+		}
+
+		eeprom->buffer_idx += wr_len;
+		eeprom->buffer_idx &= eeprom->address_mask;
+	}
+
+	/* prepare the read data outside of interrupt context */
+	schedule_work(&eeprom->prep_rdata);
+}
+
+static ssize_t i3c_slave_eeprom_bin_read(struct file *filp,
+					 struct kobject *kobj,
+					 struct bin_attribute *attr, char *buf,
+					 loff_t off, size_t count)
+{
+	struct eeprom_data *eeprom;
+	unsigned long flags;
+
+	eeprom = dev_get_drvdata(container_of(kobj, struct device, kobj));
+
+	spin_lock_irqsave(&eeprom->buffer_lock, flags);
+	memcpy(buf, &eeprom->buffer[off], count);
+	spin_unlock_irqrestore(&eeprom->buffer_lock, flags);
+
+	return count;
+}
+
+static ssize_t i3c_slave_eeprom_bin_write(struct file *filp,
+					  struct kobject *kobj,
+					  struct bin_attribute *attr, char *buf,
+					  loff_t off, size_t count)
+{
+	struct eeprom_data *eeprom;
+	unsigned long flags;
+
+	eeprom = dev_get_drvdata(container_of(kobj, struct device, kobj));
+
+	spin_lock_irqsave(&eeprom->buffer_lock, flags);
+	memcpy(&eeprom->buffer[off], buf, count);
+	spin_unlock_irqrestore(&eeprom->buffer_lock, flags);
+
+	return count;
+}
+
+int i3c_slave_eeprom_probe(struct i3c_master_controller *master)
+{
+	struct eeprom_data *eeprom;
+	int ret;
+	struct i3c_slave_setup req = {};
+	struct device *dev = &master->dev;
+
+	/* fixed parameters for testing: size 64 bytes, address size is 1 byte */
+	unsigned int size = 64;
+	unsigned int flag_addr16 = 0;
+
+	eeprom = devm_kzalloc(dev, sizeof(struct eeprom_data) + size, GFP_KERNEL);
+	if (!eeprom)
+		return -ENOMEM;
+
+	eeprom->num_address_bytes = flag_addr16 ? 2 : 1;
+	eeprom->address_mask = size - 1;
+	spin_lock_init(&eeprom->buffer_lock);
+	dev_set_drvdata(dev, eeprom);
+
+	memset(eeprom->buffer, 0xff, size);
+
+	sysfs_bin_attr_init(&eeprom->bin);
+	eeprom->bin.attr.name = "slave-eeprom";
+	eeprom->bin.attr.mode = 0600;
+	eeprom->bin.read = i3c_slave_eeprom_bin_read;
+	eeprom->bin.write = i3c_slave_eeprom_bin_write;
+	eeprom->bin.size = size;
+
+	eeprom->i3c_controller = master;
+
+	ret = sysfs_create_bin_file(&dev->kobj, &eeprom->bin);
+	if (ret)
+		return ret;
+
+	INIT_WORK(&eeprom->prep_rdata, i3c_slave_eeprom_prep_rdata);
+
+	req.handler = i3c_slave_eeprom_callback;
+	req.max_payload_len = size;
+	req.num_slots = 1;
+
+	ret = i3c_master_register_slave(master, &req);
+	if (ret) {
+		sysfs_remove_bin_file(&dev->kobj, &eeprom->bin);
+		return ret;
+	}
+
+	return 0;
+}
+
+int i3c_slave_eeprom_remove(struct i3c_master_controller *master)
+{
+	struct device *dev = &master->dev;
+	struct eeprom_data *eeprom = dev_get_drvdata(dev);
+
+	i3c_master_unregister_slave(master);
+	sysfs_remove_bin_file(&dev->kobj, &eeprom->bin);
+
+	return 0;
+}
diff --git a/drivers/i3c/i3c-slave-mqueue.c b/drivers/i3c/i3c-slave-mqueue.c
new file mode 100644
index 000000000000..ff05ee4e7de8
--- /dev/null
+++ b/drivers/i3c/i3c-slave-mqueue.c
@@ -0,0 +1,206 @@
+// SPDX-License-Identifier: GPL-2.0-only
+/*
+ * Copyright (c) 2021 Aspeed Technology Inc.
+ */
+
+#include <linux/i3c/master.h>
+#include <linux/kernel.h>
+#include <linux/module.h>
+#include <linux/of.h>
+#include <linux/slab.h>
+#include <linux/spinlock.h>
+#include <linux/sysfs.h>
+
+#define MQ_MSGBUF_SIZE		256
+#define MQ_QUEUE_SIZE		4
+#define MQ_QUEUE_NEXT(x)	(((x) + 1) & (MQ_QUEUE_SIZE - 1))
+
+#define IBI_STATUS_LAST_FRAG	BIT(24)
+#define MQ_MDB			IBI_MDB_ID(0b101, 0x1f)
+
+struct mq_msg {
+	int len;
+	u8 *buf;
+};
+
+struct mq_queue {
+	struct bin_attribute bin;
+	struct kernfs_node *kn;
+
+	spinlock_t lock;
+	int in;
+	int out;
+
+	struct mq_msg *curr;
+	int truncated;
+	struct mq_msg queue[MQ_QUEUE_SIZE];
+
+	struct i3c_master_controller *i3c_controller;
+	u8 mdb;
+};
+
+static void i3c_slave_mqueue_callback(struct i3c_master_controller *master,
+				      const struct i3c_slave_payload *payload)
+{
+	struct mq_queue *mq = dev_get_drvdata(&master->dev);
+	struct mq_msg *msg = mq->curr;
+
+	memcpy(msg->buf, (u8 *)payload->data, payload->len);
+	msg->len = payload->len;
+
+	spin_lock(&mq->lock);
+	mq->in = MQ_QUEUE_NEXT(mq->in);
+	mq->curr = &mq->queue[mq->in];
+	mq->curr->len = 0;
+
+	if (mq->out == mq->in)
+		mq->out = MQ_QUEUE_NEXT(mq->out);
+	spin_unlock(&mq->lock);
+	kernfs_notify(mq->kn);
+}
+
+static ssize_t i3c_slave_mqueue_bin_read(struct file *filp, struct kobject *kobj,
+				       struct bin_attribute *attr, char *buf,
+				       loff_t pos, size_t count)
+{
+	struct mq_queue *mq;
+	struct mq_msg *msg;
+	unsigned long flags;
+	bool more = false;
+	ssize_t ret = 0;
+
+	mq = dev_get_drvdata(container_of(kobj, struct device, kobj));
+
+	spin_lock_irqsave(&mq->lock, flags);
+	if (mq->out != mq->in) {
+		msg = &mq->queue[mq->out];
+
+		if (msg->len <= count) {
+			ret = msg->len;
+			memcpy(buf, msg->buf, ret);
+		} else {
+			ret = -EOVERFLOW; /* Drop this HUGE one. */
+		}
+
+		mq->out = MQ_QUEUE_NEXT(mq->out);
+		if (mq->out != mq->in)
+			more = true;
+	}
+	spin_unlock_irqrestore(&mq->lock, flags);
+
+	if (more)
+		kernfs_notify(mq->kn);
+
+	return ret;
+}
+
+static ssize_t i3c_slave_mqueue_bin_write(struct file *filp,
+					  struct kobject *kobj,
+					  struct bin_attribute *attr, char *buf,
+					  loff_t pos, size_t count)
+{
+	struct mq_queue *mq;
+	struct i3c_slave_payload payload, ibi;
+	u8 *data;
+
+	mq = dev_get_drvdata(container_of(kobj, struct device, kobj));
+
+	if (IS_MDB_PENDING_READ_NOTIFY(mq->mdb)) {
+		ibi.data = &mq->mdb;
+		ibi.len = 1;
+		payload.data = buf;
+		payload.len = count;
+		i3c_master_put_read_data(mq->i3c_controller, &payload, &ibi);
+	} else {
+		data = kmalloc(count + 1, GFP_KERNEL);
+		if (!data)
+			return -ENOMEM;
+
+		data[0] = mq->mdb;
+		memcpy(&data[1], buf, count);
+
+		payload.data = data;
+		payload.len = count + 1;
+		i3c_master_send_sir(mq->i3c_controller, &payload);
+		kfree(data);
+	}
+
+	return count;
+}
+
+int i3c_slave_mqueue_probe(struct i3c_master_controller *master)
+{
+	struct mq_queue *mq;
+	int ret, i;
+	void *buf;
+	struct i3c_slave_setup req = {};
+	struct device *dev = &master->dev;
+
+	mq = devm_kzalloc(dev, sizeof(*mq), GFP_KERNEL);
+	if (!mq)
+		return -ENOMEM;
+
+	BUILD_BUG_ON(!is_power_of_2(MQ_QUEUE_SIZE));
+
+	buf = devm_kmalloc_array(dev, MQ_QUEUE_SIZE, MQ_MSGBUF_SIZE,
+				 GFP_KERNEL);
+	if (!buf)
+		return -ENOMEM;
+
+	for (i = 0; i < MQ_QUEUE_SIZE; i++) {
+		mq->queue[i].buf = buf + i * MQ_MSGBUF_SIZE;
+		mq->queue[i].len = 0;
+	}
+
+	dev_set_drvdata(dev, mq);
+
+	spin_lock_init(&mq->lock);
+	mq->curr = &mq->queue[0];
+
+	sysfs_bin_attr_init(&mq->bin);
+	mq->bin.attr.name = "slave-mqueue";
+	mq->bin.attr.mode = 0600;
+	mq->bin.read = i3c_slave_mqueue_bin_read;
+	mq->bin.write = i3c_slave_mqueue_bin_write;
+	mq->bin.size = MQ_MSGBUF_SIZE * MQ_QUEUE_SIZE;
+
+	mq->i3c_controller = master;
+	mq->mdb = MQ_MDB;
+
+	ret = sysfs_create_bin_file(&dev->kobj, &mq->bin);
+	if (ret)
+		return ret;
+
+	mq->kn = kernfs_find_and_get(dev->kobj.sd, mq->bin.attr.name);
+	if (!mq->kn) {
+		sysfs_remove_bin_file(&dev->kobj, &mq->bin);
+		return -EFAULT;
+	}
+
+	req.handler = i3c_slave_mqueue_callback;
+	req.max_payload_len = MQ_MSGBUF_SIZE;
+	req.num_slots = MQ_QUEUE_SIZE;
+
+	ret = i3c_master_register_slave(master, &req);
+
+	if (ret) {
+		kernfs_put(mq->kn);
+		sysfs_remove_bin_file(&dev->kobj, &mq->bin);
+		return ret;
+	}
+
+	return 0;
+}
+
+int i3c_slave_mqueue_remove(struct i3c_master_controller *master)
+{
+	struct device *dev = &master->dev;
+	struct mq_queue *mq = dev_get_drvdata(dev);
+
+	i3c_master_unregister_slave(master);
+
+	kernfs_put(mq->kn);
+	sysfs_remove_bin_file(&dev->kobj, &mq->bin);
+
+	return 0;
+}
diff --git a/drivers/i3c/i3cdev.c b/drivers/i3c/i3cdev.c
index 04834c7daa23..ef08b6056165 100644
--- a/drivers/i3c/i3cdev.c
+++ b/drivers/i3c/i3cdev.c
@@ -1,6 +1,6 @@
 // SPDX-License-Identifier: GPL-2.0
 /*
- * Copyright (c) 2019 Synopsys, Inc. and/or its affiliates.
+ * Copyright (c) 2020 Synopsys, Inc. and/or its affiliates.
  *
  * Author: Vitor Soares <soares@synopsys.com>
  */
@@ -12,7 +12,6 @@
 #include <linux/init.h>
 #include <linux/jiffies.h>
 #include <linux/kernel.h>
-#include <linux/list.h>
 #include <linux/module.h>
 #include <linux/notifier.h>
 #include <linux/slab.h>
@@ -23,36 +22,16 @@
 #include "internals.h"

 struct i3cdev_data {
-	struct list_head list;
 	struct i3c_device *i3c;
-	struct cdev cdev;
 	struct device *dev;
+	struct mutex xfer_lock; /* prevent detach while transferring */
+	struct cdev cdev;
 	int id;
 };

 static DEFINE_IDA(i3cdev_ida);
 static dev_t i3cdev_number;
-#define I3C_MINORS 128 /* 128 I3C devices supported for now */
-
-static LIST_HEAD(i3cdev_list);
-static DEFINE_SPINLOCK(i3cdev_list_lock);
-
-static struct i3cdev_data *i3cdev_get_by_i3c(struct i3c_device *i3c)
-{
-	struct i3cdev_data *i3cdev;
-
-	spin_lock(&i3cdev_list_lock);
-	list_for_each_entry(i3cdev, &i3cdev_list, list) {
-		if (i3cdev->i3c == i3c)
-			goto found;
-	}
-
-	i3cdev = NULL;
-
-found:
-	spin_unlock(&i3cdev_list_lock);
-	return i3cdev;
-}
+#define I3C_MINORS (MINORMASK + 1)

 static struct i3cdev_data *get_free_i3cdev(struct i3c_device *i3c)
 {
@@ -73,32 +52,32 @@ static struct i3cdev_data *get_free_i3cdev(struct i3c_device *i3c)

 	i3cdev->i3c = i3c;
 	i3cdev->id = id;
-
-	spin_lock(&i3cdev_list_lock);
-	list_add_tail(&i3cdev->list, &i3cdev_list);
-	spin_unlock(&i3cdev_list_lock);
+	i3cdev_set_drvdata(i3c, i3cdev);

 	return i3cdev;
 }

 static void put_i3cdev(struct i3cdev_data *i3cdev)
 {
-	spin_lock(&i3cdev_list_lock);
-	list_del(&i3cdev->list);
-	spin_unlock(&i3cdev_list_lock);
+	i3cdev_set_drvdata(i3cdev->i3c, NULL);
 	kfree(i3cdev);
 }

 static ssize_t
 i3cdev_read(struct file *file, char __user *buf, size_t count, loff_t *f_pos)
 {
-	struct i3c_device *i3c = file->private_data;
+	struct i3cdev_data *i3cdev = file->private_data;
+	struct i3c_device *i3c = i3cdev->i3c;
 	struct i3c_priv_xfer xfers = {
 		.rnw = true,
 		.len = count,
 	};
+	int ret = -EACCES;
 	char *tmp;
-	int ret;
+
+	mutex_lock(&i3cdev->xfer_lock);
+	if (!IS_ENABLED(CONFIG_I3CDEV_FORCE_CREATE) && i3c->dev.driver)
+		goto err_out;

 	tmp = kzalloc(count, GFP_KERNEL);
 	if (!tmp)
@@ -110,9 +89,12 @@ i3cdev_read(struct file *file, char __user *buf, size_t count, loff_t *f_pos)

 	ret = i3c_device_do_priv_xfers(i3c, &xfers, 1);
 	if (!ret)
-		ret = copy_to_user(buf, tmp, count) ? -EFAULT : ret;
+		ret = copy_to_user(buf, tmp, xfers.len) ? -EFAULT : xfers.len;

 	kfree(tmp);
+
+err_out:
+	mutex_unlock(&i3cdev->xfer_lock);
 	return ret;
 }

@@ -120,13 +102,18 @@ static ssize_t
 i3cdev_write(struct file *file, const char __user *buf, size_t count,
 	     loff_t *f_pos)
 {
-	struct i3c_device *i3c = file->private_data;
+	struct i3cdev_data *i3cdev = file->private_data;
+	struct i3c_device *i3c = i3cdev->i3c;
 	struct i3c_priv_xfer xfers = {
 		.rnw = false,
 		.len = count,
 	};
+	int ret = -EACCES;
 	char *tmp;
-	int ret;
+
+	mutex_lock(&i3cdev->xfer_lock);
+	if (!IS_ENABLED(CONFIG_I3CDEV_FORCE_CREATE) && i3c->dev.driver)
+		goto err_out;

 	tmp = memdup_user(buf, count);
 	if (IS_ERR(tmp))
@@ -138,6 +125,9 @@ i3cdev_write(struct file *file, const char __user *buf, size_t count,

 	ret = i3c_device_do_priv_xfers(i3c, &xfers, 1);
 	kfree(tmp);
+
+err_out:
+	mutex_unlock(&i3cdev->xfer_lock);
 	return (!ret) ? count : ret;
 }

@@ -149,15 +139,14 @@ i3cdev_do_priv_xfer(struct i3c_device *dev, struct i3c_ioc_priv_xfer *xfers,
 	u8 **data_ptrs;
 	int i, ret = 0;

-	k_xfers = kcalloc(nxfers, sizeof(*k_xfers), GFP_KERNEL);
+	/* Since we have nxfers we may allocate k_xfer + *data_ptrs together */
+	k_xfers = kcalloc(nxfers, sizeof(*k_xfers) + sizeof(*data_ptrs),
+			  GFP_KERNEL);
 	if (!k_xfers)
 		return -ENOMEM;

-	data_ptrs = kcalloc(nxfers, sizeof(*data_ptrs), GFP_KERNEL);
-	if (!data_ptrs) {
-		ret = -ENOMEM;
-		goto err_free_k_xfer;
-	}
+	/* set data_ptrs to be after nxfers * i3c_priv_xfer */
+	data_ptrs = (void *)k_xfers + (nxfers * sizeof(*k_xfers));

 	for (i = 0; i < nxfers; i++) {
 		data_ptrs[i] = memdup_user((const u8 __user *)
@@ -182,13 +171,82 @@ i3cdev_do_priv_xfer(struct i3c_device *dev, struct i3c_ioc_priv_xfer *xfers,
 		i--;
 		goto err_free_mem;
 	}
+
 	ret = i3c_device_do_priv_xfers(dev, k_xfers, nxfers);
 	if (ret)
 		goto err_free_mem;

 	for (i = 0; i < nxfers; i++) {
 		if (xfers[i].rnw) {
-			if (copy_to_user((void __user *)(uintptr_t)xfers[i].data,
+			if (copy_to_user(u64_to_user_ptr(xfers[i].data),
+					 data_ptrs[i], xfers[i].len))
+				ret = -EFAULT;
+		}
+	}
+
+err_free_mem:
+	for (; i >= 0; i--)
+		kfree(data_ptrs[i]);
+	kfree(k_xfers);
+	return ret;
+}
+
+static int
+i3cdev_send_hdr_xfer(struct i3c_device *dev, struct i3c_ioc_priv_xfer *xfers,
+		    unsigned int nxfers)
+{
+	struct i3c_hdr_cmd *k_xfers;
+	u8 **data_ptrs;
+	u16 xfer_len;
+	int i, ret = 0;
+
+	/* Since we have nxfers we may allocate k_xfer + *data_ptrs together */
+	k_xfers = kcalloc(nxfers, sizeof(*k_xfers) + sizeof(*data_ptrs),
+			  GFP_KERNEL);
+	if (!k_xfers)
+		return -ENOMEM;
+
+	/* set data_ptrs to be after nxfers * i3c_priv_xfer */
+	data_ptrs = (void *)k_xfers + (nxfers * sizeof(*k_xfers));
+
+	for (i = 0; i < nxfers; i++) {
+		xfer_len = roundup(xfers[i].len, 2);
+		data_ptrs[i] = kzalloc(xfer_len, GFP_KERNEL);
+		if (!data_ptrs[i])
+			return -ENOMEM;
+		if (copy_from_user(data_ptrs[i],
+				   (const u8 __user *)(uintptr_t)xfers[i].data,
+				   xfers[i].len)) {
+			kfree(data_ptrs[i]);
+			return -EFAULT;
+		}
+		if (IS_ERR(data_ptrs[i])) {
+			ret = PTR_ERR(data_ptrs[i]);
+			break;
+		}
+		k_xfers[i].mode = I3C_HDR_DDR;
+		k_xfers[i].ndatawords = DIV_ROUND_UP(xfers[i].len, 2);
+		if (xfers[i].rnw) {
+			k_xfers[i].code = 0x80;
+			k_xfers[i].data.in = data_ptrs[i];
+		} else {
+			k_xfers[i].code = 0;
+			k_xfers[i].data.out = data_ptrs[i];
+		}
+	}
+
+	if (ret < 0) {
+		i--;
+		goto err_free_mem;
+	}
+
+	ret = i3c_device_send_hdr_cmds(dev, k_xfers, nxfers);
+	if (ret)
+		goto err_free_mem;
+
+	for (i = 0; i < nxfers; i++) {
+		if (xfers[i].rnw) {
+			if (copy_to_user(u64_to_user_ptr(xfers[i].data),
 					 data_ptrs[i], xfers[i].len))
 				ret = -EFAULT;
 		}
@@ -197,8 +255,6 @@ i3cdev_do_priv_xfer(struct i3c_device *dev, struct i3c_ioc_priv_xfer *xfers,
 err_free_mem:
 	for (; i >= 0; i--)
 		kfree(data_ptrs[i]);
-	kfree(data_ptrs);
-err_free_k_xfer:
 	kfree(k_xfers);
 	return ret;
 }
@@ -209,14 +265,12 @@ i3cdev_get_ioc_priv_xfer(unsigned int cmd, struct i3c_ioc_priv_xfer *u_xfers,
 {
 	u32 tmp = _IOC_SIZE(cmd);

-	if ((tmp % sizeof(struct i3c_ioc_priv_xfer)) != 0) {
-		pr_err( "i3c_ioc_priv_xfer: Error " " Req size=%d, should be=%d \n", tmp, sizeof(struct i3c_ioc_priv_xfer));
+	if ((tmp % sizeof(struct i3c_ioc_priv_xfer)) != 0)
 		return ERR_PTR(-EINVAL);
-    }

 	*nxfers = tmp / sizeof(struct i3c_ioc_priv_xfer);
 	if (*nxfers == 0)
-		return NULL;
+		return ERR_PTR(-EINVAL);

 	return memdup_user(u_xfers, tmp);
 }
@@ -230,10 +284,14 @@ i3cdev_ioc_priv_xfer(struct i3c_device *i3c, unsigned int cmd,
 	int ret;

 	k_xfers = i3cdev_get_ioc_priv_xfer(cmd, u_xfers, &nxfers);
-	if (IS_ERR_OR_NULL(k_xfers))
+	if (IS_ERR(k_xfers))
 		return PTR_ERR(k_xfers);

-	ret = i3cdev_do_priv_xfer(i3c, k_xfers, nxfers);
+	if (i3c->desc->info.hdr_cap & BIT(I3C_HDR_DDR) &&
+	    IS_ENABLED(CONFIG_I3CDEV_XFER_HDR_DDR))
+		ret = i3cdev_send_hdr_xfer(i3c, k_xfers, nxfers);
+	else
+		ret = i3cdev_do_priv_xfer(i3c, k_xfers, nxfers);

 	kfree(k_xfers);

@@ -243,20 +301,29 @@ i3cdev_ioc_priv_xfer(struct i3c_device *i3c, unsigned int cmd,
 static long
 i3cdev_ioctl(struct file *file, unsigned int cmd, unsigned long arg)
 {
-	struct i3c_device *i3c = file->private_data;
+	struct i3cdev_data *i3cdev = file->private_data;
+	struct i3c_device *i3c = i3cdev->i3c;
+	int ret = -EACCES;

 	dev_dbg(&i3c->dev, "ioctl, cmd=0x%02x, arg=0x%02lx\n", cmd, arg);

 	if (_IOC_TYPE(cmd) != I3C_DEV_IOC_MAGIC)
 		return -ENOTTY;

+	/* Use the xfer_lock to prevent device detach during ioctl call */
+	mutex_lock(&i3cdev->xfer_lock);
+	if (!IS_ENABLED(CONFIG_I3CDEV_FORCE_CREATE) && i3c->dev.driver)
+		goto err_no_dev;
+
 	/* Check command number and direction */
 	if (_IOC_NR(cmd) == _IOC_NR(I3C_IOC_PRIV_XFER(0)) &&
 	    _IOC_DIR(cmd) == (_IOC_READ | _IOC_WRITE))
-		return i3cdev_ioc_priv_xfer(i3c, cmd,
+		ret = i3cdev_ioc_priv_xfer(i3c, cmd,
 					(struct i3c_ioc_priv_xfer __user *)arg);

-	return 0;
+err_no_dev:
+	mutex_unlock(&i3cdev->xfer_lock);
+	return ret;
 }

 static int i3cdev_open(struct inode *inode, struct file *file)
@@ -264,8 +331,7 @@ static int i3cdev_open(struct inode *inode, struct file *file)
 	struct i3cdev_data *i3cdev = container_of(inode->i_cdev,
 						  struct i3cdev_data,
 						  cdev);
-
-	file->private_data = i3cdev->i3c;
+	file->private_data = i3cdev;

 	return 0;
 }
@@ -282,6 +348,7 @@ static const struct file_operations i3cdev_fops = {
 	.read		= i3cdev_read,
 	.write		= i3cdev_write,
 	.unlocked_ioctl	= i3cdev_ioctl,
+	.compat_ioctl	= compat_ptr_ioctl,
 	.open		= i3cdev_open,
 	.release	= i3cdev_release,
 };
@@ -296,7 +363,10 @@ static int i3cdev_attach(struct device *dev, void *dummy)
 	struct i3c_device *i3c;
 	int res;

-	if (dev->type == &i3c_masterdev_type || dev->driver)
+	if (dev->type == &i3c_masterdev_type)
+		return 0;
+
+	if (!IS_ENABLED(CONFIG_I3CDEV_FORCE_CREATE) && dev->driver)
 		return 0;

 	i3c = dev_to_i3cdev(dev);
@@ -306,6 +376,7 @@ static int i3cdev_attach(struct device *dev, void *dummy)
 	if (IS_ERR(i3cdev))
 		return PTR_ERR(i3cdev);

+	mutex_init(&i3cdev->xfer_lock);
 	cdev_init(&i3cdev->cdev, &i3cdev_fops);
 	i3cdev->cdev.owner = THIS_MODULE;
 	res = cdev_add(&i3cdev->cdev,
@@ -316,7 +387,7 @@ static int i3cdev_attach(struct device *dev, void *dummy)
 	/* register this i3c device with the driver core */
 	i3cdev->dev = device_create(i3cdev_class, &i3c->dev,
 				    MKDEV(MAJOR(i3cdev_number), i3cdev->id),
-				    NULL, "i3c-%s", dev_name(&i3c->dev));
+				    NULL, "bus!i3c!%s", dev_name(&i3c->dev));
 	if (IS_ERR(i3cdev->dev)) {
 		res = PTR_ERR(i3cdev->dev);
 		goto error;
@@ -342,12 +413,16 @@ static int i3cdev_detach(struct device *dev, void *dummy)

 	i3c = dev_to_i3cdev(dev);

-	i3cdev = i3cdev_get_by_i3c(i3c);
+	i3cdev = i3cdev_get_drvdata(i3c);
 	if (!i3cdev)
 		return 0;

+	/* Prevent transfers while cdev removal */
+	mutex_lock(&i3cdev->xfer_lock);
 	cdev_del(&i3cdev->cdev);
 	device_destroy(i3cdev_class, MKDEV(MAJOR(i3cdev_number), i3cdev->id));
+	mutex_unlock(&i3cdev->xfer_lock);
+
 	ida_simple_remove(&i3cdev_ida, i3cdev->id);
 	put_i3cdev(i3cdev);

@@ -366,15 +441,20 @@ static int i3cdev_notifier_call(struct notifier_block *nb,
 	case BUS_NOTIFY_ADD_DEVICE:
 	case BUS_NOTIFY_UNBOUND_DRIVER:
 		return i3cdev_attach(dev, NULL);
+	case BUS_NOTIFY_BIND_DRIVER:
+		if (IS_ENABLED(CONFIG_I3CDEV_FORCE_CREATE))
+			break;
+
+		fallthrough;
 	case BUS_NOTIFY_DEL_DEVICE:
-	case BUS_NOTIFY_BOUND_DRIVER:
+	case BUS_NOTIFY_REMOVED_DEVICE:
 		return i3cdev_detach(dev, NULL);
 	}

 	return 0;
 }

-static struct notifier_block i3c_notifier = {
+static struct notifier_block i3cdev_notifier = {
 	.notifier_call = i3cdev_notifier_call,
 };

@@ -395,7 +475,7 @@ static int __init i3cdev_init(void)
 	}

 	/* Keep track of busses which have devices to add or remove later */
-	res = bus_register_notifier(&i3c_bus_type, &i3c_notifier);
+	res = bus_register_notifier(&i3c_bus_type, &i3cdev_notifier);
 	if (res)
 		goto out_unreg_class;

@@ -415,7 +495,7 @@ static int __init i3cdev_init(void)

 static void __exit i3cdev_exit(void)
 {
-	bus_unregister_notifier(&i3c_bus_type, &i3c_notifier);
+	bus_unregister_notifier(&i3c_bus_type, &i3cdev_notifier);
 	i3c_for_each_dev(NULL, i3cdev_detach);
 	class_destroy(i3cdev_class);
 	unregister_chrdev_region(i3cdev_number, I3C_MINORS);
diff --git a/drivers/i3c/internals.h b/drivers/i3c/internals.h
index a6deedf5ce06..a9c6979b31ca 100644
--- a/drivers/i3c/internals.h
+++ b/drivers/i3c/internals.h
@@ -9,6 +9,7 @@
 #define I3C_INTERNALS_H

 #include <linux/i3c/master.h>
+#include <linux/i3c/target.h>

 extern struct bus_type i3c_bus_type;
 extern const struct device_type i3c_masterdev_type;
@@ -19,10 +20,22 @@ void i3c_bus_normaluse_unlock(struct i3c_bus *bus);
 int i3c_dev_do_priv_xfers_locked(struct i3c_dev_desc *dev,
 				 struct i3c_priv_xfer *xfers,
 				 int nxfers);
+int i3c_master_send_hdr_cmds_locked(struct i3c_master_controller *master,
+				    struct i3c_hdr_cmd *cmds, int ncmds);
 int i3c_dev_disable_ibi_locked(struct i3c_dev_desc *dev);
 int i3c_dev_enable_ibi_locked(struct i3c_dev_desc *dev);
 int i3c_dev_request_ibi_locked(struct i3c_dev_desc *dev,
 			       const struct i3c_ibi_setup *req);
 void i3c_dev_free_ibi_locked(struct i3c_dev_desc *dev);
+int i3c_dev_send_ccc_cmd_locked(struct i3c_dev_desc *dev, u8 ccc_id);
+int i3c_dev_getstatus_locked(struct i3c_dev_desc *dev, struct i3c_device_info *info);
+int i3c_master_getmrl_locked(struct i3c_master_controller *master, struct i3c_device_info *info);
+int i3c_master_getmwl_locked(struct i3c_master_controller *master, struct i3c_device_info *info);
+int i3c_master_setmrl_locked(struct i3c_master_controller *master,
+			     struct i3c_device_info *info, u16 read_len, u8 ibi_len);
+int i3c_master_setmwl_locked(struct i3c_master_controller *master,
+			     struct i3c_device_info *info, u16 write_len);
 int i3c_for_each_dev(void *data, int (*fn)(struct device *, void *));
+int i3c_dev_generate_ibi_locked(struct i3c_dev_desc *dev, const u8 *data, int len);
+int i3c_dev_control_pec(struct i3c_dev_desc *dev, bool pec);
 #endif /* I3C_INTERNAL_H */
diff --git a/drivers/i3c/master.c b/drivers/i3c/master.c
index 6b5fb95f3c4f..78f9cd290d13 100644
--- a/drivers/i3c/master.c
+++ b/drivers/i3c/master.c
@@ -19,10 +19,9 @@

 #include "internals.h"

-#define I3C_MUX_SA 0x70
-
 static DEFINE_IDR(i3c_bus_idr);
 static DEFINE_MUTEX(i3c_core_lock);
+static int __i3c_first_dynamic_bus_num;

 /**
  * i3c_bus_maintenance_lock - Lock the bus for a maintenance operation
@@ -243,12 +242,52 @@ static ssize_t hdrcap_show(struct device *dev,
 }
 static DEVICE_ATTR_RO(hdrcap);

+static ssize_t modalias_show(struct device *dev,
+			     struct device_attribute *da, char *buf)
+{
+	struct i3c_device *i3c = dev_to_i3cdev(dev);
+	struct i3c_device_info devinfo;
+	u16 manuf, part, ext;
+
+	i3c_device_get_info(i3c, &devinfo);
+	manuf = I3C_PID_MANUF_ID(devinfo.pid);
+	part = I3C_PID_PART_ID(devinfo.pid);
+	ext = I3C_PID_EXTRA_INFO(devinfo.pid);
+
+	if (I3C_PID_RND_LOWER_32BITS(devinfo.pid))
+		return sprintf(buf, "i3c:dcr%02Xmanuf%04X", devinfo.dcr,
+			       manuf);
+
+	return sprintf(buf, "i3c:dcr%02Xmanuf%04Xpart%04xext%04x",
+		       devinfo.dcr, manuf, part, ext);
+}
+static DEVICE_ATTR_RO(modalias);
+
+static ssize_t bus_reset_store(struct device *dev, struct device_attribute *da,
+			       const char *buf, size_t count)
+{
+	struct i3c_master_controller *master;
+	ssize_t ret = count;
+
+	master = dev_to_i3cmaster(dev);
+	dev_dbg(&master->dev, "Reset bus to return to i2c_mode...\n");
+	i3c_bus_maintenance_lock(&master->bus);
+	if (master->ops->bus_reset)
+		master->ops->bus_reset(master);
+
+	i3c_bus_maintenance_unlock(&master->bus);
+
+	return ret;
+}
+static DEVICE_ATTR_WO(bus_reset);
+
 static struct attribute *i3c_device_attrs[] = {
 	&dev_attr_bcr.attr,
 	&dev_attr_dcr.attr,
 	&dev_attr_pid.attr,
 	&dev_attr_dynamic_address.attr,
 	&dev_attr_hdrcap.attr,
+	&dev_attr_modalias.attr,
 	NULL,
 };
 ATTRIBUTE_GROUPS(i3c_device);
@@ -278,19 +317,24 @@ static const struct device_type i3c_device_type = {
 	.uevent = i3c_device_uevent,
 };

+const struct device_type i3c_target_device_type = {
+};
+
 static int i3c_device_match(struct device *dev, struct device_driver *drv)
 {
 	struct i3c_device *i3cdev;
 	struct i3c_driver *i3cdrv;

-	if (dev->type != &i3c_device_type)
+	if (dev->type != &i3c_device_type && dev->type != &i3c_target_device_type)
 		return 0;

 	i3cdev = dev_to_i3cdev(dev);
 	i3cdrv = drv_to_i3cdrv(drv);
-	if (i3c_device_match_id(i3cdev, i3cdrv->id_table))
-		return 1;

+	if ((dev->type == &i3c_device_type && !i3cdrv->target) ||
+	    (dev->type == &i3c_target_device_type && i3cdrv->target))
+		if (i3c_device_match_id(i3cdev, i3cdrv->id_table))
+			return 1;
 	return 0;
 }

@@ -306,15 +350,14 @@ static int i3c_device_remove(struct device *dev)
 {
 	struct i3c_device *i3cdev = dev_to_i3cdev(dev);
 	struct i3c_driver *driver = drv_to_i3cdrv(dev->driver);
-	int ret;

-	ret = driver->remove(i3cdev);
-	if (ret)
-		return ret;
+	if (driver->remove)
+		driver->remove(i3cdev);

-	i3c_device_free_ibi(i3cdev);
+	if (!driver->target)
+		i3c_device_free_ibi(i3cdev);

-	return ret;
+    return 0;
 }

 struct bus_type i3c_bus_type = {
@@ -328,7 +371,8 @@ EXPORT_SYMBOL_GPL(i3c_bus_type);
 static enum i3c_addr_slot_status
 i3c_bus_get_addr_slot_status(struct i3c_bus *bus, u16 addr)
 {
-	int status, bitpos = addr * 2;
+	unsigned long status;
+	int bitpos = addr * 2;

 	if (addr > I2C_MAX_ADDR)
 		return I3C_ADDR_SLOT_RSVD;
@@ -403,9 +447,9 @@ static void i3c_bus_cleanup(struct i3c_bus *i3cbus)
 	mutex_unlock(&i3c_core_lock);
 }

-static int i3c_bus_init(struct i3c_bus *i3cbus)
+static int i3c_bus_init(struct i3c_bus *i3cbus, struct device_node *np)
 {
-	int ret;
+	int ret, start, end, id = -1;

 	init_rwsem(&i3cbus->lock);
 	INIT_LIST_HEAD(&i3cbus->devs.i2c);
@@ -413,8 +457,18 @@ static int i3c_bus_init(struct i3c_bus *i3cbus)
 	i3c_bus_init_addrslots(i3cbus);
 	i3cbus->mode = I3C_BUS_MODE_PURE;

+    if (np)
+        id = of_alias_get_id(np, "i3c");
+
 	mutex_lock(&i3c_core_lock);
-	ret = idr_alloc(&i3c_bus_idr, i3cbus, 0, 0, GFP_KERNEL);
+    if (id >= 0) {
+		start = id;
+		end = start + 1;
+	} else {
+		start = __i3c_first_dynamic_bus_num;
+		end = 0;
+	}
+	ret = idr_alloc(&i3c_bus_idr, i3cbus, start, end, GFP_KERNEL);
 	mutex_unlock(&i3c_core_lock);

 	if (ret < 0)
@@ -508,6 +562,7 @@ static struct attribute *i3c_masterdev_attrs[] = {
 	&dev_attr_pid.attr,
 	&dev_attr_dynamic_address.attr,
 	&dev_attr_hdrcap.attr,
+	&dev_attr_bus_reset.attr,
 	NULL,
 };
 ATTRIBUTE_GROUPS(i3c_masterdev);
@@ -532,7 +587,7 @@ const struct device_type i3c_masterdev_type = {
 EXPORT_SYMBOL_GPL(i3c_masterdev_type);

 static int i3c_bus_set_mode(struct i3c_bus *i3cbus, enum i3c_bus_mode mode,
-		     unsigned long max_i2c_scl_rate)
+			    unsigned long max_i2c_scl_rate)
 {
 	struct i3c_master_controller *master = i3c_bus_to_i3c_master(i3cbus);

@@ -594,7 +649,7 @@ static void i3c_master_free_i2c_dev(struct i2c_dev_desc *dev)

 static struct i2c_dev_desc *
 i3c_master_alloc_i2c_dev(struct i3c_master_controller *master,
-			 const struct i2c_dev_boardinfo *boardinfo)
+			 u16 addr, u8 lvr)
 {
 	struct i2c_dev_desc *dev;

@@ -603,9 +658,8 @@ i3c_master_alloc_i2c_dev(struct i3c_master_controller *master,
 		return ERR_PTR(-ENOMEM);

 	dev->common.master = master;
-	dev->boardinfo = boardinfo;
-	dev->addr = boardinfo->base.addr;
-	dev->lvr = boardinfo->lvr;
+	dev->addr = addr;
+	dev->lvr = lvr;

 	return dev;
 }
@@ -630,13 +684,15 @@ static void i3c_ccc_cmd_dest_cleanup(struct i3c_ccc_cmd_dest *dest)

 static void i3c_ccc_cmd_init(struct i3c_ccc_cmd *cmd, bool rnw, u8 id,
 			     struct i3c_ccc_cmd_dest *dests,
-			     unsigned int ndests)
+			     unsigned int ndests, bool dbp, u8 db)
 {
 	cmd->rnw = rnw ? 1 : 0;
 	cmd->id = id;
 	cmd->dests = dests;
 	cmd->ndests = ndests;
 	cmd->err = I3C_ERROR_UNKNOWN;
+	cmd->dbp = dbp;
+	cmd->db = db;
 }

 static int i3c_master_send_ccc_cmd_locked(struct i3c_master_controller *master,
@@ -679,7 +735,7 @@ i3c_master_find_i2c_dev_by_addr(const struct i3c_master_controller *master,
 	struct i2c_dev_desc *dev;

 	i3c_bus_for_each_i2cdev(&master->bus, dev) {
-		if (dev->boardinfo->base.addr == addr)
+		if (dev->addr == addr)
 			return dev;
 	}

@@ -735,7 +791,7 @@ i3c_master_alloc_i3c_dev(struct i3c_master_controller *master,
 	return dev;
 }

-static int i3c_master_rstdaa_locked(struct i3c_master_controller *master,
+int i3c_master_rstdaa_locked(struct i3c_master_controller *master,
 				    u8 addr)
 {
 	enum i3c_addr_slot_status addrstat;
@@ -753,12 +809,13 @@ static int i3c_master_rstdaa_locked(struct i3c_master_controller *master,
 	i3c_ccc_cmd_dest_init(&dest, addr, 0);
 	i3c_ccc_cmd_init(&cmd, false,
 			 I3C_CCC_RSTDAA(addr == I3C_BROADCAST_ADDR),
-			 &dest, 1);
+			 &dest, 1, false, 0);
 	ret = i3c_master_send_ccc_cmd_locked(master, &cmd);
 	i3c_ccc_cmd_dest_cleanup(&dest);

 	return ret;
 }
+EXPORT_SYMBOL_GPL(i3c_master_rstdaa_locked);

 /**
  * i3c_master_entdaa_locked() - start a DAA (Dynamic Address Assignment)
@@ -783,7 +840,7 @@ int i3c_master_entdaa_locked(struct i3c_master_controller *master)
 	int ret;

 	i3c_ccc_cmd_dest_init(&dest, I3C_BROADCAST_ADDR, 0);
-	i3c_ccc_cmd_init(&cmd, false, I3C_CCC_ENTDAA, &dest, 1);
+	i3c_ccc_cmd_init(&cmd, false, I3C_CCC_ENTDAA, &dest, 1, false, 0);
 	ret = i3c_master_send_ccc_cmd_locked(master, &cmd);
 	i3c_ccc_cmd_dest_cleanup(&dest);

@@ -808,7 +865,7 @@ static int i3c_master_enec_disec_locked(struct i3c_master_controller *master,
 			 enable ?
 			 I3C_CCC_ENEC(addr == I3C_BROADCAST_ADDR) :
 			 I3C_CCC_DISEC(addr == I3C_BROADCAST_ADDR),
-			 &dest, 1);
+			 &dest, 1, false, 0);
 	ret = i3c_master_send_ccc_cmd_locked(master, &cmd);
 	i3c_ccc_cmd_dest_cleanup(&dest);

@@ -941,7 +998,7 @@ int i3c_master_defslvs_locked(struct i3c_master_controller *master)
 		desc++;
 	}

-	i3c_ccc_cmd_init(&cmd, false, I3C_CCC_DEFSLVS, &dest, 1);
+	i3c_ccc_cmd_init(&cmd, false, I3C_CCC_DEFSLVS, &dest, 1, false, 0);
 	ret = i3c_master_send_ccc_cmd_locked(master, &cmd);
 	i3c_ccc_cmd_dest_cleanup(&dest);

@@ -949,6 +1006,35 @@ int i3c_master_defslvs_locked(struct i3c_master_controller *master)
 }
 EXPORT_SYMBOL_GPL(i3c_master_defslvs_locked);

+int i3c_master_devctrl_locked(struct i3c_master_controller *master,
+			      union devctrl_ctrl ctrl, u8 dev_id, bool pec_en,
+			      bool parity_dis, bool ibi_clr)
+{
+	struct i3c_ccc_cmd_dest dest;
+	struct i3c_ccc_devctrl *devctrl;
+	struct i3c_ccc_cmd cmd;
+	int ret;
+
+	dev_info(&master->dev, "%s()\n", __func__);
+	devctrl = i3c_ccc_cmd_dest_init(&dest, I3C_BROADCAST_ADDR,
+					sizeof(*devctrl));
+	if (!devctrl)
+		return -ENOMEM;
+
+	devctrl->ctrl.value = ctrl.value;
+	devctrl->dev_addr = dev_id << 1;
+	devctrl->data0 = pec_en << 7 | parity_dis << 6;
+	devctrl->data1 = ibi_clr << 3;
+	devctrl->data2 = 0;
+	devctrl->data3 = 0;
+	i3c_ccc_cmd_init(&cmd, false, I3C_CCC_DEVCTRL, &dest, 1, false, 0);
+	ret = i3c_master_send_ccc_cmd_locked(master, &cmd);
+	i3c_ccc_cmd_dest_cleanup(&dest);
+
+	return ret;
+}
+EXPORT_SYMBOL_GPL(i3c_master_devctrl_locked);
+
 static int i3c_master_setda_locked(struct i3c_master_controller *master,
 				   u8 oldaddr, u8 newaddr, bool setdasa)
 {
@@ -957,21 +1043,17 @@ static int i3c_master_setda_locked(struct i3c_master_controller *master,
 	struct i3c_ccc_cmd cmd;
 	int ret;

-	if (!oldaddr || !newaddr) {
-		pr_err( "i3c_master_setda_locked: Error " "No newaddr or Oldaddr\n" );
+	if (!oldaddr || !newaddr)
 		return -EINVAL;
-	}

 	setda = i3c_ccc_cmd_dest_init(&dest, oldaddr, sizeof(*setda));
-	if (!setda) {
-		pr_err( "i3c_master_setda_locked: Error " "No setda\n" );
+	if (!setda)
 		return -ENOMEM;
-	}

 	setda->addr = newaddr << 1;
 	i3c_ccc_cmd_init(&cmd, false,
 			 setdasa ? I3C_CCC_SETDASA : I3C_CCC_SETNEWDA,
-			 &dest, 1);
+			 &dest, 1, false, 0);
 	ret = i3c_master_send_ccc_cmd_locked(master, &cmd);
 	i3c_ccc_cmd_dest_cleanup(&dest);

@@ -985,7 +1067,7 @@ static int i3c_master_setaasa_locked(struct i3c_master_controller *master)
 	int ret;

 	i3c_ccc_cmd_dest_init(&dest, I3C_BROADCAST_ADDR, 0);
-	i3c_ccc_cmd_init(&cmd, false, I3C_CCC_SETAASA, &dest, 1);
+	i3c_ccc_cmd_init(&cmd, false, I3C_CCC_SETAASA, &dest, 1, false, 0);

 	ret = i3c_master_send_ccc_cmd_locked(master, &cmd);
 	i3c_ccc_cmd_dest_cleanup(&dest);
@@ -1013,13 +1095,11 @@ static int i3c_master_sethid_locked(struct i3c_master_controller *master)
 	int ret;

 	sethid = i3c_ccc_cmd_dest_init(&dest, I3C_BROADCAST_ADDR, 1);
-	if (!sethid)  {
-            pr_err( "i3c_master_sethid_locked: Error " "No sethid\n" );
-            return -ENOMEM;
-	}
+	if (!sethid)
+		return -ENOMEM;

 	sethid->hid = 0;
-	i3c_ccc_cmd_init(&cmd, false, I3C_CCC_SETHID, &dest, 1);
+	i3c_ccc_cmd_init(&cmd, false, I3C_CCC_SETHID, &dest, 1, false, 0);

 	ret = i3c_master_send_ccc_cmd_locked(master, &cmd);
 	i3c_ccc_cmd_dest_cleanup(&dest);
@@ -1027,8 +1107,7 @@ static int i3c_master_sethid_locked(struct i3c_master_controller *master)
 	return ret;
 }

-static int i3c_master_getmrl_locked(struct i3c_master_controller *master,
-				    struct i3c_device_info *info)
+int i3c_master_getmrl_locked(struct i3c_master_controller *master, struct i3c_device_info *info)
 {
 	struct i3c_ccc_cmd_dest dest;
 	struct i3c_ccc_mrl *mrl;
@@ -1036,10 +1115,8 @@ static int i3c_master_getmrl_locked(struct i3c_master_controller *master,
 	int ret;

 	mrl = i3c_ccc_cmd_dest_init(&dest, info->dyn_addr, sizeof(*mrl));
-	if (!mrl) {
-            pr_err( "i3c_master_getmrl_locked: Error " "No mrl\n" );
-            return -ENOMEM;
-	}
+	if (!mrl)
+		return -ENOMEM;

 	/*
 	 * When the device does not have IBI payload GETMRL only returns 2
@@ -1048,12 +1125,10 @@ static int i3c_master_getmrl_locked(struct i3c_master_controller *master,
 	if (!(info->bcr & I3C_BCR_IBI_PAYLOAD))
 		dest.payload.len -= 1;

-	i3c_ccc_cmd_init(&cmd, true, I3C_CCC_GETMRL, &dest, 1);
+	i3c_ccc_cmd_init(&cmd, true, I3C_CCC_GETMRL, &dest, 1, false, 0);
 	ret = i3c_master_send_ccc_cmd_locked(master, &cmd);
-	if (ret) {
-	    pr_err( "i3c_master_getmrl_locked: Error " "send_ccc_cmd ret %d\n", ret );
-	    goto out;
-	}
+	if (ret)
+		goto out;

 	switch (dest.payload.len) {
 	case 3:
@@ -1073,8 +1148,7 @@ static int i3c_master_getmrl_locked(struct i3c_master_controller *master,
 	return ret;
 }

-static int i3c_master_getmwl_locked(struct i3c_master_controller *master,
-				    struct i3c_device_info *info)
+int i3c_master_getmwl_locked(struct i3c_master_controller *master, struct i3c_device_info *info)
 {
 	struct i3c_ccc_cmd_dest dest;
 	struct i3c_ccc_mwl *mwl;
@@ -1082,20 +1156,15 @@ static int i3c_master_getmwl_locked(struct i3c_master_controller *master,
 	int ret;

 	mwl = i3c_ccc_cmd_dest_init(&dest, info->dyn_addr, sizeof(*mwl));
-	if (!mwl) {
-		pr_err( "i3c_master_getmwl_locked: Error " "No mwl\n" );
+	if (!mwl)
 		return -ENOMEM;
-	}

-	i3c_ccc_cmd_init(&cmd, true, I3C_CCC_GETMWL, &dest, 1);
+	i3c_ccc_cmd_init(&cmd, true, I3C_CCC_GETMWL, &dest, 1, false, 0);
 	ret = i3c_master_send_ccc_cmd_locked(master, &cmd);
-	if (ret) {
-		pr_err( "i3c_master_getmwl_locked: Error " "send_ccc_cmd ret %d\n", ret );
+	if (ret)
 		goto out;
-	}

 	if (dest.payload.len != sizeof(*mwl)) {
-		pr_err( "i3c_master_getmwl_locked: Error " "dest.payload is not the size of mwl\n" );
 		ret = -EIO;
 		goto out;
 	}
@@ -1108,6 +1177,61 @@ static int i3c_master_getmwl_locked(struct i3c_master_controller *master,
 	return ret;
 }

+int i3c_master_setmrl_locked(struct i3c_master_controller *master,
+			     struct i3c_device_info *info, u16 read_len, u8 ibi_len)
+{
+	struct i3c_ccc_cmd_dest dest;
+	struct i3c_ccc_cmd cmd;
+	struct i3c_ccc_mrl *mrl;
+	int ret;
+
+	mrl = i3c_ccc_cmd_dest_init(&dest, info->dyn_addr, sizeof(*mrl));
+	if (!mrl)
+		return -ENOMEM;
+
+	/*
+	 * When the device does not have IBI payload SETMRL only sends 2
+	 * bytes of data.
+	 */
+	if (!(info->bcr & I3C_BCR_IBI_PAYLOAD))
+		dest.payload.len -= 1;
+
+	mrl->read_len = cpu_to_be16(read_len);
+	mrl->ibi_len = ibi_len;
+	info->max_read_len = read_len;
+	info->max_ibi_len = mrl->ibi_len;
+	i3c_ccc_cmd_init(&cmd, false, I3C_CCC_SETMRL(false), &dest, 1, false,
+			 0);
+
+	ret = i3c_master_send_ccc_cmd_locked(master, &cmd);
+	i3c_ccc_cmd_dest_cleanup(&dest);
+
+	return ret;
+}
+
+int i3c_master_setmwl_locked(struct i3c_master_controller *master,
+			     struct i3c_device_info *info, u16 write_len)
+{
+	struct i3c_ccc_cmd_dest dest;
+	struct i3c_ccc_cmd cmd;
+	struct i3c_ccc_mwl *mwl;
+	int ret;
+
+	mwl = i3c_ccc_cmd_dest_init(&dest, info->dyn_addr, sizeof(*mwl));
+	if (!mwl)
+		return -ENOMEM;
+
+	mwl->len = cpu_to_be16(write_len);
+	info->max_write_len = write_len;
+	i3c_ccc_cmd_init(&cmd, false, I3C_CCC_SETMWL(false), &dest, 1, false,
+			 0);
+
+	ret = i3c_master_send_ccc_cmd_locked(master, &cmd);
+	i3c_ccc_cmd_dest_cleanup(&dest);
+
+	return ret;
+}
+
 static int i3c_master_getmxds_locked(struct i3c_master_controller *master,
 				     struct i3c_device_info *info)
 {
@@ -1118,20 +1242,15 @@ static int i3c_master_getmxds_locked(struct i3c_master_controller *master,

 	getmaxds = i3c_ccc_cmd_dest_init(&dest, info->dyn_addr,
 					 sizeof(*getmaxds));
-	if (!getmaxds) {
-		pr_err( "i3c_master_getmxds_locked: Error " "No getmaxds\n" );
+	if (!getmaxds)
 		return -ENOMEM;
-	}

-	i3c_ccc_cmd_init(&cmd, true, I3C_CCC_GETMXDS, &dest, 1);
+	i3c_ccc_cmd_init(&cmd, true, I3C_CCC_GETMXDS, &dest, 1, false, 0);
 	ret = i3c_master_send_ccc_cmd_locked(master, &cmd);
-	if (ret) {
-		pr_err( "i3c_master_getmxds_locked: Error " "send_ccc_cmd ret %d\n", ret );
+	if (ret)
 		goto out;
-	}

 	if (dest.payload.len != 2 && dest.payload.len != 5) {
-		pr_err( "i3c_master_getmxds_locked: Error " "dest.payload.len is not 2 or 5\n" );
 		ret = -EIO;
 		goto out;
 	}
@@ -1159,20 +1278,15 @@ static int i3c_master_gethdrcap_locked(struct i3c_master_controller *master,

 	gethdrcap = i3c_ccc_cmd_dest_init(&dest, info->dyn_addr,
 					  sizeof(*gethdrcap));
-	if (!gethdrcap) {
-		pr_err( "i3c_master_gethdrcap_locked: Error " "No gethdrcap\n" );
+	if (!gethdrcap)
 		return -ENOMEM;
-	}

-	i3c_ccc_cmd_init(&cmd, true, I3C_CCC_GETHDRCAP, &dest, 1);
+	i3c_ccc_cmd_init(&cmd, true, I3C_CCC_GETHDRCAP, &dest, 1, false, 0);
 	ret = i3c_master_send_ccc_cmd_locked(master, &cmd);
-	if (ret) {
-		pr_err( "i3c_master_gethdrcap_locked: Error " "send_ccc_cmd ret %d\n", ret );
+	if (ret)
 		goto out;
-	}

 	if (dest.payload.len != 1) {
-		pr_err( "i3c_master_gethdrcap_locked: Error " "dest.payload.len is not 1\n" );
 		ret = -EIO;
 		goto out;
 	}
@@ -1194,17 +1308,13 @@ static int i3c_master_getpid_locked(struct i3c_master_controller *master,
 	int ret, i;

 	getpid = i3c_ccc_cmd_dest_init(&dest, info->dyn_addr, sizeof(*getpid));
-	if (!getpid) {
-		pr_err( "i3c_master_getpid_locked: Error " "No getpid\n" );
+	if (!getpid)
 		return -ENOMEM;
-	}

-	i3c_ccc_cmd_init(&cmd, true, I3C_CCC_GETPID, &dest, 1);
+	i3c_ccc_cmd_init(&cmd, true, I3C_CCC_GETPID, &dest, 1, false, 0);
 	ret = i3c_master_send_ccc_cmd_locked(master, &cmd);
-	if (ret) {
-		pr_err( "i3c_master_getpid_locked: Error " "send_ccc_cmd ret %d\n", ret );
+	if (ret)
 		goto out;
-	}

 	info->pid = 0;
 	for (i = 0; i < sizeof(getpid->pid); i++) {
@@ -1228,17 +1338,13 @@ static int i3c_master_getbcr_locked(struct i3c_master_controller *master,
 	int ret;

 	getbcr = i3c_ccc_cmd_dest_init(&dest, info->dyn_addr, sizeof(*getbcr));
-	if (!getbcr) {
-		pr_err( "i3c_master_getbcr_locked: Error " "No getbcr\n" );
+	if (!getbcr)
 		return -ENOMEM;
-	}

-	i3c_ccc_cmd_init(&cmd, true, I3C_CCC_GETBCR, &dest, 1);
+	i3c_ccc_cmd_init(&cmd, true, I3C_CCC_GETBCR, &dest, 1, false, 0);
 	ret = i3c_master_send_ccc_cmd_locked(master, &cmd);
-	if (ret) {
-		pr_err( "i3c_master_getbcr_locked: Error " "send_ccc_cmd ret %d\n", ret );
+	if (ret)
 		goto out;
-	}

 	info->bcr = getbcr->bcr;

@@ -1257,17 +1363,13 @@ static int i3c_master_getdcr_locked(struct i3c_master_controller *master,
 	int ret;

 	getdcr = i3c_ccc_cmd_dest_init(&dest, info->dyn_addr, sizeof(*getdcr));
-	if (!getdcr) {
-		pr_err( "i3c_master_getdcr_locked: Error " "No getdcr\n" );
+	if (!getdcr)
 		return -ENOMEM;
-	}

-	i3c_ccc_cmd_init(&cmd, true, I3C_CCC_GETDCR, &dest, 1);
+	i3c_ccc_cmd_init(&cmd, true, I3C_CCC_GETDCR, &dest, 1, false, 0);
 	ret = i3c_master_send_ccc_cmd_locked(master, &cmd);
-	if (ret) {
-		pr_err( "i3c_master_getdcr_locked: Error " "send_ccc_cmd ret %d\n", ret );
+	if (ret)
 		goto out;
-	}

 	info->dcr = getdcr->dcr;

@@ -1277,27 +1379,51 @@ static int i3c_master_getdcr_locked(struct i3c_master_controller *master,
 	return ret;
 }

+int i3c_dev_getstatus_locked(struct i3c_dev_desc *dev,
+			     struct i3c_device_info *info)
+{
+	struct i3c_master_controller *master = i3c_dev_get_master(dev);
+	struct i3c_ccc_getstatus *getsts;
+	struct i3c_ccc_cmd_dest dest;
+	struct i3c_ccc_cmd cmd;
+	int ret;
+
+	getsts = i3c_ccc_cmd_dest_init(&dest, info->dyn_addr, sizeof(*getsts));
+	if (!getsts)
+		return -ENOMEM;
+
+	i3c_ccc_cmd_init(&cmd, true, I3C_CCC_GETSTATUS, &dest, 1, false, 0);
+	ret = i3c_master_send_ccc_cmd_locked(master, &cmd);
+	if (ret)
+		goto out;
+
+	info->status = getsts->status;
+
+out:
+	i3c_ccc_cmd_dest_cleanup(&dest);
+
+	return ret;
+}
+
 static int i3c_master_retrieve_dev_info(struct i3c_dev_desc *dev)
 {
 	struct i3c_master_controller *master = i3c_dev_get_master(dev);
 	enum i3c_addr_slot_status slot_status;
 	int ret;

-	if (!dev->info.dyn_addr) {
-		pr_err( "i3c_master_retrieve_locked: Error " "No dev.info.dyn_addr\n" );
+	if (!dev->info.dyn_addr)
 		return -EINVAL;
-	}

 	slot_status = i3c_bus_get_addr_slot_status(&master->bus,
 						   dev->info.dyn_addr);
 	if (slot_status == I3C_ADDR_SLOT_RSVD ||
-	    slot_status == I3C_ADDR_SLOT_I2C_DEV) {
-		pr_err( "i3c_master_retrieve_locked: Error " "Reserved Addr\n" );
+	    slot_status == I3C_ADDR_SLOT_I2C_DEV)
 		return -EINVAL;
-	}

-	if (master->jdec_spd) {
+	if (master->jdec_spd && dev->boardinfo) {
 		dev->info.pid = dev->boardinfo->pid;
+		dev->info.dcr = dev->boardinfo->dcr;
+		dev->info.bcr = dev->boardinfo->bcr;
 		return 0;
 	}

@@ -1363,10 +1489,8 @@ static int i3c_master_get_i3c_addrs(struct i3c_dev_desc *dev)
 	if (dev->info.static_addr) {
 		status = i3c_bus_get_addr_slot_status(&master->bus,
 						      dev->info.static_addr);
-		if (status != I3C_ADDR_SLOT_FREE) {
-			pr_err( "i3c_master_get_i3c_addr: Error " "i3c_bus_get_addr_slot_status 1 status %d\n" , status);
+		if (status != I3C_ADDR_SLOT_FREE)
 			return -EBUSY;
-		}

 		i3c_bus_set_addr_slot_status(&master->bus,
 					     dev->info.static_addr,
@@ -1383,10 +1507,8 @@ static int i3c_master_get_i3c_addrs(struct i3c_dev_desc *dev)
 	     dev->boardinfo->init_dyn_addr != dev->info.dyn_addr)) {
 		status = i3c_bus_get_addr_slot_status(&master->bus,
 						      dev->info.dyn_addr);
-		if (status != I3C_ADDR_SLOT_FREE) {
-			pr_err( "i3c_master_get_i3c_addr: Error " "i3c_bus_get_addr_slot_status 2 status %d\n" , status);
+		if (status != I3C_ADDR_SLOT_FREE)
 			goto err_release_static_addr;
-		}

 		i3c_bus_set_addr_slot_status(&master->bus, dev->info.dyn_addr,
 					     I3C_ADDR_SLOT_I3C_DEV);
@@ -1412,23 +1534,18 @@ static int i3c_master_attach_i3c_dev(struct i3c_master_controller *master,
 	 * We don't attach devices to the controller until they are
 	 * addressable on the bus.
 	 */
-	if (!dev->info.static_addr && !dev->info.dyn_addr) {
-		pr_err( "i3c_master_attach_i3c_dev: Error " "No i3c Addr\n" );
+	if (!dev->info.static_addr && !dev->info.dyn_addr)
 		return 0;
-	}

 	ret = i3c_master_get_i3c_addrs(dev);
-	if (ret) {
-		pr_err( "i3c_master_attach_i3c_dev: Error " "get_i3c_addr ret %d\n" , ret);
+	if (ret)
 		return ret;
-	}

 	/* Do not attach the master device itself. */
 	if (master->this != dev && master->ops->attach_i3c_dev) {
 		ret = master->ops->attach_i3c_dev(dev);
 		if (ret) {
 			i3c_master_put_i3c_addrs(dev);
-			pr_err( "i3c_master_attach_i3c_dev: Error " "attach_i3c_addrs ret %d\n" , ret);
 			return ret;
 		}
 	}
@@ -1445,23 +1562,25 @@ static int i3c_master_reattach_i3c_dev(struct i3c_dev_desc *dev,
 	enum i3c_addr_slot_status status;
 	int ret;

-	if (dev->info.dyn_addr != old_dyn_addr) {
+	if (dev->info.dyn_addr != old_dyn_addr &&
+	    (!dev->boardinfo ||
+	     dev->info.dyn_addr != dev->boardinfo->init_dyn_addr)) {
 		status = i3c_bus_get_addr_slot_status(&master->bus,
 						      dev->info.dyn_addr);
-		if (status != I3C_ADDR_SLOT_FREE) {
-			pr_err( "i3c_master_reattach_i3c_dev: Error " "I3C ADDR Slot Not Free\n" );
+		if (status != I3C_ADDR_SLOT_FREE)
 			return -EBUSY;
-		}
 		i3c_bus_set_addr_slot_status(&master->bus,
 					     dev->info.dyn_addr,
 					     I3C_ADDR_SLOT_I3C_DEV);
+		if (old_dyn_addr)
+			i3c_bus_set_addr_slot_status(&master->bus, old_dyn_addr,
+						     I3C_ADDR_SLOT_FREE);
 	}

 	if (master->ops->reattach_i3c_dev) {
 		ret = master->ops->reattach_i3c_dev(dev, old_dyn_addr);
 		if (ret) {
 			i3c_master_put_i3c_addrs(dev);
-			pr_err( "i3c_master_reattach_i3c_dev: Error " "reattach_i3c_dev ret %d\n" , ret);
 			return ret;
 		}
 	}
@@ -1488,10 +1607,8 @@ static int i3c_master_attach_i2c_dev(struct i3c_master_controller *master,

 	if (master->ops->attach_i2c_dev) {
 		ret = master->ops->attach_i2c_dev(dev);
-		if (ret) {
-			pr_err( "i3c_master_attach_i2c_dev: Error " "attach_i2c_dev ret %d\n" , ret);
+		if (ret)
 			return ret;
-		}
 	}

 	list_add_tail(&dev->common.node, &master->bus.devs.i2c);
@@ -1509,53 +1626,55 @@ static void i3c_master_detach_i2c_dev(struct i2c_dev_desc *dev)
 		master->ops->detach_i2c_dev(dev);
 }

-static int i3c_master_pre_assign_dyn_addr(struct i3c_dev_desc *dev)
+static int i3c_master_early_i3c_dev_add(struct i3c_master_controller *master,
+					  struct i3c_dev_boardinfo *boardinfo)
 {
-	struct i3c_master_controller *master = i3c_dev_get_master(dev);
+	struct i3c_device_info info = {
+		.static_addr = boardinfo->static_addr,
+	};
+	struct i3c_dev_desc *i3cdev;
 	int ret;

-	if (!dev->boardinfo || !dev->boardinfo->init_dyn_addr ||
-	    !dev->boardinfo->static_addr)
-		return -1;
+	i3cdev = i3c_master_alloc_i3c_dev(master, &info);
+	if (IS_ERR(i3cdev))
+		return -ENOMEM;

-	if (master->jdec_spd) {
-		dev->info.dyn_addr = dev->boardinfo->init_dyn_addr;
-		ret = i3c_master_reattach_i3c_dev(dev, dev->info.static_addr);
-		if(master->set_dasa) {
-			if(dev->info.static_addr !=  I3C_MUX_SA) { // Do Not issue SET DASA for I3C Mux
-				i3c_master_setdasa_locked(master, dev->info.static_addr, dev->boardinfo->init_dyn_addr);
-				pr_debug( "i3c_master_pre_assign_dyn_addr: Reattach Bus %x SA %x to DA %x\n",
-				master->bus.id, dev->info.static_addr, dev->boardinfo->init_dyn_addr );
-			}
-		}
-	} else {
-		ret = i3c_master_setdasa_locked(master, dev->info.static_addr,
-					dev->boardinfo->init_dyn_addr);
+	i3cdev->boardinfo = boardinfo;

-		if (ret) {
-			pr_err( "i3c_master_pre_assign_dyn_addr: Error " "setdasa ret %d\n", ret );
-			return ret;
-		}
+	ret = i3c_master_attach_i3c_dev(master, i3cdev);
+	if (ret)
+		goto err_free_dev;

-		dev->info.dyn_addr = dev->boardinfo->init_dyn_addr;
-			ret = i3c_master_reattach_i3c_dev(dev, 0);
+	/*
+	 * JESD403-1 devices only support SETAASA (will be called in do_daa)
+	 * Here we use SETDASA for non-JESD403-1 devices
+	 */
+	if (!I3C_DCR_IS_JESD403_COMPLIANT(i3cdev->boardinfo->dcr)) {
+		ret = i3c_master_setdasa_locked(
+			master, i3cdev->info.static_addr,
+			i3cdev->boardinfo->init_dyn_addr);
+		if (ret)
+			goto err_detach_dev;
 	}

-	if (ret) {
-		pr_err( "i3c_master_pre_assign_dyn_addr: Error " " reattach ret %d\n", ret );
+	i3cdev->info.dyn_addr = i3cdev->boardinfo->init_dyn_addr;
+	ret = i3c_master_reattach_i3c_dev(i3cdev, 0);
+	if (ret)
 		goto err_rstdaa;
-	}

-	ret = i3c_master_retrieve_dev_info(dev);
-	if (ret) {
-		pr_err( "i3c_master_pre_assign_dyn_addr: Error " "retrieve ret %d\n", ret );
+	ret = i3c_master_retrieve_dev_info(i3cdev);
+	if (ret)
 		goto err_rstdaa;
-	}

 	return 0;

 err_rstdaa:
-	i3c_master_rstdaa_locked(master, dev->boardinfo->init_dyn_addr);
+	i3c_master_rstdaa_locked(master, i3cdev->boardinfo->init_dyn_addr);
+err_detach_dev:
+	i3c_master_detach_i3c_dev(i3cdev);
+err_free_dev:
+	i3c_master_free_i3c_dev(i3cdev);
+
 	return ret;
 }

@@ -1589,11 +1708,9 @@ i3c_master_register_new_i3c_devs(struct i3c_master_controller *master)
 			desc->dev->dev.of_node = desc->boardinfo->of_node;

 		ret = device_register(&desc->dev->dev);
-		if (ret) {
-			pr_err( "i3c_master_register_new_i3c_devs: Error " "Failed to add I3C device ret %d", ret );
+		if (ret)
 			dev_err(&master->dev,
 				"Failed to add I3C device (err = %d)\n", ret);
-		}
 	}
 }

@@ -1615,24 +1732,17 @@ i3c_master_register_new_i3c_devs(struct i3c_master_controller *master)
 int i3c_master_do_daa(struct i3c_master_controller *master)
 {
 	int ret;
+
+	i3c_bus_maintenance_lock(&master->bus);
 	if (master->jdec_spd) {
-		ret = i3c_master_sethid_locked(master);
-		if(ret)
-            pr_err( "i3c_master_do_daa: Error " " SETHID bus %d, ret %d\n",master->bus.id, ret );
-		ret = i3c_master_setaasa_locked(master);
-		if(ret)
-            pr_err( "i3c_master_do_daa: Error" " SETAASA bus %d, ret %d\n",master->bus.id, ret );
-	}
-	else {
-		i3c_bus_maintenance_lock(&master->bus);
+		i3c_master_sethid_locked(master);
+		i3c_master_setaasa_locked(master);
+	} else
 		ret = master->ops->do_daa(master);
-		i3c_bus_maintenance_unlock(&master->bus);
-	}
+	i3c_bus_maintenance_unlock(&master->bus);

-	if (ret) {
-		pr_err( "i3c_master_do_daa: Error " " bus %d, ret %d\n",master->bus.id, ret );
+	if (ret)
 		return ret;
-	}

 	i3c_bus_normaluse_lock(&master->bus);
 	i3c_master_register_new_i3c_devs(master);
@@ -1642,6 +1752,29 @@ int i3c_master_do_daa(struct i3c_master_controller *master)
 }
 EXPORT_SYMBOL_GPL(i3c_master_do_daa);

+/**
+ * i3c_master_enable_hj() - enable hot-join
+ * @master: master broadcast the enec ccc to enable hot-join.
+ *
+ * This function must be called after the master init done to satisfy
+ * the description "Hot-Join does not allow Targets to join the I3C
+ * Bus before the I3C Bus has been configured." in i3c specification.
+ *
+ * Return: a 0 in case of success, an negative error code otherwise.
+ */
+int i3c_master_enable_hj(struct i3c_master_controller *master)
+{
+	if (!master->init_done)
+		return -ENOPROTOOPT;
+
+	i3c_bus_maintenance_lock(&master->bus);
+	i3c_master_enec_locked(master, I3C_BROADCAST_ADDR, I3C_CCC_EVENT_HJ);
+	i3c_bus_maintenance_unlock(&master->bus);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(i3c_master_enable_hj);
+
 /**
  * i3c_master_set_info() - set master device information
  * @master: master used to send frames on the bus
@@ -1675,10 +1808,6 @@ int i3c_master_set_info(struct i3c_master_controller *master,
 	if (!i3c_bus_dev_addr_is_avail(&master->bus, info->dyn_addr))
 		return -EINVAL;

-	if (I3C_BCR_DEVICE_ROLE(info->bcr) == I3C_BCR_I3C_MASTER &&
-	    master->secondary)
-		return -EINVAL;
-
 	if (master->this)
 		return -EINVAL;

@@ -1687,7 +1816,10 @@ int i3c_master_set_info(struct i3c_master_controller *master,
 		return PTR_ERR(i3cdev);

 	master->this = i3cdev;
-	master->bus.cur_master = master->this;
+	if (master->secondary)
+		master->bus.cur_master = NULL;
+	else
+		master->bus.cur_master = master->this;

 	ret = i3c_master_attach_i3c_dev(master, i3cdev);
 	if (ret)
@@ -1736,8 +1868,8 @@ static void i3c_master_detach_free_devs(struct i3c_master_controller *master)
  * This function is following all initialisation steps described in the I3C
  * specification:
  *
- * 1. Attach I2C and statically defined I3C devs to the master so that the
- *    master can fill its internal device table appropriately
+ * 1. Attach I2C devs to the master so that the master can fill its internal
+ *    device table appropriately
  *
  * 2. Call &i3c_master_controller_ops->bus_init() method to initialize
  *    the master controller. That's usually where the bus mode is selected
@@ -1749,8 +1881,10 @@ static void i3c_master_detach_free_devs(struct i3c_master_controller *master)
  *
  * 4. Disable all slave events.
  *
- * 5. Pre-assign dynamic addresses requested by the FW with SETDASA for I3C
- *    devices that have a static address
+ * 5. Reserve address slots for I3C devices with init_dyn_addr. And if devices
+ *    also have static_addr, try to pre-assign dynamic addresses requested by
+ *    the FW with SETDASA and attach corresponding statically defined I3C
+ *    devices to the master.
  *
  * 6. Do a DAA (Dynamic Address Assignment) to assign dynamic addresses to all
  *    remaining I3C devices
@@ -1764,20 +1898,17 @@ static int i3c_master_bus_init(struct i3c_master_controller *master)
 	enum i3c_addr_slot_status status;
 	struct i2c_dev_boardinfo *i2cboardinfo;
 	struct i3c_dev_boardinfo *i3cboardinfo;
-	struct i3c_dev_desc *i3cdev, *i3ctmp;
 	struct i2c_dev_desc *i2cdev;
-	int ret, n_i3cdev = 0;
+	int ret;

 	/*
 	 * First attach all devices with static definitions provided by the
 	 * FW.
 	 */
-	pr_info( "i3c_master_bus_init: Start " "bus %d\n",master->bus.id );
 	list_for_each_entry(i2cboardinfo, &master->boardinfo.i2c, node) {
 		status = i3c_bus_get_addr_slot_status(&master->bus,
 						      i2cboardinfo->base.addr);
 		if (status != I3C_ADDR_SLOT_FREE) {
-			pr_err( "i3c_master_bus_init: Error " "i3c bus status, bus %d, status %d\n",master->bus.id, status );
 			ret = -EBUSY;
 			goto err_detach_devs;
 		}
@@ -1786,120 +1917,115 @@ static int i3c_master_bus_init(struct i3c_master_controller *master)
 					     i2cboardinfo->base.addr,
 					     I3C_ADDR_SLOT_I2C_DEV);

-		i2cdev = i3c_master_alloc_i2c_dev(master, i2cboardinfo);
+		i2cdev = i3c_master_alloc_i2c_dev(master,
+						  i2cboardinfo->base.addr,
+						  i2cboardinfo->lvr);
 		if (IS_ERR(i2cdev)) {
 			ret = PTR_ERR(i2cdev);
-			pr_err( "i3c_master_bus_init: Error " "i2cdev Not free, bus %d, ret %d\n",master->bus.id, ret );
 			goto err_detach_devs;
 		}

 		ret = i3c_master_attach_i2c_dev(master, i2cdev);
 		if (ret) {
-			pr_err( "i3c_master_bus_init: Error " "attach_i2c_dev, bus %d, ret %d\n",master->bus.id, ret );
 			i3c_master_free_i2c_dev(i2cdev);
 			goto err_detach_devs;
 		}
 	}
-	list_for_each_entry(i3cboardinfo, &master->boardinfo.i3c, node) {
-		struct i3c_device_info info = {
-			.static_addr = i3cboardinfo->static_addr,
-		};
-
-		if (i3cboardinfo->init_dyn_addr) {
-			status = i3c_bus_get_addr_slot_status(&master->bus,
-						i3cboardinfo->init_dyn_addr);
-			if (status != I3C_ADDR_SLOT_FREE) {
-				pr_err( "i3c_master_bus_init: Error " "I3C ADDR Slot not Free, bus %d, status %d\n",master->bus.id, status );
-				ret = -EBUSY;
-				goto err_detach_devs;
-			}
-		}
-
-		i3cdev = i3c_master_alloc_i3c_dev(master, &info);
-		if (IS_ERR(i3cdev)) {
-			ret = PTR_ERR(i3cdev);
-			pr_err( "i3c_master_bus_init: Error " "Error with i3cdev bus %d, ret %d\n",master->bus.id , ret);
-			goto err_detach_devs;
-		}
-
-		i3cdev->boardinfo = i3cboardinfo;
-
-		ret = i3c_master_attach_i3c_dev(master, i3cdev);
-		if (ret) {
-			pr_err( "i3c_master_bus_init: Error " "attach_i3c_dev, bus %d, ret %d\n",master->bus.id, ret );
-			i3c_master_free_i3c_dev(i3cdev);
-			goto err_detach_devs;
-		}
-	}

 	/*
 	 * Now execute the controller specific ->bus_init() routine, which
 	 * might configure its internal logic to match the bus limitations.
 	 */
 	ret = master->ops->bus_init(master);
-	if (ret) {
-		pr_err( "i3c_master_bus_init: Error " "in bus_init, bus %d, ret %d\n",master->bus.id, ret );
+	if (ret)
 		goto err_detach_devs;
-	}

 	/*
 	 * The master device should have been instantiated in ->bus_init(),
 	 * complain if this was not the case.
 	 */
 	if (!master->this) {
-		pr_err( "i3c_master_bus_init: Error " " master_set_info() was not called in ->bus_init()\n");
+		dev_err(&master->dev,
+			"master_set_info() was not called in ->bus_init()\n");
 		ret = -EINVAL;
 		goto err_bus_cleanup;
 	}

+	if (master->secondary)
+		return 0;
+
+	/*
+	 * Not support mix mode on JEDEC bus context. Here We only handle
+	 * the I2C part so simply return with success code.
+	 */
+	if (master->jdec_spd && master->bus.mode != I3C_BUS_MODE_PURE)
+		return 0;
+
 	/*
 	 * Reset all dynamic address that may have been assigned before
 	 * (assigned by the bootloader for example).
 	 */
 	ret = i3c_master_rstdaa_locked(master, I3C_BROADCAST_ADDR);
-	if (ret && ret != I3C_ERROR_M2) {
-		pr_err( "i3c_master_bus_init: Error " "RSTDAA bus %d, ret %d\n",master->bus.id, ret );
+	if (ret && ret != I3C_ERROR_M2)
 		goto err_bus_cleanup;
-	}

 	/* Disable all slave events before starting DAA. */
 	ret = i3c_master_disec_locked(master, I3C_BROADCAST_ADDR,
 				      I3C_CCC_EVENT_SIR | I3C_CCC_EVENT_MR |
 				      I3C_CCC_EVENT_HJ);
-	if (ret && ret != I3C_ERROR_M2) {
-		pr_err( "i3c_master_bus_init: Error " "DISEC bus %d, ret %d\n",master->bus.id, ret );
+	if (ret && ret != I3C_ERROR_M2)
 		goto err_bus_cleanup;
-	}

 	/*
-	 * Pre-assign dynamic address and retrieve device information if
-	 * needed.
+	 * Reserve init_dyn_addr first, and then try to pre-assign dynamic
+	 * address and retrieve device information if needed.
+	 * In case pre-assign dynamic address fails, setting dynamic address to
+	 * the requested init_dyn_addr is retried after DAA is done in
+	 * i3c_master_add_i3c_dev_locked().
 	 */
-	list_for_each_entry_safe(i3cdev, i3ctmp, &master->bus.devs.i3c,
-				 common.node) {
-		ret = i3c_master_pre_assign_dyn_addr(i3cdev);
-		if (ret) {
-			i3c_master_detach_i3c_dev(i3cdev);
-			i3c_master_free_i3c_dev(i3cdev);
-		} else {
-			n_i3cdev++;
-		}
-	}
+	list_for_each_entry(i3cboardinfo, &master->boardinfo.i3c, node) {

-	/*
-	 * Since SPD devices are all with static address.  Don't do DAA if we
-	 * know it is a pure I2C bus.
-	*/
-    if ((master->jdec_spd) && (n_i3cdev == 0)) {
-        pr_debug( "i3c_master_bus_init: " " bus %d, return n_i3cdev %d\n",master->bus.id, n_i3cdev);
-		return 0;
-	}
+		/*
+		 * We don't reserve a dynamic address for devices that
+		 * don't explicitly request one.
+		 */
+		if (!i3cboardinfo->init_dyn_addr)
+			continue;

-	ret = i3c_master_do_daa(master);
-	if (ret) {
-		pr_err( "i3c_master_bus_init: Error " "do_daa , bus %d, ret %d\n",master->bus.id, ret);
-		goto err_rstdaa;
-	}
+		ret = i3c_bus_get_addr_slot_status(&master->bus,
+						   i3cboardinfo->init_dyn_addr);
+		if (ret != I3C_ADDR_SLOT_FREE) {
+			ret = -EBUSY;
+			goto err_rstdaa;
+		}
+
+		/*
+		 * If the static address equals to the assigned dynamic address,
+		 * don't reserve the address slot here, it will be set after the
+		 * DA has been assigned.
+		 */
+		if (i3cboardinfo->static_addr != i3cboardinfo->init_dyn_addr)
+			i3c_bus_set_addr_slot_status(
+				&master->bus, i3cboardinfo->init_dyn_addr,
+				I3C_ADDR_SLOT_I3C_DEV);
+
+		/*
+		 * Only try to create/attach devices that have a static
+		 * address. Other devices will be created/attached when
+		 * DAA happens, and the requested dynamic address will
+		 * be set using SETNEWDA once those devices become
+		 * addressable.
+		 */
+
+		if (i3cboardinfo->static_addr)
+			i3c_master_early_i3c_dev_add(master, i3cboardinfo);
+	}
+
+	ret = i3c_master_do_daa(master);
+	if (ret)
+		dev_dbg(&master->dev,
+			"Failed to do DAA: %d. However, devices with static address can still be accessed\n",
+			ret);

 	return 0;

@@ -1924,10 +2050,25 @@ static void i3c_master_bus_cleanup(struct i3c_master_controller *master)
 	i3c_master_detach_free_devs(master);
 }

+static void i3c_master_attach_boardinfo(struct i3c_dev_desc *i3cdev)
+{
+	struct i3c_master_controller *master = i3cdev->common.master;
+	struct i3c_dev_boardinfo *i3cboardinfo;
+
+	list_for_each_entry(i3cboardinfo, &master->boardinfo.i3c, node) {
+		if (i3cdev->info.pid != i3cboardinfo->pid)
+			continue;
+
+		i3cdev->boardinfo = i3cboardinfo;
+		i3cdev->info.static_addr = i3cboardinfo->static_addr;
+		return;
+	}
+}
+
 static struct i3c_dev_desc *
 i3c_master_search_i3c_dev_duplicate(struct i3c_dev_desc *refdev)
 {
-	struct i3c_master_controller *master = refdev->common.master;
+	struct i3c_master_controller *master = i3c_dev_get_master(refdev);
 	struct i3c_dev_desc *i3cdev;

 	i3c_bus_for_each_i3cdev(&master->bus, i3cdev) {
@@ -1979,10 +2120,10 @@ int i3c_master_add_i3c_dev_locked(struct i3c_master_controller *master,
 	if (ret)
 		goto err_detach_dev;

+	i3c_master_attach_boardinfo(newdev);
+
 	olddev = i3c_master_search_i3c_dev_duplicate(newdev);
 	if (olddev) {
-		newdev->boardinfo = olddev->boardinfo;
-		newdev->info.static_addr = olddev->info.static_addr;
 		newdev->dev = olddev->dev;
 		if (newdev->dev)
 			newdev->dev->desc = newdev;
@@ -2007,6 +2148,16 @@ int i3c_master_add_i3c_dev_locked(struct i3c_master_controller *master,
 			i3c_dev_free_ibi_locked(olddev);
 		}
 		mutex_unlock(&olddev->ibi_lock);
+		if (olddev->info.max_ibi_len != newdev->info.max_ibi_len ||
+		    olddev->info.max_read_len != newdev->info.max_read_len)
+			i3c_master_setmrl_locked(master, &newdev->info,
+					      olddev->info.max_read_len,
+					      olddev->info.max_ibi_len);
+		if (olddev->info.max_write_len != newdev->info.max_write_len)
+			i3c_master_setmwl_locked(master, &newdev->info,
+					      olddev->info.max_write_len);
+		if (olddev->info.pec != newdev->info.pec)
+			i3c_device_control_pec(newdev->dev, olddev->info.pec);

 		old_dyn_addr = olddev->info.dyn_addr;

@@ -2014,10 +2165,6 @@ int i3c_master_add_i3c_dev_locked(struct i3c_master_controller *master,
 		i3c_master_free_i3c_dev(olddev);
 	}

-	ret = i3c_master_reattach_i3c_dev(newdev, old_dyn_addr);
-	if (ret)
-		goto err_detach_dev;
-
 	/*
 	 * Depending on our previous state, the expected dynamic address might
 	 * differ:
@@ -2117,7 +2264,7 @@ of_i3c_master_add_i2c_boardinfo(struct i3c_master_controller *master,
 	 * DEFSLVS command.
 	 */
 	if (boardinfo->base.flags & I2C_CLIENT_TEN) {
-		dev_err(&master->dev, "I2C device with 10 bit address not supported.");
+		dev_err(dev, "I2C device with 10 bit address not supported.");
 		return -ENOTSUPP;
 	}

@@ -2138,6 +2285,8 @@ of_i3c_master_add_i3c_boardinfo(struct i3c_master_controller *master,
 	struct device *dev = &master->dev;
 	enum i3c_addr_slot_status addrstatus;
 	u32 init_dyn_addr = 0;
+	u32 bcr = 0;
+	u32 dcr = 0;

 	boardinfo = devm_kzalloc(dev, sizeof(*boardinfo), GFP_KERNEL);
 	if (!boardinfo)
@@ -2171,6 +2320,16 @@ of_i3c_master_add_i3c_boardinfo(struct i3c_master_controller *master,
 	    I3C_PID_RND_LOWER_32BITS(boardinfo->pid))
 		return -EINVAL;

+	if (!of_property_read_u32(node, "dcr", &dcr)) {
+		if (dcr > I3C_DCR_MAX)
+			return -EINVAL;
+
+		boardinfo->dcr = dcr;
+	}
+
+	if (!of_property_read_u32(node, "bcr", &bcr))
+		boardinfo->bcr = bcr;
+
 	boardinfo->init_dyn_addr = init_dyn_addr;
 	boardinfo->of_node = of_node_get(node);
 	list_add_tail(&boardinfo->node, &master->boardinfo.i3c);
@@ -2208,7 +2367,7 @@ static int of_populate_i3c_bus(struct i3c_master_controller *master)
 	struct device *dev = &master->dev;
 	struct device_node *i3cbus_np = dev->of_node;
 	struct device_node *node;
-	int ret;
+	int ret, i;
 	u32 val;

 	if (!i3cbus_np)
@@ -2217,17 +2376,21 @@ static int of_populate_i3c_bus(struct i3c_master_controller *master)
 	if (of_get_property(i3cbus_np, "jdec-spd", NULL)) {
 		master->jdec_spd = 1;
 	}
-	if (of_get_property(i3cbus_np, "set_dasa", NULL)) {
-		master->set_dasa = 1;
-	}

-	ret = of_property_read_u32(i3cbus_np, "bus_id", &master->bus.id);
+	/* For SPD bus, undo unnecessary address reservations. */
+	if (master->jdec_spd) {
+		for (i = 0; i < 7; i++)
+			i3c_bus_set_addr_slot_status(&master->bus, I3C_BROADCAST_ADDR ^ BIT(i),
+						     I3C_ADDR_SLOT_FREE);
+	}

 	for_each_available_child_of_node(i3cbus_np, node) {
-		ret = of_i3c_master_add_dev(master, node);
-		if (ret) {
-			of_node_put(node);
-			return ret;
+		if (node->name && of_node_cmp(node->name, "hub")) {
+			ret = of_i3c_master_add_dev(master, node);
+			if (ret) {
+				of_node_put(node);
+				return ret;
+			}
 		}
 	}

@@ -2282,15 +2445,127 @@ static u32 i3c_master_i2c_funcs(struct i2c_adapter *adapter)
 	return I2C_FUNC_SMBUS_EMUL | I2C_FUNC_I2C;
 }

+static u8 i3c_master_i2c_get_lvr(struct i2c_client *client)
+{
+	/* Fall back to no spike filters and FM bus mode. */
+	u8 lvr = I3C_LVR_I2C_INDEX(2) | I3C_LVR_I2C_FM_MODE;
+
+	if (client->dev.of_node) {
+		u32 reg[3];
+
+		if (!of_property_read_u32_array(client->dev.of_node, "reg",
+						reg, ARRAY_SIZE(reg)))
+			lvr = reg[2];
+	}
+
+	return lvr;
+}
+
+static int i3c_master_i2c_attach(struct i2c_adapter *adap, struct i2c_client *client)
+{
+	struct i3c_master_controller *master = i2c_adapter_to_i3c_master(adap);
+	enum i3c_addr_slot_status status;
+	struct i2c_dev_desc *i2cdev;
+	int ret;
+
+	/* Already added by board info? */
+	if (i3c_master_find_i2c_dev_by_addr(master, client->addr))
+		return 0;
+
+	status = i3c_bus_get_addr_slot_status(&master->bus, client->addr);
+	if (status != I3C_ADDR_SLOT_FREE)
+		return -EBUSY;
+
+	i3c_bus_set_addr_slot_status(&master->bus, client->addr,
+				     I3C_ADDR_SLOT_I2C_DEV);
+
+	i2cdev = i3c_master_alloc_i2c_dev(master, client->addr,
+					  i3c_master_i2c_get_lvr(client));
+	if (IS_ERR(i2cdev)) {
+		ret = PTR_ERR(i2cdev);
+		goto out_clear_status;
+	}
+
+	ret = i3c_master_attach_i2c_dev(master, i2cdev);
+	if (ret)
+		goto out_free_dev;
+
+	return 0;
+
+out_free_dev:
+	i3c_master_free_i2c_dev(i2cdev);
+out_clear_status:
+	i3c_bus_set_addr_slot_status(&master->bus, client->addr,
+				     I3C_ADDR_SLOT_FREE);
+
+	return ret;
+}
+
+static int i3c_master_i2c_detach(struct i2c_adapter *adap, struct i2c_client *client)
+{
+	struct i3c_master_controller *master = i2c_adapter_to_i3c_master(adap);
+	struct i2c_dev_desc *dev;
+
+	dev = i3c_master_find_i2c_dev_by_addr(master, client->addr);
+	if (!dev)
+		return -ENODEV;
+
+	i3c_master_detach_i2c_dev(dev);
+	i3c_bus_set_addr_slot_status(&master->bus, dev->addr,
+				     I3C_ADDR_SLOT_FREE);
+	i3c_master_free_i2c_dev(dev);
+
+	return 0;
+}
+
 static const struct i2c_algorithm i3c_master_i2c_algo = {
 	.master_xfer = i3c_master_i2c_adapter_xfer,
 	.functionality = i3c_master_i2c_funcs,
 };

+static int i3c_i2c_notifier_call(struct notifier_block *nb, unsigned long action,
+				 void *data)
+{
+	struct i2c_adapter *adap;
+	struct i2c_client *client;
+	struct device *dev = data;
+	struct i3c_master_controller *master;
+	int ret;
+
+	if (dev->type != &i2c_client_type)
+		return 0;
+
+	client = to_i2c_client(dev);
+	adap = client->adapter;
+
+	if (adap->algo != &i3c_master_i2c_algo)
+		return 0;
+
+	master = i2c_adapter_to_i3c_master(adap);
+
+	i3c_bus_maintenance_lock(&master->bus);
+	switch (action) {
+	case BUS_NOTIFY_ADD_DEVICE:
+		ret = i3c_master_i2c_attach(adap, client);
+		break;
+	case BUS_NOTIFY_DEL_DEVICE:
+		ret = i3c_master_i2c_detach(adap, client);
+		break;
+	}
+	i3c_bus_maintenance_unlock(&master->bus);
+
+	return ret;
+}
+
+static struct notifier_block i2cdev_notifier = {
+	.notifier_call = i3c_i2c_notifier_call,
+};
+
 static int i3c_master_i2c_adapter_init(struct i3c_master_controller *master)
 {
 	struct i2c_adapter *adap = i3c_master_to_i2c_adapter(master);
 	struct i2c_dev_desc *i2cdev;
+	struct i2c_dev_boardinfo *i2cboardinfo;
 	int ret;

 	adap->dev.parent = master->dev.parent;
@@ -2310,8 +2585,13 @@ static int i3c_master_i2c_adapter_init(struct i3c_master_controller *master)
 	 * We silently ignore failures here. The bus should keep working
 	 * correctly even if one or more i2c devices are not registered.
 	 */
-	i3c_bus_for_each_i2cdev(&master->bus, i2cdev)
-		i2cdev->dev = i2c_new_client_device(adap, &i2cdev->boardinfo->base);
+	list_for_each_entry(i2cboardinfo, &master->boardinfo.i2c, node) {
+		i2cdev = i3c_master_find_i2c_dev_by_addr(master,
+							 i2cboardinfo->base.addr);
+		if (WARN_ON(!i2cdev))
+			continue;
+		i2cdev->dev = i2c_new_client_device(adap, &i2cboardinfo->base);
+	}

 	return 0;
 }
@@ -2586,17 +2866,10 @@ int i3c_master_register(struct i3c_master_controller *master,
 	struct i2c_dev_boardinfo *i2cbi;
 	int ret;

-	/* We do not support secondary masters yet. */
-	if (secondary) {
-            pr_err( "i3c_master_register: Error " " secondary bus %d\n",master->bus.id );
-            return -ENOTSUPP;
-	}

 	ret = i3c_master_check_ops(ops);
-	if (ret) {
-            pr_err( "i3c_master_register: Error " " check_ops bus %d, ret %d\n",master->bus.id, ret );
-            return ret;
-	}
+	if (ret)
+		return ret;

 	master->dev.parent = parent;
 	master->dev.of_node = of_node_get(parent->of_node);
@@ -2608,20 +2881,16 @@ int i3c_master_register(struct i3c_master_controller *master,
 	INIT_LIST_HEAD(&master->boardinfo.i2c);
 	INIT_LIST_HEAD(&master->boardinfo.i3c);

-	ret = i3c_bus_init(i3cbus);
-	if (ret) {
-            pr_err( "i3c_master_register: Error " " bus_init bus %d, ret %d\n",master->bus.id, ret );
-            return ret;
-	}
+	ret = i3c_bus_init(i3cbus, master->dev.of_node);
+	if (ret)
+		return ret;

 	device_initialize(&master->dev);
 	dev_set_name(&master->dev, "i3c-%d", i3cbus->id);

 	ret = of_populate_i3c_bus(master);
-	if (ret) {
-            pr_err( "i3c_master_register: Error " " 0f_populate_i3c_bus bus %d, ret %d\n",master->bus.id, ret );
-            goto err_put_dev;
-	}
+	if (ret)
+		goto err_put_dev;

 	list_for_each_entry(i2cbi, &master->boardinfo.i2c, node) {
 		switch (i2cbi->lvr & I3C_LVR_I2C_INDEX_MASK) {
@@ -2638,7 +2907,6 @@ int i3c_master_register(struct i3c_master_controller *master,
 				mode = I3C_BUS_MODE_MIXED_SLOW;
 			break;
 		default:
-			pr_err( "i3c_master_register: Error " " Default list bus %d\n",master->bus.id );
 			ret = -EINVAL;
 			goto err_put_dev;
 		}
@@ -2648,47 +2916,47 @@ int i3c_master_register(struct i3c_master_controller *master,
 	}

 	ret = i3c_bus_set_mode(i3cbus, mode, i2c_scl_rate);
-	if (ret) {
-            pr_err( "i3c_master_register: Error " " set_mode bus %d, ret %d\n",master->bus.id, ret );
-            goto err_put_dev;
-	}
+	if (ret)
+		goto err_put_dev;

 	master->wq = alloc_workqueue("%s", 0, 0, dev_name(parent));
 	if (!master->wq) {
-		pr_err( "i3c_master_register: Error " " alloc_workqueue bus %d\n",master->bus.id );
 		ret = -ENOMEM;
 		goto err_put_dev;
 	}

 	ret = i3c_master_bus_init(master);
-	if (ret) {
-		pr_err( "i3c_master_register: Error " " bus_init bus %d, ret %d\n",master->bus.id, ret );
+	if (ret)
 		goto err_put_dev;
-	}

 	ret = device_add(&master->dev);
-	if (ret) {
-		pr_err( "i3c_master_register: Error " " device_add bus %d, ret %d\n",master->bus.id, ret );
+	if (ret)
 		goto err_cleanup_bus;
-	}

 	/*
 	 * Expose our I3C bus as an I2C adapter so that I2C devices are exposed
 	 * through the I2C subsystem.
 	 */
 	ret = i3c_master_i2c_adapter_init(master);
-	if (ret) {
-		pr_err( "i3c_master_register: Error " " i2c_adapter_init bus %d, ret %d\n",master->bus.id, ret );
+	if (ret)
 		goto err_del_dev;
-	}

 	/*
 	 * We're done initializing the bus and the controller, we can now
-	 * register I3C devices dicovered during the initial DAA.
+	 * register I3C devices discovered during the initial DAA.
 	 */
 	master->init_done = true;
 	i3c_bus_normaluse_lock(&master->bus);
 	i3c_master_register_new_i3c_devs(master);
+#ifdef CONFIG_I3C_SLAVE_MQUEUE
+	if (master->secondary)
+		i3c_slave_mqueue_probe(master);
+#endif
+
+#ifdef CONFIG_I3C_SLAVE_EEPROM
+	if (master->secondary)
+		i3c_slave_eeprom_probe(master);
+#endif
 	i3c_bus_normaluse_unlock(&master->bus);

 	return 0;
@@ -2725,28 +2993,300 @@ int i3c_master_unregister(struct i3c_master_controller *master)
 }
 EXPORT_SYMBOL_GPL(i3c_master_unregister);

+static int i3c_target_bus_init(struct i3c_master_controller *master)
+{
+	return master->target_ops->bus_init(master);
+}
+
+static void i3c_target_bus_cleanup(struct i3c_master_controller *master)
+{
+	if (master->target_ops->bus_cleanup)
+		master->target_ops->bus_cleanup(master);
+}
+
+static void i3c_targetdev_release(struct device *dev)
+{
+	struct i3c_master_controller *master = container_of(dev, struct i3c_master_controller, dev);
+	struct i3c_bus *bus = &master->bus;
+
+	mutex_lock(&i3c_core_lock);
+	idr_remove(&i3c_bus_idr, bus->id);
+	mutex_unlock(&i3c_core_lock);
+
+	of_node_put(dev->of_node);
+}
+
+static void i3c_target_device_release(struct device *dev)
+{
+	struct i3c_device *i3cdev = dev_to_i3cdev(dev);
+	struct i3c_dev_desc *desc = i3cdev->desc;
+
+	kfree(i3cdev);
+	kfree(desc);
+}
+
+static void
+i3c_target_register_new_i3c_dev(struct i3c_master_controller *master, struct i3c_device_info info)
+{
+	struct i3c_dev_desc *desc;
+	int ret;
+
+	desc = kzalloc(sizeof(*desc), GFP_KERNEL);
+	if (!desc)
+		return;
+
+	desc->dev = kzalloc(sizeof(*desc->dev), GFP_KERNEL);
+	if (!desc->dev) {
+		kfree(desc);
+		return;
+	}
+
+	desc->dev->bus = &master->bus;
+	desc->dev->desc = desc;
+	desc->dev->dev.parent = &master->dev;
+	desc->dev->dev.type = &i3c_target_device_type;
+	desc->dev->dev.bus = &i3c_bus_type;
+	desc->dev->dev.release = i3c_target_device_release;
+	desc->info = info;
+	desc->common.master = master;
+	dev_set_name(&desc->dev->dev, "%d-target", master->bus.id);
+
+	ret = device_register(&desc->dev->dev);
+	if (ret)
+		dev_err(&master->dev, "Failed to add I3C target device (err = %d)\n", ret);
+
+	master->this = desc;
+}
+
+static void i3c_target_unregister_i3c_dev(struct i3c_master_controller *master)
+{
+	struct i3c_dev_desc *i3cdev = master->this;
+
+	if (device_is_registered(&i3cdev->dev->dev))
+		device_unregister(&i3cdev->dev->dev);
+	else
+		put_device(&i3cdev->dev->dev);
+}
+
+static void i3c_target_read_device_info(struct device_node *np, struct i3c_device_info *info)
+{
+	u64 pid;
+	u32 dcr;
+	int ret;
+
+	ret = of_property_read_u64(np, "pid", &pid);
+	if (ret)
+		info->pid = 0;
+	else
+		info->pid = pid;
+
+	ret = of_property_read_u32(np, "dcr", &dcr);
+	if (ret)
+		info->pid = 0;
+	else
+		info->dcr = dcr;
+}
+
+static int i3c_target_check_ops(const struct i3c_target_ops *ops)
+{
+	if (!ops || !ops->bus_init)
+		return -EINVAL;
+
+	return 0;
+}
+
+int i3c_target_register(struct i3c_master_controller *master, struct device *parent,
+			const struct i3c_target_ops *ops)
+{
+	struct i3c_bus *i3cbus = i3c_master_get_bus(master);
+	struct i3c_device_info info;
+	int ret;
+
+	ret = i3c_target_check_ops(ops);
+	if (ret)
+		return ret;
+
+	master->dev.parent = parent;
+	master->dev.of_node = of_node_get(parent->of_node);
+	master->dev.bus = &i3c_bus_type;
+	master->dev.release = i3c_targetdev_release;
+	master->target_ops = ops;
+	i3cbus->mode = I3C_BUS_MODE_PURE;
+
+	init_rwsem(&i3cbus->lock);
+	mutex_lock(&i3c_core_lock);
+	ret = idr_alloc(&i3c_bus_idr, i3cbus, 0, 0, GFP_KERNEL);
+	mutex_unlock(&i3c_core_lock);
+	if (ret < 0)
+		return ret;
+	i3cbus->id = ret;
+
+	device_initialize(&master->dev);
+	dev_set_name(&master->dev, "i3c-%d", i3cbus->id);
+
+	ret = device_add(&master->dev);
+	if (ret)
+		goto err_put_device;
+
+	i3c_target_read_device_info(master->dev.of_node, &info);
+
+	i3c_target_register_new_i3c_dev(master, info);
+
+	ret = i3c_target_bus_init(master);
+	if (ret)
+		goto err_cleanup_bus;
+
+	return 0;
+
+err_cleanup_bus:
+	i3c_target_bus_cleanup(master);
+
+err_put_device:
+	put_device(&master->dev);
+
+	return ret;
+}
+EXPORT_SYMBOL_GPL(i3c_target_register);
+
+int i3c_target_unregister(struct i3c_master_controller *master)
+{
+	i3c_target_unregister_i3c_dev(master);
+	i3c_target_bus_cleanup(master);
+	device_unregister(&master->dev);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(i3c_target_unregister);
+
+int i3c_target_read_register(struct i3c_device *dev, const struct i3c_target_read_setup *setup)
+{
+	dev->desc->target_info.read_handler = setup->handler;
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(i3c_target_read_register);
+
+int i3c_register(struct i3c_master_controller *master,
+		 struct device *parent,
+		 const struct i3c_master_controller_ops *master_ops,
+		 const struct i3c_target_ops *target_ops,
+		 bool secondary)
+{
+	const char *role;
+	int ret;
+
+	ret = of_property_read_string(parent->of_node, "initial-role", &role);
+	if (ret || !strcmp("primary", role)) {
+		return i3c_master_register(master, parent, master_ops, secondary);
+	} else if (!strcmp("target", role)) {
+		master->target = true;
+		return i3c_target_register(master, parent, target_ops);
+	} else {
+		return -EOPNOTSUPP;
+	}
+}
+EXPORT_SYMBOL_GPL(i3c_register);
+
+int i3c_unregister(struct i3c_master_controller *master)
+{
+	if (master->target)
+		i3c_target_unregister(master);
+	else
+		i3c_master_unregister(master);
+
+	return 0;
+}
+EXPORT_SYMBOL_GPL(i3c_unregister);
+
+int i3c_master_send_hdr_cmds_locked(struct i3c_master_controller *master,
+				    struct i3c_hdr_cmd *cmds, int ncmds)
+{
+	int i;
+
+	if (!cmds || !master || ncmds <= 0)
+		return -EINVAL;
+
+	if (!master->ops->send_hdr_cmds)
+		return -ENOTSUPP;
+
+	for (i = 0; i < ncmds; i++) {
+		if (!(master->this->info.hdr_cap & BIT(cmds[i].mode)))
+			return -ENOTSUPP;
+	}
+
+	return master->ops->send_hdr_cmds(master, cmds, ncmds);
+}
+
+/**
+ * i3c_master_send_hdr_cmds() - send HDR commands on the I3C bus
+ * @master: master used to send frames on the bus
+ * @cmds: array of HDR commands
+ * @ncmds: number of commands to send
+ *
+ * Send one or several HDR commands.
+ *
+ * This function can sleep and thus cannot be called in atomic context.
+ *
+ * Return: 0 in case of success, a negative error code otherwise.
+ */
+int i3c_master_send_hdr_cmds(struct i3c_master_controller *master,
+			     struct i3c_hdr_cmd *cmds, int ncmds)
+{
+	int ret;
+
+	i3c_bus_normaluse_lock(&master->bus);
+	ret = i3c_master_send_hdr_cmds_locked(master, cmds, ncmds);
+	i3c_bus_normaluse_unlock(&master->bus);
+
+	return ret;
+}
+EXPORT_SYMBOL_GPL(i3c_master_send_hdr_cmds);
+
 int i3c_dev_do_priv_xfers_locked(struct i3c_dev_desc *dev,
 				 struct i3c_priv_xfer *xfers,
 				 int nxfers)
 {
 	struct i3c_master_controller *master;

-	if (!dev){
-	    pr_err( "i3c_device-do_priv_xfers_locked: Error " " No Device\n");
-	    return -ENOENT;
-	}
+	if (!dev)
+		return -ENOENT;

 	master = i3c_dev_get_master(dev);
-	if (!master || !xfers) {
-	    pr_err( "i3c_device-do_priv_xfers_locked: Error " " No Master \n");
-	    return -EINVAL;
-	}
+	if (!master || !xfers)
+		return -EINVAL;

-	if (!master->ops->priv_xfers) {
-	    pr_err( "i3c_device-do_priv_xfers_locked: Error " " No Priv Xfers Func\n");
-	    return -ENOTSUPP;
+	if (!master->target) {
+		if (!master->ops->priv_xfers)
+			return -EOPNOTSUPP;
+
+		return master->ops->priv_xfers(dev, xfers, nxfers);
 	}
-	return master->ops->priv_xfers(dev, xfers, nxfers);
+
+	if (!master->target_ops->priv_xfers)
+		return -EOPNOTSUPP;
+
+	return master->target_ops->priv_xfers(dev, xfers, nxfers);
+}
+
+int i3c_dev_generate_ibi_locked(struct i3c_dev_desc *dev, const u8 *data, int len)
+
+{
+	struct i3c_master_controller *master;
+
+	if (!dev)
+		return -ENOENT;
+
+	master = i3c_dev_get_master(dev);
+	if (!master)
+		return -EINVAL;
+
+	if (!master->target)
+		return -EINVAL;
+
+	if (!master->target_ops->generate_ibi)
+		return -EOPNOTSUPP;
+
+	return master->target_ops->generate_ibi(dev, data, len);
 }

 int i3c_dev_disable_ibi_locked(struct i3c_dev_desc *dev)
@@ -2834,6 +3374,81 @@ void i3c_dev_free_ibi_locked(struct i3c_dev_desc *dev)
 	dev->ibi = NULL;
 }

+int i3c_dev_send_ccc_cmd_locked(struct i3c_dev_desc *dev, u8 ccc_id)
+{
+	struct i3c_master_controller *master = i3c_dev_get_master(dev);
+	int ret;
+
+	switch (ccc_id) {
+	case I3C_CCC_SETAASA:
+		ret = i3c_master_setaasa_locked(master);
+		break;
+	case I3C_CCC_SETHID:
+		ret = i3c_master_sethid_locked(master);
+		break;
+	case I3C_CCC_RSTDAA(false):
+		ret = i3c_master_rstdaa_locked(master, dev->info.dyn_addr);
+		break;
+	case I3C_CCC_RSTDAA(true):
+		ret = i3c_master_rstdaa_locked(master, I3C_BROADCAST_ADDR);
+		break;
+	default:
+		dev_err(&master->dev, "Unpermitted ccc: %x\n", ccc_id);
+		return -ENOTSUPP;
+	}
+
+	return ret;
+}
+EXPORT_SYMBOL_GPL(i3c_dev_send_ccc_cmd_locked);
+
+int i3c_master_register_slave(struct i3c_master_controller *master,
+			      const struct i3c_slave_setup *req)
+{
+	if (!master->ops->register_slave)
+		return -ENOTSUPP;
+
+	return master->ops->register_slave(master, req);
+}
+
+int i3c_master_unregister_slave(struct i3c_master_controller *master)
+{
+	if (!master->ops->unregister_slave)
+		return -ENOTSUPP;
+
+	return master->ops->unregister_slave(master);
+}
+
+int i3c_master_send_sir(struct i3c_master_controller *master,
+			struct i3c_slave_payload *payload)
+{
+	int ret;
+
+	if (!master->ops->send_sir)
+		return -ENOTSUPP;
+
+	i3c_bus_normaluse_lock(&master->bus);
+	ret = master->ops->send_sir(master, payload);
+	i3c_bus_normaluse_unlock(&master->bus);
+
+	return ret;
+}
+
+int i3c_master_put_read_data(struct i3c_master_controller *master,
+			     struct i3c_slave_payload *data,
+			     struct i3c_slave_payload *ibi_notify)
+{
+	int ret;
+
+	if (!master->ops->put_read_data)
+		return -ENOTSUPP;
+
+	i3c_bus_normaluse_lock(&master->bus);
+	ret = master->ops->put_read_data(master, data, ibi_notify);
+	i3c_bus_normaluse_unlock(&master->bus);
+
+	return ret;
+}
+
 int i3c_for_each_dev(void *data, int (*fn)(struct device *, void *))
 {
 	int res;
@@ -2846,14 +3461,57 @@ int i3c_for_each_dev(void *data, int (*fn)(struct device *, void *))
 }
 EXPORT_SYMBOL_GPL(i3c_for_each_dev);

+int i3c_dev_control_pec(struct i3c_dev_desc *dev, bool pec)
+{
+	struct i3c_master_controller *master = i3c_dev_get_master(dev);
+
+	if (!master->pec_supported)
+		return -EOPNOTSUPP;
+
+	dev->info.pec = pec;
+
+	/*
+	 * TODO: There are two cases which shall be covered
+	 * 1. Controller doesn't support PEC.
+	 *    In this case we could just fallback to SW implementation.
+	 * 2. Device doesn't support PEC.
+	 *    Then we really can't use PEC - and should error-out.
+	 */
+
+	return 0;
+}
+
 static int __init i3c_init(void)
 {
-	return bus_register(&i3c_bus_type);
+	int res;
+
+    res = of_alias_get_highest_id("i3c");
+	if (res >= 0) {
+		mutex_lock(&i3c_core_lock);
+		__i3c_first_dynamic_bus_num = res + 1;
+		mutex_unlock(&i3c_core_lock);
+	}
+
+	res = bus_register_notifier(&i2c_bus_type, &i2cdev_notifier);
+	if (res)
+		return res;
+
+	res = bus_register(&i3c_bus_type);
+	if (res)
+		goto out_unreg_notifier;
+
+	return 0;
+
+out_unreg_notifier:
+	bus_unregister_notifier(&i2c_bus_type, &i2cdev_notifier);
+
+	return res;
 }
 subsys_initcall(i3c_init);

 static void __exit i3c_exit(void)
 {
+	bus_unregister_notifier(&i2c_bus_type, &i2cdev_notifier);
 	idr_destroy(&i3c_bus_idr);
 	bus_unregister(&i3c_bus_type);
 }
diff --git a/drivers/i3c/master/Kconfig b/drivers/i3c/master/Kconfig
index 0eecba763754..4cb8ea236eb6 100644
--- a/drivers/i3c/master/Kconfig
+++ b/drivers/i3c/master/Kconfig
@@ -22,11 +22,52 @@ config DW_I3C_MASTER
 	  This driver can also be built as a module.  If so, the module
 	  will be called dw-i3c-master.

-config ASPEED_I3C_MASTER
-	tristate "Aspeed I3C master driver"
+config AST2600_I3C_MASTER
+	tristate "Aspeed AST2600 I3C master driver"
 	depends on I3C
+	depends on HAS_IOMEM
 	depends on MACH_ASPEED_G6
-	select DW_I3C_MASTER
 	help
-	  Aspeed I3C master controller is a Synopsys DesignWare I3C controller
-	  plus additional global control.
+	  Support for Aspeed AST2600 MIPI I3C Controller.
+
+	  This driver can also be built as a module.  If so, the module
+	  will be called ast2600-i3c-master.
+
+if AST2600_I3C_MASTER
+config AST2600_I3C_IBI_MAX_PAYLOAD
+	int "Max IBI payload size"
+	default 255
+
+config AST2600_I3C_MRL
+	int "Max read length"
+	default 256
+
+config AST2600_I3C_CCC_WORKAROUND
+	bool "Workaround for AST2600A1 errata item#30"
+	default n
+	help
+	  Say y to enable the workaround for AST2600A1 errata item#30.  No need
+	  to enable this option if you are using AST2600A2 or later versions.
+endif
+
+config SVC_I3C_MASTER
+	tristate "Silvaco I3C Dual-Role Master driver"
+	depends on I3C
+	depends on HAS_IOMEM
+	depends on !(ALPHA || PARISC)
+	help
+	  Support for Silvaco I3C Dual-Role Master Controller.
+
+config MIPI_I3C_HCI
+	tristate "MIPI I3C Host Controller Interface driver (EXPERIMENTAL)"
+	depends on I3C
+	depends on HAS_IOMEM
+	help
+	  Support for hardware following the MIPI Aliance's I3C Host Controller
+	  Interface specification.
+
+	  For details please see:
+	  https://www.mipi.org/specifications/i3c-hci
+
+	  This driver can also be built as a module.  If so, the module will be
+	  called mipi-i3c-hci.
diff --git a/drivers/i3c/master/Makefile b/drivers/i3c/master/Makefile
index 2dbfed073cb8..77e9c5b4bdaf 100644
--- a/drivers/i3c/master/Makefile
+++ b/drivers/i3c/master/Makefile
@@ -1,4 +1,6 @@
 # SPDX-License-Identifier: GPL-2.0-only
 obj-$(CONFIG_CDNS_I3C_MASTER)		+= i3c-master-cdns.o
 obj-$(CONFIG_DW_I3C_MASTER)		+= dw-i3c-master.o
-obj-$(CONFIG_ASPEED_I3C_MASTER)		+= aspeed-i3c-global.o
+obj-$(CONFIG_AST2600_I3C_MASTER)	+= ast2600-i3c-global.o ast2600-i3c-master.o
+obj-$(CONFIG_SVC_I3C_MASTER)		+= svc-i3c-master.o
+obj-$(CONFIG_MIPI_I3C_HCI)		+= mipi-i3c-hci/
diff --git a/drivers/i3c/master/aspeed-i3c-global.c b/drivers/i3c/master/aspeed-i3c-global.c
deleted file mode 100644
index b03d6f97a865..000000000000
--- a/drivers/i3c/master/aspeed-i3c-global.c
+++ /dev/null
@@ -1,117 +0,0 @@
-/*
- *  Aspeed I2C Interrupt Controller.
- *
- *  Copyright (C) 2012-2017 ASPEED Technology Inc.
- *  Copyright 2017 IBM Corporation
- *  Copyright 2017 Google, Inc.
- *
- *  This program is free software; you can redistribute it and/or modify
- *  it under the terms of the GNU General Public License version 2 as
- *  published by the Free Software Foundation.
- */
-#include <linux/clk.h>
-#include <linux/irq.h>
-#include <linux/irqchip.h>
-#include <linux/irqchip/chained_irq.h>
-#include <linux/irqdomain.h>
-#include <linux/module.h>
-#include <linux/of_platform.h>
-#include <linux/platform_device.h>
-#include <linux/of_address.h>
-#include <linux/of_irq.h>
-#include <linux/io.h>
-#include <linux/reset.h>
-#include <linux/delay.h>
-
-#define ASPEED_I3CG_CTRL(x)		(0x10 + (x * 0x10))
-#define ASPEED_I3CG_SET(x)		(0x14 + (x * 0x10))
-
-#define DEF_SLV_INST_ID			0x4
-#define DEF_SLV_STATIC_ADDR		0x74
-
-union i3c_set_reg {
-	uint32_t value;
-	struct {
-		unsigned int i2c_mode : 1;	/* bit[0] */
-		unsigned int test_mode : 1;	/* bit[1] */
-		unsigned int act_mode : 2;	/* bit[ 3: 2] */
-		unsigned int pending_int : 4;	/* bit[ 7: 4] */
-		unsigned int sa : 7;		/* bit[14: 8] */
-		unsigned int sa_en : 1;		/* bit[15] */
-		unsigned int inst_id : 4;	/* bit[19:16] */
-		unsigned int rsvd : 12;		/* bit[31:20] */
-	} fields;
-};
-
-
-struct aspeed_i3c_global {
-	void __iomem		*base;
-	struct reset_control	*rst;
-};
-
-static const struct of_device_id aspeed_i3c_of_match[] = {
-	{ .compatible = "aspeed,ast2600-i3c-global", },
-	{},
-};
-
-static int aspeed_i3c_global_probe(struct platform_device *pdev)
-{
-	struct aspeed_i3c_global *i3c_global;
-	struct device_node *node = pdev->dev.of_node;
-	union i3c_set_reg reg;
-	int i, ret;
-	u32 num_of_i3cs;
-
-	i3c_global = kzalloc(sizeof(*i3c_global), GFP_KERNEL);
-	if (!i3c_global)
-		return -ENOMEM;
-
-	i3c_global->base = of_iomap(node, 0);
-	if (!i3c_global->base)
-		return -ENOMEM;
-
-	i3c_global->rst = devm_reset_control_get_exclusive(&pdev->dev, NULL);
-	if (IS_ERR(i3c_global->rst)) {
-		dev_err(&pdev->dev,
-			"missing or invalid reset controller device tree entry");
-		return PTR_ERR(i3c_global->rst);
-	}
-
-	reset_control_assert(i3c_global->rst);
-	udelay(3);
-	reset_control_deassert(i3c_global->rst);
-
-	ret = of_property_read_u32(pdev->dev.of_node, "ni3cs", &num_of_i3cs);
-	if (ret < 0) {
-		dev_err(&pdev->dev, "unable to get number of i3c devices");
-		return -ENOMEM;
-	}
-
-	reg.value = 0;
-	reg.fields.inst_id = DEF_SLV_INST_ID;
-	reg.fields.sa = DEF_SLV_STATIC_ADDR;
-	reg.fields.pending_int = 0xc;
-	reg.fields.act_mode = 0x1;
-	for (i = 0; i < num_of_i3cs; i++)
-		writel(reg.value, i3c_global->base + ASPEED_I3CG_SET(i));
-
-	return 0;
-}
-
-static struct platform_driver aspeed_i3c_driver = {
-	.probe  = aspeed_i3c_global_probe,
-	.driver = {
-		.name = KBUILD_MODNAME,
-		.of_match_table = aspeed_i3c_of_match,
-	},
-};
-
-static int __init aspeed_i3c_global_init(void)
-{
-	return platform_driver_register(&aspeed_i3c_driver);
-}
-postcore_initcall(aspeed_i3c_global_init);
-
-MODULE_AUTHOR("Ryan Chen");
-MODULE_DESCRIPTION("ASPEED I3C Global Driver");
-MODULE_LICENSE("GPL v2");
diff --git a/drivers/i3c/master/ast2600-i3c-global.c b/drivers/i3c/master/ast2600-i3c-global.c
new file mode 100644
index 000000000000..3536849dbe5f
--- /dev/null
+++ b/drivers/i3c/master/ast2600-i3c-global.c
@@ -0,0 +1,141 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Copyright (C) 2021 ASPEED Technology Inc.
+ *
+ * Author: Dylan Hung <dylan_hung@aspeedtech.com>
+ * Based on a work from: Ryan Chen <ryan_chen@aspeedtech.com>
+ */
+#include <linux/clk.h>
+#include <linux/module.h>
+#include <linux/of_platform.h>
+#include <linux/platform_device.h>
+#include <linux/of_address.h>
+#include <linux/io.h>
+#include <linux/reset.h>
+#include <linux/delay.h>
+#include <linux/slab.h>
+
+#define I3CG_REG0(x)			((x * 0x10) + 0x10)
+#define I3CG_REG0_SDA_PULLUP_EN_MASK	GENMASK(29, 28)
+#define I3CG_REG0_SDA_PULLUP_EN_2K	(0x1 << 28)
+#define I3CG_REG0_SDA_PULLUP_EN_750	(0x2 << 28)
+#define I3CG_REG0_SDA_PULLUP_EN_545	(0x3 << 28)
+
+#define I3CG_REG1(x)			((x * 0x10) + 0x14)
+#define I3CG_REG1_I2C_MODE		BIT(0)
+#define I3CG_REG1_TEST_MODE		BIT(1)
+#define I3CG_REG1_ACT_MODE_MASK		GENMASK(3, 2)
+#define I3CG_REG1_ACT_MODE(x)		(((x) << 2) & I3CG_REG1_ACT_MODE_MASK)
+#define I3CG_REG1_PENDING_INT_MASK	GENMASK(7, 4)
+#define I3CG_REG1_PENDING_INT(x)	(((x) << 4) & I3CG_REG1_PENDING_INT_MASK)
+#define I3CG_REG1_SA_MASK		GENMASK(14, 8)
+#define I3CG_REG1_SA(x)			(((x) << 8) & I3CG_REG1_SA_MASK)
+#define I3CG_REG1_SA_EN			BIT(15)
+#define I3CG_REG1_INST_ID_MASK		GENMASK(19, 16)
+#define I3CG_REG1_INST_ID(x)		(((x) << 16) & I3CG_REG1_INST_ID_MASK)
+
+struct aspeed_i3c_global {
+	void __iomem *regs;
+	struct reset_control *rst;
+};
+
+static const struct of_device_id aspeed_i3c_of_match[] = {
+	{ .compatible = "aspeed,ast2600-i3c-global", },
+	{},
+};
+MODULE_DEVICE_TABLE(of, aspeed_i3c_of_match);
+
+static u32 pullup_resistor_ohm_to_reg(u32 ohm)
+{
+	switch (ohm) {
+	case 545:
+		return I3CG_REG0_SDA_PULLUP_EN_545;
+	case 750:
+		return I3CG_REG0_SDA_PULLUP_EN_750;
+	case 2000:
+	default:
+		return I3CG_REG0_SDA_PULLUP_EN_2K;
+	}
+}
+
+static int aspeed_i3c_global_probe(struct platform_device *pdev)
+{
+	struct aspeed_i3c_global *i3cg;
+	u32 reg0, reg1, num_i3cs;
+	u32 *pullup_resistors;
+	int i, ret;
+
+	i3cg = devm_kzalloc(&pdev->dev, sizeof(*i3cg), GFP_KERNEL);
+	if (!i3cg)
+		return -ENOMEM;
+
+	i3cg->regs = devm_platform_ioremap_resource(pdev, 0);
+	if (IS_ERR(i3cg->regs))
+		return -ENOMEM;
+
+	i3cg->rst = devm_reset_control_get(&pdev->dev, NULL);
+	if (IS_ERR(i3cg->rst)) {
+		dev_err(&pdev->dev,
+			"missing or invalid reset controller device tree entry");
+		return PTR_ERR(i3cg->rst);
+	}
+
+	reset_control_assert(i3cg->rst);
+	udelay(3);
+	reset_control_deassert(i3cg->rst);
+
+	ret = of_property_read_u32(pdev->dev.of_node, "num-i3cs", &num_i3cs);
+	if (ret < 0) {
+		dev_err(&pdev->dev, "unable to get number of i3c controllers");
+		return -ENOMEM;
+	}
+
+	pullup_resistors = kcalloc(num_i3cs, sizeof(u32), GFP_KERNEL);
+	if (!pullup_resistors)
+		return -ENOMEM;
+
+	ret = of_property_read_u32_array(pdev->dev.of_node, "pull-up-resistors",
+					 pullup_resistors, num_i3cs);
+	if (ret < 0) {
+		dev_warn(&pdev->dev,
+			 "use 2K Ohm SDA pull up resistor by default");
+	}
+
+	reg1 = I3CG_REG1_ACT_MODE(1) | I3CG_REG1_PENDING_INT(0xc) |
+	       I3CG_REG1_SA(0x74);
+
+	for (i = 0; i < num_i3cs; i++) {
+		reg0 = readl(i3cg->regs + I3CG_REG0(i));
+		reg0 &= ~I3CG_REG0_SDA_PULLUP_EN_MASK;
+		reg0 |= pullup_resistor_ohm_to_reg(pullup_resistors[i]);
+		writel(reg0, i3cg->regs + I3CG_REG0(i));
+
+		reg1 &= ~I3CG_REG1_INST_ID_MASK;
+		reg1 |= I3CG_REG1_INST_ID(i);
+		writel(reg1, i3cg->regs + I3CG_REG1(i));
+	}
+
+	kfree(pullup_resistors);
+
+	return 0;
+}
+
+static struct platform_driver aspeed_i3c_driver = {
+	.probe  = aspeed_i3c_global_probe,
+	.driver = {
+		.name = KBUILD_MODNAME,
+		.of_match_table = of_match_ptr(aspeed_i3c_of_match),
+	},
+};
+
+//static int __init aspeed_i3c_global_init(void)
+//{
+//	return platform_driver_register(&aspeed_i3c_driver);
+//}
+//postcore_initcall(aspeed_i3c_global_init);
+module_platform_driver(aspeed_i3c_driver);
+
+MODULE_AUTHOR("Ryan Chen <ryan_chen@aspeedtech.com>");
+MODULE_AUTHOR("Dylan Hung <dylan_hung@aspeedtech.com>");
+MODULE_DESCRIPTION("ASPEED I3C Global Driver");
+MODULE_LICENSE("GPL v2");
diff --git a/drivers/i3c/master/ast2600-i3c-master.c b/drivers/i3c/master/ast2600-i3c-master.c
new file mode 100644
index 000000000000..3b7707ad1a7a
--- /dev/null
+++ b/drivers/i3c/master/ast2600-i3c-master.c
@@ -0,0 +1,3036 @@
+// SPDX-License-Identifier: GPL-2.0-or-later
+/*
+ * Copyright (c) 2021 ASPEED Technology Inc.
+ *
+ * Derived from dw-i3c-master.c by Vitor Soares <vitor.soares@synopsys.com>
+ */
+
+#include <linux/bitops.h>
+#include <linux/bitfield.h>
+#include <linux/clk.h>
+#include <linux/completion.h>
+#include <linux/err.h>
+#include <linux/errno.h>
+#include <linux/i3c/master.h>
+#include <linux/interrupt.h>
+#include <linux/ioport.h>
+#include <linux/iopoll.h>
+#include <linux/list.h>
+#include <linux/module.h>
+#include <linux/of.h>
+#include <linux/platform_device.h>
+#include <linux/reset.h>
+#include <linux/slab.h>
+#include <linux/mfd/syscon.h>
+#include <linux/regmap.h>
+#include <linux/crc8.h>
+
+/* CRC8 table for PEC support */
+#define I3C_CRC8_POLYNOMIAL	0x07
+DECLARE_CRC8_TABLE(i3c_crc8_table);
+#define I3C_CHANNEL_MAX 5
+
+#define DEVICE_CTRL			0x0
+#define DEV_CTRL_ENABLE			BIT(31)
+#define DEV_CTRL_RESUME			BIT(30)
+#define DEV_CTRL_ABORT			BIT(29)
+#define DEV_CTRL_AUTO_HJ_DISABLE	BIT(27)
+#define DEV_CTRL_SLAVE_MDB		GENMASK(23, 16)
+#define DEV_CTRL_SLAVE_PEC_EN		BIT(10)
+#define DEV_CRTL_IBI_PAYLOAD_EN		BIT(9)
+#define DEV_CTRL_HOT_JOIN_NACK		BIT(8)
+#define DEV_CTRL_I2C_SLAVE_PRESENT	BIT(7)
+#define DEV_CTRL_IBA_INCLUDE		BIT(0)
+
+#define DEVICE_ADDR			0x4
+#define DEV_ADDR_DYNAMIC_ADDR_VALID	BIT(31)
+#define DEV_ADDR_DYNAMIC_MASK		GENMASK(22, 16)
+#define DEV_ADDR_DYNAMIC(x)		(((x) << 16) & DEV_ADDR_DYNAMIC_MASK)
+#define DEV_ADDR_STATIC_ADDR_VALID	BIT(15)
+#define DEV_ADDR_STATIC_MASK		GENMASK(6, 0)
+#define DEV_ADDR_STATIC(x)		(((x) << 0) & DEV_ADDR_STATIC_MASK)
+
+#define HW_CAPABILITY			0x8
+#define COMMAND_QUEUE_PORT		0xc
+#define COMMAND_PORT_PEC		BIT(31)
+#define COMMAND_PORT_TOC		BIT(30)
+#define COMMAND_PORT_READ_TRANSFER	BIT(28)
+#define COMMAND_PORT_SDAP		BIT(27)
+#define COMMAND_PORT_ROC		BIT(26)
+#define COMMAND_PORT_DBP(x)		((x) << 25)
+#define COMMAND_PORT_SPEED(x)		(((x) << 21) & GENMASK(23, 21))
+#define   SPEED_I3C_SDR0		0x0
+#define   SPEED_I3C_SDR1		0x1
+#define   SPEED_I3C_SDR2		0x2
+#define   SPEED_I3C_SDR3		0x3
+#define   SPEED_I3C_SDR4		0x4
+#define   SPEED_I3C_HDR_TS		0x5
+#define   SPEED_I3C_HDR_DDR		0x6
+#define   SPEED_I3C_I2C_FM		0x7
+#define   SPEED_I2C_FM			0x0
+#define   SPEED_I2C_FMP			0x1
+#define COMMAND_PORT_DEV_INDEX(x)	(((x) << 16) & GENMASK(20, 16))
+#define COMMAND_PORT_CP			BIT(15)
+#define COMMAND_PORT_CMD(x)		(((x) << 7) & GENMASK(14, 7))
+#define COMMAND_PORT_TID(x)		(((x) << 3) & GENMASK(6, 3))
+
+#define COMMAND_PORT_ARG_DBP(x)		(((x) << 8) & GENMASK(15, 8))
+#define COMMAND_PORT_ARG_DATA_LEN(x)	(((x) << 16) & GENMASK(31, 16))
+#define COMMAND_PORT_ARG_DATA_LEN_MAX	65536
+#define COMMAND_PORT_TRANSFER_ARG	0x01
+
+#define COMMAND_ATTR_SLAVE_DATA		0x0
+#define COMMAND_PORT_SLAVE_TID(x)      (((x) << 3) & GENMASK(5, 3))
+#define COMMAND_PORT_SLAVE_DATA_LEN	GENMASK(31, 16)
+
+#define COMMAND_PORT_SDA_DATA_BYTE_3(x)	(((x) << 24) & GENMASK(31, 24))
+#define COMMAND_PORT_SDA_DATA_BYTE_2(x)	(((x) << 16) & GENMASK(23, 16))
+#define COMMAND_PORT_SDA_DATA_BYTE_1(x)	(((x) << 8) & GENMASK(15, 8))
+#define COMMAND_PORT_SDA_BYTE_STRB_3	BIT(5)
+#define COMMAND_PORT_SDA_BYTE_STRB_2	BIT(4)
+#define COMMAND_PORT_SDA_BYTE_STRB_1	BIT(3)
+#define COMMAND_PORT_SHORT_DATA_ARG	0x02
+
+#define COMMAND_PORT_DEV_COUNT(x)	(((x) << 21) & GENMASK(25, 21))
+#define COMMAND_PORT_ADDR_ASSGN_CMD	0x03
+
+#define RESPONSE_QUEUE_PORT		0x10
+#define RESPONSE_PORT_ERR_STATUS(x)	(((x) & GENMASK(31, 28)) >> 28)
+#define RESPONSE_NO_ERROR		0
+#define RESPONSE_ERROR_CRC		1
+#define RESPONSE_ERROR_PARITY		2
+#define RESPONSE_ERROR_FRAME		3
+#define RESPONSE_ERROR_IBA_NACK		4
+#define RESPONSE_ERROR_ADDRESS_NACK	5
+#define RESPONSE_ERROR_OVER_UNDER_FLOW	6
+#define RESPONSE_ERROR_TRANSF_ABORT	8
+#define RESPONSE_ERROR_I2C_W_NACK_ERR	9
+#define RESPONSE_ERROR_EARLY_TERMINATE	10
+#define RESPONSE_ERROR_PEC_ERR		12
+#define RESPONSE_PORT_TID(x)		(((x) & GENMASK(27, 24)) >> 24)
+#define   TID_SLAVE_IBI_DONE		0b0001
+#define   TID_MASTER_READ_DATA		0b0010
+#define   TID_MASTER_WRITE_DATA		0b1000
+#define   TID_CCC_WRITE_DATA		0b1111
+#define RESPONSE_PORT_DATA_LEN(x)	((x) & GENMASK(15, 0))
+
+#define RX_TX_DATA_PORT			0x14
+#define IBI_QUEUE_STATUS		0x18
+#define IBI_QUEUE_STATUS_RSP_NACK	BIT(31)
+#define IBI_QUEUE_STATUS_PEC_ERR	BIT(30)
+#define IBI_QUEUE_STATUS_LAST_FRAG	BIT(24)
+#define IBI_QUEUE_STATUS_IBI_ID(x)	(((x) & GENMASK(15, 8)) >> 8)
+#define IBI_QUEUE_STATUS_DATA_LEN(x)	((x) & GENMASK(7, 0))
+
+#define IBI_QUEUE_IBI_ADDR(x)		(IBI_QUEUE_STATUS_IBI_ID(x) >> 1)
+#define IBI_QUEUE_IBI_RNW(x)		(IBI_QUEUE_STATUS_IBI_ID(x) & BIT(0))
+#define IBI_TYPE_MR(x)                                                         \
+	((IBI_QUEUE_IBI_ADDR(x) != I3C_HOT_JOIN_ADDR) && !IBI_QUEUE_IBI_RNW(x))
+#define IBI_TYPE_HJ(x)                                                         \
+	((IBI_QUEUE_IBI_ADDR(x) == I3C_HOT_JOIN_ADDR) && !IBI_QUEUE_IBI_RNW(x))
+#define IBI_TYPE_SIR(x)                                                        \
+	((IBI_QUEUE_IBI_ADDR(x) != I3C_HOT_JOIN_ADDR) && IBI_QUEUE_IBI_RNW(x))
+
+#define IBI_QUEUE_DATA			0x18
+#define QUEUE_THLD_CTRL			0x1c
+#define QUEUE_THLD_CTRL_IBI_STA_MASK	GENMASK(31, 24)
+#define QUEUE_THLD_CTRL_IBI_STA(x)	(((x) - 1) << 24)
+#define QUEUE_THLD_CTRL_IBI_DAT_MASK	GENMASK(23, 16)
+#define QUEUE_THLD_CTRL_IBI_DAT(x)	((x) << 16)
+#define QUEUE_THLD_CTRL_RESP_BUF_MASK	GENMASK(15, 8)
+#define QUEUE_THLD_CTRL_RESP_BUF(x)	(((x) - 1) << 8)
+
+#define DATA_BUFFER_THLD_CTRL		0x20
+#define DATA_BUFFER_THLD_CTRL_RX_BUF	GENMASK(11, 8)
+
+#define IBI_QUEUE_CTRL			0x24
+#define IBI_MR_REQ_REJECT		0x2C
+#define IBI_SIR_REQ_REJECT		0x30
+#define IBI_REQ_REJECT_ALL		GENMASK(31, 0)
+
+#define RESET_CTRL			0x34
+#define RESET_CTRL_BUS			BIT(31)
+#define RESET_CTRL_BUS_RESET_TYPE	GENMASK(30, 29)
+#define   BUS_RESET_TYPE_EXIT		0b00
+#define   BUS_RESET_TYPE_SCL_LOW	0b11
+#define RESET_CTRL_IBI_QUEUE		BIT(5)
+#define RESET_CTRL_RX_FIFO		BIT(4)
+#define RESET_CTRL_TX_FIFO		BIT(3)
+#define RESET_CTRL_RESP_QUEUE		BIT(2)
+#define RESET_CTRL_CMD_QUEUE		BIT(1)
+#define RESET_CTRL_SOFT			BIT(0)
+#define RESET_CTRL_ALL                  (RESET_CTRL_IBI_QUEUE	              |\
+					 RESET_CTRL_RX_FIFO	              |\
+					 RESET_CTRL_TX_FIFO	              |\
+					 RESET_CTRL_RESP_QUEUE	              |\
+					 RESET_CTRL_CMD_QUEUE	              |\
+					 RESET_CTRL_SOFT)
+#define RESET_CTRL_QUEUES		(RESET_CTRL_IBI_QUEUE	              |\
+					 RESET_CTRL_RX_FIFO	              |\
+					 RESET_CTRL_TX_FIFO	              |\
+					 RESET_CTRL_RESP_QUEUE	              |\
+					 RESET_CTRL_CMD_QUEUE)
+#define RESET_CTRL_XFER_QUEUES		(RESET_CTRL_RX_FIFO	              |\
+					 RESET_CTRL_TX_FIFO	              |\
+					 RESET_CTRL_RESP_QUEUE	              |\
+					 RESET_CTRL_CMD_QUEUE)
+
+#define SLV_EVENT_CTRL			0x38
+#define SLV_EVENT_CTRL_MWL_UPD		BIT(7)
+#define SLV_EVENT_CTRL_MRL_UPD		BIT(6)
+#define SLV_EVENT_CTRL_SIR_EN		BIT(0)
+#define SLV_EVETN_CTRL_W1C_MASK		(SLV_EVENT_CTRL_MWL_UPD |\
+					 SLV_EVENT_CTRL_MRL_UPD)
+
+#define INTR_STATUS			0x3c
+#define INTR_STATUS_EN			0x40
+#define INTR_SIGNAL_EN			0x44
+#define INTR_FORCE			0x48
+#define INTR_BUSOWNER_UPDATE_STAT	BIT(13)
+#define INTR_IBI_UPDATED_STAT		BIT(12)
+#define INTR_READ_REQ_RECV_STAT		BIT(11)
+#define INTR_DEFSLV_STAT		BIT(10)
+#define INTR_TRANSFER_ERR_STAT		BIT(9)
+#define INTR_DYN_ADDR_ASSGN_STAT	BIT(8)
+#define INTR_CCC_UPDATED_STAT		BIT(6)
+#define INTR_TRANSFER_ABORT_STAT	BIT(5)
+#define INTR_RESP_READY_STAT		BIT(4)
+#define INTR_CMD_QUEUE_READY_STAT	BIT(3)
+#define INTR_IBI_THLD_STAT		BIT(2)
+#define INTR_RX_THLD_STAT		BIT(1)
+#define INTR_TX_THLD_STAT		BIT(0)
+#define INTR_ALL			(INTR_BUSOWNER_UPDATE_STAT |	\
+					INTR_IBI_UPDATED_STAT |		\
+					INTR_READ_REQ_RECV_STAT |	\
+					INTR_DEFSLV_STAT |		\
+					INTR_TRANSFER_ERR_STAT |	\
+					INTR_DYN_ADDR_ASSGN_STAT |	\
+					INTR_CCC_UPDATED_STAT |		\
+					INTR_TRANSFER_ABORT_STAT |	\
+					INTR_RESP_READY_STAT |		\
+					INTR_CMD_QUEUE_READY_STAT |	\
+					INTR_IBI_THLD_STAT |		\
+					INTR_TX_THLD_STAT |		\
+					INTR_RX_THLD_STAT)
+#define INTR_MASTER_MASK		(INTR_TRANSFER_ERR_STAT |	\
+					 INTR_RESP_READY_STAT)
+#define INTR_2ND_MASTER_MASK		(INTR_TRANSFER_ERR_STAT |	\
+					 INTR_RESP_READY_STAT	|	\
+					 INTR_IBI_UPDATED_STAT  |	\
+					 INTR_CCC_UPDATED_STAT)
+#define QUEUE_STATUS_LEVEL		0x4c
+#define QUEUE_STATUS_IBI_STATUS_CNT(x)	(((x) & GENMASK(28, 24)) >> 24)
+#define QUEUE_STATUS_IBI_BUF_BLR(x)	(((x) & GENMASK(23, 16)) >> 16)
+#define QUEUE_STATUS_LEVEL_RESP(x)	(((x) & GENMASK(15, 8)) >> 8)
+#define QUEUE_STATUS_LEVEL_CMD(x)	((x) & GENMASK(7, 0))
+
+#define DATA_BUFFER_STATUS_LEVEL	0x50
+#define DATA_BUFFER_STATUS_LEVEL_TX(x)	((x) & GENMASK(7, 0))
+
+#define PRESENT_STATE			0x54
+#define   CM_TFR_ST_STS			GENMASK(21, 16)
+#define     CM_TFR_ST_STS_HALT		0x13
+#define   CM_TFR_STS			GENMASK(13, 8)
+#define     CM_TFR_STS_MASTER_SERV_IBI	0xe
+#define     CM_TFR_STS_MASTER_HALT	0xf
+#define     CM_TFR_STS_SLAVE_HALT	0x6
+
+#define CCC_DEVICE_STATUS		0x58
+#define DEVICE_ADDR_TABLE_POINTER	0x5c
+#define DEVICE_ADDR_TABLE_DEPTH(x)	(((x) & GENMASK(31, 16)) >> 16)
+#define DEVICE_ADDR_TABLE_ADDR(x)	((x) & GENMASK(7, 0))
+
+#define DEV_CHAR_TABLE_POINTER		0x60
+#define VENDOR_SPECIFIC_REG_POINTER	0x6c
+#define SLV_MIPI_PID_VALUE		0x70
+#define PID_MANUF_ID_ASPEED		0x03f6
+
+#define SLV_PID_VALUE			0x74
+#define SLV_PID_PART_ID(x)		(((x) << 16) & GENMASK(31, 16))
+#define SLV_PID_INST_ID(x)		(((x) << 12) & GENMASK(15, 12))
+#define SLV_PID_DCR(x)			((x) & GENMASK(11, 0))
+
+#define PID_PART_ID_AST2600_SERIES	0x0500
+#define PID_PART_ID_AST1030_A0		0x8000
+
+#define SLV_CHAR_CTRL			0x78
+#define SLV_CHAR_GET_DCR(x)		(((x) & GENMASK(15, 8)) >> 8)
+#define SLV_CHAR_GET_BCR(x)		(((x) & GENMASK(7, 0)) >> 0)
+#define SLV_MAX_LEN			0x7c
+#define MAX_READ_TURNAROUND		0x80
+#define MAX_DATA_SPEED			0x84
+#define SLV_DEBUG_STATUS		0x88
+#define SLV_INTR_REQ			0x8c
+#define SLV_INTR_REQ_IBI_STS(x)		((x) & GENMASK(9, 8) >> 8)
+#define SLV_IBI_STS_OK			0x1
+
+#define DEVICE_CTRL_EXTENDED		0xb0
+#define DEVICE_CTRL_ROLE_MASK		GENMASK(1, 0)
+#define DEVICE_CTRL_ROLE_MASTER		0
+#define DEVICE_CTRL_ROLE_SLAVE		1
+#define SCL_I3C_OD_TIMING		0xb4
+#define SCL_I3C_PP_TIMING		0xb8
+#define SCL_I3C_TIMING_HCNT		GENMASK(23, 16)
+#define SCL_I3C_TIMING_LCNT		GENMASK(7, 0)
+#define SCL_I3C_TIMING_CNT_MIN		5
+
+#define SCL_I2C_FM_TIMING		0xbc
+#define SCL_I2C_FM_TIMING_HCNT		GENMASK(31, 16)
+#define SCL_I2C_FM_TIMING_LCNT		GENMASK(15, 0)
+
+#define SCL_I2C_FMP_TIMING		0xc0
+#define SCL_I2C_FMP_TIMING_HCNT		GENMASK(23, 16)
+#define SCL_I2C_FMP_TIMING_LCNT		GENMASK(15, 0)
+
+#define SCL_EXT_LCNT_TIMING		0xc8
+#define SCL_EXT_LCNT_4(x)		(((x) << 24) & GENMASK(31, 24))
+#define SCL_EXT_LCNT_3(x)		(((x) << 16) & GENMASK(23, 16))
+#define SCL_EXT_LCNT_2(x)		(((x) << 8) & GENMASK(15, 8))
+#define SCL_EXT_LCNT_1(x)		((x) & GENMASK(7, 0))
+
+#define SCL_EXT_TERMN_LCNT_TIMING	0xcc
+#define SDA_HOLD_SWITCH_DLY_TIMING	0xd0
+#define SDA_TX_HOLD			GENMASK(18, 16)
+#define   SDA_TX_HOLD_MIN		0b001
+#define   SDA_TX_HOLD_MAX		0b111
+#define SDA_PP_OD_SWITCH_DLY		GENMASK(10, 8)
+#define SDA_OD_PP_SWITCH_DLY		GENMASK(2, 0)
+#define BUS_FREE_TIMING			0xd4
+#define BUS_I3C_AVAILABLE_TIME(x)	(((x) << 16) & GENMASK(31, 16))
+#define BUS_I3C_MST_FREE(x)		((x) & GENMASK(15, 0))
+
+#define BUS_IDLE_TIMING			0xd8
+#define SCL_LOW_MST_EXT_TIMEOUT		0xdc
+#define I3C_VER_ID			0xe0
+#define I3C_VER_TYPE			0xe4
+#define EXTENDED_CAPABILITY		0xe8
+#define SLAVE_CONFIG			0xec
+
+#define DEV_ADDR_TABLE_LEGACY_I2C_DEV	BIT(31)
+#define DEV_ADDR_TABLE_DEV_NACK_RETRY	GENMASK(30, 29)
+#define DEV_ADDR_TABLE_IBI_ADDR_MASK	GENMASK(25, 24)
+#define   IBI_ADDR_MASK_OFF		0b00
+#define   IBI_ADDR_MASK_LAST_3BITS	0b01
+#define   IBI_ADDR_MASK_LAST_4BITS	0b10
+#define DEV_ADDR_TABLE_DA_PARITY	BIT(23)
+#define DEV_ADDR_TABLE_DYNAMIC_ADDR	GENMASK(22, 16)
+#define DEV_ADDR_TABLE_MR_REJECT	BIT(14)
+#define DEV_ADDR_TABLE_SIR_REJECT	BIT(13)
+#define DEV_ADDR_TABLE_IBI_WITH_DATA	BIT(12)
+#define DEV_ADDR_TABLE_IBI_PEC_EN	BIT(11)
+#define DEV_ADDR_TABLE_STATIC_ADDR	GENMASK(6, 0)
+
+#define DEV_ADDR_TABLE_LOC(start, idx)	((start) + ((idx) << 2))
+#define GET_DAT_FROM_POS(_master, _pos)                                        \
+	(readl(_master->regs + DEV_ADDR_TABLE_LOC(_master->datstartaddr, _pos)))
+
+#define MAX_DEVS			128
+#define MAX_IBI_FRAG_SIZE		124
+
+#define I3C_BUS_SDR1_SCL_RATE		8000000
+#define I3C_BUS_SDR2_SCL_RATE		6000000
+#define I3C_BUS_SDR3_SCL_RATE		4000000
+#define I3C_BUS_SDR4_SCL_RATE		2000000
+#define I3C_BUS_I2C_STD_TLOW_MIN_NS	4700
+#define I3C_BUS_I2C_STD_THIGH_MIN_NS	4000
+#define I3C_BUS_I2C_STD_TR_MAX_NS	1000
+#define I3C_BUS_I2C_STD_TF_MAX_NS	300
+#define I3C_BUS_I2C_FM_TLOW_MIN_NS	1300
+#define I3C_BUS_I2C_FM_THIGH_MIN_NS	600
+#define I3C_BUS_I2C_FM_TR_MAX_NS	300
+#define I3C_BUS_I2C_FM_TF_MAX_NS	300
+#define I3C_BUS_I2C_FMP_TLOW_MIN_NS	500
+#define I3C_BUS_I2C_FMP_THIGH_MIN_NS	260
+#define I3C_BUS_I2C_FMP_TR_MAX_NS	120
+#define I3C_BUS_I2C_FMP_TF_MAX_NS	120
+#define I3C_BUS_JESD403_PP_TLOW_MIN_NS	35
+#define I3C_BUS_JESD403_PP_THIGH_MIN_NS	35
+#define I3C_BUS_JESD403_PP_TR_MAX_NS	5
+#define I3C_BUS_JESD403_PP_TF_MAX_NS	5
+#define I3C_BUS_THIGH_MAX_NS		41
+
+#define I3C_BUS_EXT_TERMN_CNT		4
+#define JESD403_TIMED_RESET_NS_DEF	52428800
+
+#define XFER_TIMEOUT			(msecs_to_jiffies(1000))
+
+#define ast_setbits(x, set)		writel(readl(x) | (set), x)
+#define ast_clrbits(x, clr)		writel(readl(x) & ~(clr), x)
+#define ast_clrsetbits(x, clr, set)	writel((readl(x) & ~(clr)) | (set), x)
+
+#define MAX_GROUPS			(1 << 4)
+#define MAX_DEVS_IN_GROUP		(1 << 3)
+#define ALL_DEVS_IN_GROUP_ARE_FREE	((1 << MAX_DEVS_IN_GROUP) - 1)
+#define ADDR_GRP_MASK			GENMASK(6, 3)
+#define ADDR_GRP(x)			(((x) & ADDR_GRP_MASK) >> 3)
+#define ADDR_HID_MASK			GENMASK(2, 0)
+#define ADDR_HID(x)			((x) & ADDR_HID_MASK)
+
+struct aspeed_i3c_master_caps {
+	u8 cmdfifodepth;
+	u8 datafifodepth;
+};
+
+struct aspeed_i3c_cmd {
+	u32 cmd_lo;
+	u32 cmd_hi;
+	u16 tx_len;
+	const void *tx_buf;
+	u16 rx_len;
+	void *rx_buf;
+	u8 error;
+};
+
+struct aspeed_i3c_xfer {
+	struct list_head node;
+	struct completion comp;
+	int ret;
+	unsigned int ncmds;
+	struct aspeed_i3c_cmd cmds[];
+};
+
+struct aspeed_i3c_dev_group {
+	u32 dat[8];
+	u32 free_pos;
+	int hw_index;
+	struct {
+		u32 set;
+		u32 clr;
+	} mask;
+};
+
+struct aspeed_i3c_master {
+	struct device *dev;
+	struct i3c_master_controller base;
+	struct regmap *i3cg;
+	u16 maxdevs;
+	u16 datstartaddr;
+	u32 free_pos;
+	struct aspeed_i3c_dev_group dev_group[MAX_GROUPS];
+	struct {
+		struct list_head list;
+		struct aspeed_i3c_xfer *cur;
+		spinlock_t lock;
+	} xferqueue;
+	struct {
+		struct i3c_dev_desc *slots[MAX_DEVS];
+		u32 received_ibi_len[MAX_DEVS];
+		spinlock_t lock;
+	} ibi;
+	struct aspeed_i3c_master_caps caps;
+	void __iomem *regs;
+	struct reset_control *core_rst;
+	struct clk *core_clk;
+	char version[5];
+	char type[5];
+	u8 addrs[MAX_DEVS];
+	u32 channel;
+	bool secondary;
+	bool ibi_wo_pec;
+	struct {
+		u32 *buf;
+		void (*callback)(struct i3c_master_controller *m,
+				 const struct i3c_slave_payload *payload);
+	} slave_data;
+	struct completion sir_complete;
+	struct completion data_read_complete;
+
+	struct {
+		unsigned long core_rate;
+		unsigned long core_period;
+		u32 i3c_od_scl_freq;
+		u32 i3c_od_scl_low;
+		u32 i3c_od_scl_high;
+		u32 i3c_pp_scl_freq;
+		u32 i3c_pp_scl_low;
+		u32 i3c_pp_scl_high;
+	} timing;
+	struct work_struct hj_work;
+};
+
+struct aspeed_i3c_i2c_dev_data {
+	struct i3c_generic_ibi_pool *ibi_pool;
+	u8 index;
+	s8 ibi;
+};
+
+static u8 even_parity(u8 p)
+{
+	p ^= p >> 4;
+	p &= 0xf;
+
+	return (0x9669 >> p) & 1;
+}
+
+#define I3CG_REG1(x)			(((x) * 0x10) + 0x14)
+#define SDA_OUT_SW_MODE_EN		BIT(31)
+#define SCL_OUT_SW_MODE_EN		BIT(30)
+#define SDA_IN_SW_MODE_EN		BIT(29)
+#define SCL_IN_SW_MODE_EN		BIT(28)
+#define SDA_IN_SW_MODE_VAL		BIT(27)
+#define SDA_OUT_SW_MODE_VAL		BIT(25)
+#define SDA_SW_MODE_OE			BIT(24)
+#define SCL_IN_SW_MODE_VAL		BIT(23)
+#define SCL_OUT_SW_MODE_VAL		BIT(21)
+#define SCL_SW_MODE_OE			BIT(20)
+
+static void aspeed_i3c_isolate_scl_sda(struct aspeed_i3c_master *master, bool iso)
+{
+	if (iso) {
+		regmap_write_bits(master->i3cg, I3CG_REG1(master->channel),
+				  SCL_IN_SW_MODE_VAL | SDA_IN_SW_MODE_VAL,
+				  SCL_IN_SW_MODE_VAL | SDA_IN_SW_MODE_VAL);
+		regmap_write_bits(master->i3cg, I3CG_REG1(master->channel),
+				  SCL_IN_SW_MODE_EN | SDA_IN_SW_MODE_EN,
+				  SCL_IN_SW_MODE_EN | SDA_IN_SW_MODE_EN);
+	} else {
+		regmap_write_bits(master->i3cg, I3CG_REG1(master->channel),
+				  SCL_IN_SW_MODE_EN | SDA_IN_SW_MODE_EN, 0);
+	}
+}
+
+static void aspeed_i3c_toggle_scl_in(struct aspeed_i3c_master *master, u32 times)
+{
+	for (; times; times--) {
+		regmap_write_bits(master->i3cg, I3CG_REG1(master->channel),
+				  SCL_IN_SW_MODE_VAL, 0);
+		regmap_write_bits(master->i3cg, I3CG_REG1(master->channel),
+				  SCL_IN_SW_MODE_VAL, SCL_IN_SW_MODE_VAL);
+	}
+}
+
+static void aspeed_i3c_gen_stop_to_internal(struct aspeed_i3c_master *master)
+{
+	regmap_write_bits(master->i3cg, I3CG_REG1(master->channel),
+			  SCL_IN_SW_MODE_VAL, 0);
+	regmap_write_bits(master->i3cg, I3CG_REG1(master->channel),
+			  SDA_IN_SW_MODE_VAL, 0);
+	regmap_write_bits(master->i3cg, I3CG_REG1(master->channel),
+			  SCL_IN_SW_MODE_VAL, SCL_IN_SW_MODE_VAL);
+	regmap_write_bits(master->i3cg, I3CG_REG1(master->channel),
+			  SDA_IN_SW_MODE_VAL, SDA_IN_SW_MODE_VAL);
+}
+
+static bool aspeed_i3c_fsm_exit_serv_ibi(struct aspeed_i3c_master *master)
+{
+	/*
+	 * Clear the IBI queue to enable the hardware to generate SCL and
+	 * begin detecting the T-bit low to stop reading IBI data.
+	 */
+	readl(master->regs + IBI_QUEUE_DATA);
+	if (FIELD_GET(CM_TFR_STS, readl(master->regs + PRESENT_STATE)) ==
+	    CM_TFR_STS_MASTER_SERV_IBI)
+		return false;
+	return true;
+}
+
+static void aspeed_i3c_gen_tbits_in(struct aspeed_i3c_master *master)
+{
+	bool is_idle;
+	int ret;
+
+	regmap_write_bits(master->i3cg, I3CG_REG1(master->channel),
+			  SDA_IN_SW_MODE_VAL, SDA_IN_SW_MODE_VAL);
+	regmap_write_bits(master->i3cg, I3CG_REG1(master->channel),
+			  SDA_IN_SW_MODE_EN, SDA_IN_SW_MODE_EN);
+
+	regmap_write_bits(master->i3cg, I3CG_REG1(master->channel),
+			  SDA_IN_SW_MODE_VAL, 0);
+	ret = readx_poll_timeout_atomic(aspeed_i3c_fsm_exit_serv_ibi, master, is_idle,
+					is_idle, 0, 2000000);
+	regmap_write_bits(master->i3cg, I3CG_REG1(master->channel),
+			  SDA_IN_SW_MODE_EN, 0);
+	if (ret)
+		dev_err(master->dev,
+			"Failed to exit the I3C fsm from %lx(MASTER_SERV_IBI): %d",
+			FIELD_GET(CM_TFR_STS,
+				  readl(master->regs + PRESENT_STATE)),
+			ret);
+}
+
+static bool aspeed_i3c_master_supports_ccc_cmd(struct i3c_master_controller *m,
+					   const struct i3c_ccc_cmd *cmd)
+{
+	if (cmd->ndests > 1)
+		return false;
+
+	switch (cmd->id) {
+	case I3C_CCC_ENEC(true):
+	case I3C_CCC_ENEC(false):
+	case I3C_CCC_DISEC(true):
+	case I3C_CCC_DISEC(false):
+	case I3C_CCC_ENTAS(0, true):
+	case I3C_CCC_ENTAS(0, false):
+	case I3C_CCC_RSTDAA(true):
+	case I3C_CCC_RSTDAA(false):
+	case I3C_CCC_ENTDAA:
+	case I3C_CCC_SETMWL(true):
+	case I3C_CCC_SETMWL(false):
+	case I3C_CCC_SETMRL(true):
+	case I3C_CCC_SETMRL(false):
+	case I3C_CCC_ENTHDR(0):
+	case I3C_CCC_SETDASA:
+	case I3C_CCC_SETNEWDA:
+	case I3C_CCC_GETMWL:
+	case I3C_CCC_GETMRL:
+	case I3C_CCC_GETPID:
+	case I3C_CCC_GETBCR:
+	case I3C_CCC_GETDCR:
+	case I3C_CCC_GETSTATUS:
+	case I3C_CCC_GETMXDS:
+	case I3C_CCC_GETHDRCAP:
+	case I3C_CCC_SETAASA:
+	case I3C_CCC_SETHID:
+	case I3C_CCC_DEVCTRL:
+		return true;
+	default:
+		return false;
+	}
+}
+
+static inline struct aspeed_i3c_master *
+to_aspeed_i3c_master(struct i3c_master_controller *master)
+{
+	return container_of(master, struct aspeed_i3c_master, base);
+}
+
+static void aspeed_i3c_master_iba_ctrl(struct aspeed_i3c_master *master, bool ctrl)
+{
+	ctrl ? writel(readl(master->regs + DEVICE_CTRL) | DEV_CTRL_IBA_INCLUDE,
+		      master->regs + DEVICE_CTRL) :
+	       writel(readl(master->regs + DEVICE_CTRL) & ~DEV_CTRL_IBA_INCLUDE,
+		      master->regs + DEVICE_CTRL);
+}
+
+static int aspeed_i3c_master_disable(struct aspeed_i3c_master *master)
+{
+	if (master->secondary)
+		aspeed_i3c_isolate_scl_sda(master, true);
+	writel(readl(master->regs + DEVICE_CTRL) & ~DEV_CTRL_ENABLE,
+	       master->regs + DEVICE_CTRL);
+	if (master->secondary) {
+		aspeed_i3c_toggle_scl_in(master, 8);
+		/* Clear the internal busy status */
+		aspeed_i3c_gen_stop_to_internal(master);
+		if (readl(master->regs + DEVICE_CTRL) & DEV_CTRL_ENABLE) {
+			dev_warn(master->dev,
+					"Failed to disable controller");
+			aspeed_i3c_isolate_scl_sda(master, false);
+			return -EACCES;
+		}
+		aspeed_i3c_isolate_scl_sda(master, false);
+	}
+	return 0;
+}
+
+static int aspeed_i3c_master_enable(struct aspeed_i3c_master *master)
+{
+	u32 wait_enable_us;
+
+	if (master->secondary)
+		aspeed_i3c_isolate_scl_sda(master, true);
+	writel(readl(master->regs + DEVICE_CTRL) | DEV_CTRL_ENABLE,
+	       master->regs + DEVICE_CTRL);
+	if (master->secondary) {
+		wait_enable_us =
+			DIV_ROUND_UP(master->timing.core_period *
+					     FIELD_GET(GENMASK(31, 16),
+						       readl(master->regs +
+							     BUS_FREE_TIMING)),
+				     NSEC_PER_USEC);
+		udelay(wait_enable_us);
+		aspeed_i3c_toggle_scl_in(master, 8);
+		if (!(readl(master->regs + DEVICE_CTRL) & DEV_CTRL_ENABLE)) {
+			dev_warn(master->dev, "Failed to enable controller");
+			aspeed_i3c_isolate_scl_sda(master, false);
+			return -EACCES;
+		}
+		aspeed_i3c_gen_stop_to_internal(master);
+		aspeed_i3c_isolate_scl_sda(master, false);
+	}
+
+	return 0;
+}
+
+static void aspeed_i3c_master_abort(struct aspeed_i3c_master *master)
+{
+	writel(readl(master->regs + DEVICE_CTRL) | DEV_CTRL_ABORT,
+	       master->regs + DEVICE_CTRL);
+}
+
+static int aspeed_i3c_master_enter_halt(struct aspeed_i3c_master *master, bool by_sw)
+{
+	u32 status;
+	int ret;
+
+	if (by_sw)
+		aspeed_i3c_master_abort(master);
+	ret = readl_poll_timeout_atomic(master->regs + PRESENT_STATE, status,
+					FIELD_GET(CM_TFR_STS, status) ==
+						CM_TFR_STS_MASTER_HALT,
+					10, 1000000);
+	if (ret)
+		dev_err(master->dev, "Enter halt status failed: %d %#x %#x\n",
+			ret, readl(master->regs + PRESENT_STATE),
+			readl(master->regs + QUEUE_STATUS_LEVEL));
+	return ret;
+}
+
+static int aspeed_i3c_master_reset_ctrl(struct aspeed_i3c_master *master, u32 rst_ctrl)
+{
+	u32 status, rst = rst_ctrl & RESET_CTRL_ALL;
+	int ret;
+
+	if (!rst)
+		return -EINVAL;
+	writel(rst, master->regs + RESET_CTRL);
+
+	ret = readl_poll_timeout_atomic(master->regs + RESET_CTRL, status,
+					!status, 10, 1000000);
+
+	if (ret)
+		dev_err(master->dev, "Reset %#x/%#x failed: %d\n", status, rst,
+			ret);
+	return ret;
+}
+
+static int aspeed_i3c_master_resume(struct aspeed_i3c_master *master)
+{
+	u32 status;
+	int ret;
+
+	writel(readl(master->regs + DEVICE_CTRL) | DEV_CTRL_RESUME,
+	       master->regs + DEVICE_CTRL);
+	ret = readl_poll_timeout_atomic(master->regs + PRESENT_STATE, status,
+					FIELD_GET(CM_TFR_STS, status) !=
+						CM_TFR_STS_MASTER_HALT,
+					10, 1000000);
+	if (ret)
+		dev_err(master->dev, "Exit halt status failed: %d %#x %#x\n",
+			ret, readl(master->regs + PRESENT_STATE),
+			readl(master->regs + QUEUE_STATUS_LEVEL));
+	return ret;
+}
+
+static void aspeed_i3c_master_set_role(struct aspeed_i3c_master *master)
+{
+	u32 reg;
+	u32 role = DEVICE_CTRL_ROLE_MASTER;
+
+	if (master->secondary)
+		role = DEVICE_CTRL_ROLE_SLAVE;
+
+	reg = readl(master->regs + DEVICE_CTRL_EXTENDED);
+	reg = (reg & ~DEVICE_CTRL_ROLE_MASK) | role;
+	writel(reg, master->regs + DEVICE_CTRL_EXTENDED);
+}
+
+static int aspeed_i3c_master_get_free_pos(struct aspeed_i3c_master *master)
+{
+	if (!(master->free_pos & GENMASK(master->maxdevs - 1, 0)))
+		return -ENOSPC;
+
+	return ffs(master->free_pos) - 1;
+}
+
+static void aspeed_i3c_master_init_group_dat(struct aspeed_i3c_master *master)
+{
+	struct aspeed_i3c_dev_group *dev_grp;
+	int i, j;
+	u32 def_set, def_clr;
+
+	def_clr = DEV_ADDR_TABLE_IBI_ADDR_MASK;
+
+	/* For now don't support Hot-Join */
+	def_set = DEV_ADDR_TABLE_DEV_NACK_RETRY | DEV_ADDR_TABLE_MR_REJECT | DEV_ADDR_TABLE_SIR_REJECT;
+
+	for (i = 0; i < MAX_GROUPS; i++) {
+		dev_grp = &master->dev_group[i];
+		dev_grp->hw_index = -1;
+		dev_grp->free_pos = ALL_DEVS_IN_GROUP_ARE_FREE;
+		dev_grp->mask.set = def_set;
+		dev_grp->mask.clr = def_clr;
+		for (j = 0; j < MAX_DEVS_IN_GROUP; j++)
+			dev_grp->dat[j] = 0;
+	}
+
+	for (i = 0; i < master->maxdevs; i++)
+		writel(def_set,
+		       master->regs +
+			       DEV_ADDR_TABLE_LOC(master->datstartaddr, i));
+}
+
+static int aspeed_i3c_master_set_group_dat(struct aspeed_i3c_master *master, u8 addr,
+				       u32 val)
+{
+	struct aspeed_i3c_dev_group *dev_grp = &master->dev_group[ADDR_GRP(addr)];
+	u8 idx = ADDR_HID(addr);
+
+	val &= ~DEV_ADDR_TABLE_DA_PARITY;
+	val |= FIELD_PREP(DEV_ADDR_TABLE_DA_PARITY, even_parity(addr));
+	dev_grp->dat[idx] = val;
+
+	if (val) {
+		dev_grp->free_pos &= ~BIT(idx);
+
+		/*
+		 * reserve the hw dat resource for the first member of the
+		 * group. all the members in the group share the same hw dat.
+		 */
+		if (dev_grp->hw_index == -1) {
+			dev_grp->hw_index = aspeed_i3c_master_get_free_pos(master);
+			if (dev_grp->hw_index < 0)
+				goto out;
+
+			master->free_pos &= ~BIT(dev_grp->hw_index);
+			val &= dev_grp->mask.clr;
+			val |= dev_grp->mask.set;
+			writel(val, master->regs + DEV_ADDR_TABLE_LOC(
+							   master->datstartaddr,
+							   dev_grp->hw_index));
+		}
+	} else {
+		dev_grp->free_pos |= BIT(idx);
+
+		/*
+		 * release the hw dat resource if all the members in the group
+		 * are free.
+		 */
+		if (dev_grp->free_pos == ALL_DEVS_IN_GROUP_ARE_FREE) {
+			writel(dev_grp->mask.set,
+			       master->regs +
+				       DEV_ADDR_TABLE_LOC(master->datstartaddr,
+							  dev_grp->hw_index));
+			master->free_pos |= BIT(dev_grp->hw_index);
+			dev_grp->hw_index = -1;
+		}
+	}
+out:
+	return dev_grp->hw_index;
+}
+
+static u32 aspeed_i3c_master_get_group_dat(struct aspeed_i3c_master *master, u8 addr)
+{
+	struct aspeed_i3c_dev_group *dev_grp = &master->dev_group[ADDR_GRP(addr)];
+
+	return dev_grp->dat[ADDR_HID(addr)];
+}
+
+static int aspeed_i3c_master_get_group_hw_index(struct aspeed_i3c_master *master,
+					    u8 addr)
+{
+	struct aspeed_i3c_dev_group *dev_grp = &master->dev_group[ADDR_GRP(addr)];
+
+	return dev_grp->hw_index;
+}
+
+static struct aspeed_i3c_dev_group *
+aspeed_i3c_master_get_group(struct aspeed_i3c_master *master, u8 addr)
+{
+	return &master->dev_group[ADDR_GRP(addr)];
+}
+
+static int aspeed_i3c_master_sync_hw_dat(struct aspeed_i3c_master *master, u8 addr)
+{
+	struct aspeed_i3c_dev_group *dev_grp = &master->dev_group[ADDR_GRP(addr)];
+	u32 dat = dev_grp->dat[ADDR_HID(addr)];
+	int hw_index = dev_grp->hw_index;
+
+	if (!dat || hw_index < 0)
+		return -1;
+
+	dat &= ~dev_grp->mask.clr;
+	dat |= dev_grp->mask.set;
+	writel(dat, master->regs +
+			    DEV_ADDR_TABLE_LOC(master->datstartaddr, hw_index));
+	return hw_index;
+}
+
+static void aspeed_i3c_master_wr_tx_fifo(struct aspeed_i3c_master *master,
+				     const u8 *bytes, int nbytes)
+{
+	/*
+	 * ensure all memory accesses are done before we move the data from
+	 * memory to the hardware FIFO
+	 */
+	wmb();
+
+	writesl(master->regs + RX_TX_DATA_PORT, bytes, nbytes / 4);
+	if (nbytes & 3) {
+		u32 tmp = 0;
+
+		memcpy(&tmp, bytes + (nbytes & ~3), nbytes & 3);
+		writesl(master->regs + RX_TX_DATA_PORT, &tmp, 1);
+		dev_dbg(master->dev, "TX data = %08x\n", tmp);
+	}
+}
+
+static void aspeed_i3c_master_read_fifo(struct aspeed_i3c_master *master, u32 fifo_reg,
+				    u8 *bytes, int nbytes)
+{
+	readsl(master->regs + fifo_reg, bytes, nbytes / 4);
+	if (nbytes & 3) {
+		u32 tmp;
+
+		readsl(master->regs + fifo_reg, &tmp, 1);
+		memcpy(bytes + (nbytes & ~3), &tmp, nbytes & 3);
+	}
+}
+
+static void aspeed_i3c_master_read_rx_fifo(struct aspeed_i3c_master *master,
+					      u8 *bytes, int nbytes)
+{
+	aspeed_i3c_master_read_fifo(master, RX_TX_DATA_PORT, bytes, nbytes);
+}
+
+static void aspeed_i3c_master_read_ibi_fifo(struct aspeed_i3c_master *master,
+					       u8 *bytes, int nbytes)
+{
+	aspeed_i3c_master_read_fifo(master, IBI_QUEUE_DATA, bytes, nbytes);
+}
+
+static struct aspeed_i3c_xfer *
+aspeed_i3c_master_alloc_xfer(struct aspeed_i3c_master *master, unsigned int ncmds)
+{
+	struct aspeed_i3c_xfer *xfer;
+
+	xfer = kzalloc(struct_size(xfer, cmds, ncmds), GFP_KERNEL);
+	if (!xfer)
+		return NULL;
+
+	INIT_LIST_HEAD(&xfer->node);
+	xfer->ncmds = ncmds;
+	xfer->ret = -ETIMEDOUT;
+
+	return xfer;
+}
+
+static void aspeed_i3c_master_free_xfer(struct aspeed_i3c_xfer *xfer)
+{
+	kfree(xfer);
+}
+
+static void aspeed_i3c_master_start_xfer_locked(struct aspeed_i3c_master *master)
+{
+	struct aspeed_i3c_xfer *xfer = master->xferqueue.cur;
+	unsigned int i;
+	u32 thld_ctrl;
+
+	if (!xfer)
+		return;
+
+	for (i = 0; i < xfer->ncmds; i++) {
+		struct aspeed_i3c_cmd *cmd = &xfer->cmds[i];
+
+		aspeed_i3c_master_wr_tx_fifo(master, cmd->tx_buf, cmd->tx_len);
+	}
+
+	thld_ctrl = readl(master->regs + QUEUE_THLD_CTRL);
+	thld_ctrl &= ~QUEUE_THLD_CTRL_RESP_BUF_MASK;
+	thld_ctrl |= QUEUE_THLD_CTRL_RESP_BUF(xfer->ncmds);
+	writel(thld_ctrl, master->regs + QUEUE_THLD_CTRL);
+
+	for (i = 0; i < xfer->ncmds; i++) {
+		struct aspeed_i3c_cmd *cmd = &xfer->cmds[i];
+
+		writel(cmd->cmd_hi, master->regs + COMMAND_QUEUE_PORT);
+		writel(cmd->cmd_lo, master->regs + COMMAND_QUEUE_PORT);
+	}
+}
+
+static void aspeed_i3c_master_enqueue_xfer(struct aspeed_i3c_master *master,
+				       struct aspeed_i3c_xfer *xfer)
+{
+	unsigned long flags;
+
+	init_completion(&xfer->comp);
+	spin_lock_irqsave(&master->xferqueue.lock, flags);
+	if (master->xferqueue.cur) {
+		list_add_tail(&xfer->node, &master->xferqueue.list);
+	} else {
+		master->xferqueue.cur = xfer;
+		aspeed_i3c_master_start_xfer_locked(master);
+	}
+	spin_unlock_irqrestore(&master->xferqueue.lock, flags);
+}
+
+static void aspeed_i3c_master_dequeue_xfer_locked(struct aspeed_i3c_master *master,
+					      struct aspeed_i3c_xfer *xfer)
+{
+	if (master->xferqueue.cur == xfer) {
+		master->xferqueue.cur = NULL;
+
+		aspeed_i3c_master_reset_ctrl(master, RESET_CTRL_XFER_QUEUES);
+	} else {
+		list_del_init(&xfer->node);
+	}
+}
+
+static void aspeed_i3c_master_dequeue_xfer(struct aspeed_i3c_master *master,
+				       struct aspeed_i3c_xfer *xfer)
+{
+	unsigned long flags;
+
+	spin_lock_irqsave(&master->xferqueue.lock, flags);
+	aspeed_i3c_master_dequeue_xfer_locked(master, xfer);
+	spin_unlock_irqrestore(&master->xferqueue.lock, flags);
+}
+
+static void aspeed_i3c_master_sir_handler(struct aspeed_i3c_master *master,
+				      u32 ibi_status)
+{
+	struct aspeed_i3c_i2c_dev_data *data;
+	struct i3c_dev_desc *dev;
+	struct i3c_ibi_slot *slot;
+	u8 addr = IBI_QUEUE_IBI_ADDR(ibi_status);
+	u8 length = IBI_QUEUE_STATUS_DATA_LEN(ibi_status);
+	u8 *buf;
+	bool data_consumed = false;
+
+	dev = master->ibi.slots[addr];
+	if (!dev) {
+		pr_warn("no matching dev\n");
+		goto out;
+	}
+
+	spin_lock(&master->ibi.lock);
+	data = i3c_dev_get_master_data(dev);
+	slot = i3c_generic_ibi_get_free_slot(data->ibi_pool);
+	if (!slot) {
+		pr_err("no free ibi slot\n");
+		goto out_unlock;
+	}
+	master->ibi.received_ibi_len[addr] += length;
+	if (master->ibi.received_ibi_len[addr] >
+	    slot->dev->ibi->max_payload_len) {
+		pr_err("received ibi payload %d > device requested buffer %d",
+		       master->ibi.received_ibi_len[addr],
+		       slot->dev->ibi->max_payload_len);
+		goto out_unlock;
+	}
+	if (ibi_status & IBI_QUEUE_STATUS_LAST_FRAG)
+		master->ibi.received_ibi_len[addr] = 0;
+	buf = slot->data;
+	/* prepend ibi status */
+	memcpy(buf, &ibi_status, sizeof(ibi_status));
+	buf += sizeof(ibi_status);
+
+	aspeed_i3c_master_read_ibi_fifo(master, buf, length);
+	slot->len = length + sizeof(ibi_status);
+	i3c_master_queue_ibi(dev, slot);
+	data_consumed = true;
+out_unlock:
+	spin_unlock(&master->ibi.lock);
+
+out:
+	/* Consume data from the FIFO if it's not been done already. */
+	if (!data_consumed) {
+		int nwords = (length + 3) >> 2;
+		int i;
+
+		for (i = 0; i < nwords; i++)
+			readl(master->regs + IBI_QUEUE_DATA);
+		if (FIELD_GET(CM_TFR_STS,
+			      readl(master->regs + PRESENT_STATE)) ==
+		    CM_TFR_STS_MASTER_SERV_IBI)
+			aspeed_i3c_gen_tbits_in(master);
+		master->ibi.received_ibi_len[addr] = 0;
+	}
+}
+
+static void aspeed_i3c_master_demux_ibis(struct aspeed_i3c_master *master)
+{
+	u32 nibi, status;
+	int i, ret;
+	u8 addr;
+
+	nibi = readl(master->regs + QUEUE_STATUS_LEVEL);
+	nibi = QUEUE_STATUS_IBI_STATUS_CNT(nibi);
+	if (!nibi)
+		return;
+	/*
+	 * Make sure that the function does not manage a queue number that
+	 * surpasses the tolerance level for the IBI buffer. Failing to
+	 * address this situation properly could lead to a bus hang.
+	 */
+	if (nibi > 16) {
+		dev_err(master->dev,
+			"The nibi %d surpasses the tolerance level for the IBI buffer\n",
+			nibi);
+		goto ibi_fifo_clear;
+	}
+
+	for (i = 0; i < nibi; i++) {
+		status = readl(master->regs + IBI_QUEUE_STATUS);
+		addr = IBI_QUEUE_IBI_ADDR(status);
+
+		/* FIXME: how to handle the unrecognized slave? */
+		if (status & IBI_QUEUE_STATUS_RSP_NACK) {
+			pr_warn_once("ibi from unrecognized slave %02x\n",
+				     addr);
+			goto ibi_fifo_clear;
+		}
+
+		if (IBI_TYPE_SIR(status))
+			aspeed_i3c_master_sir_handler(master, status);
+
+		if (IBI_TYPE_HJ(status))
+			queue_work(master->base.wq, &master->hj_work);
+
+		if (IBI_TYPE_MR(status))
+			pr_info("get mr from %02x\n", addr);
+	}
+	return;
+ibi_fifo_clear:
+	dev_err(master->dev, "Clear the ibi fifo try to avoid the bus hang\n");
+	aspeed_i3c_master_enter_halt(master, true);
+	ret = aspeed_i3c_master_reset_ctrl(master, RESET_CTRL_IBI_QUEUE);
+	if (ret)
+		dev_err(master->dev,
+			"Waiting for reset of IBI queue to complete TIMEOUT");
+	aspeed_i3c_master_resume(master);
+}
+
+static void aspeed_i3c_master_end_xfer_locked(struct aspeed_i3c_master *master, u32 isr)
+{
+	struct aspeed_i3c_xfer *xfer = master->xferqueue.cur;
+	int i, ret = 0;
+	u32 nresp;
+
+	if (!xfer)
+		return;
+
+	nresp = readl(master->regs + QUEUE_STATUS_LEVEL);
+	nresp = QUEUE_STATUS_LEVEL_RESP(nresp);
+
+	for (i = 0; i < nresp; i++) {
+		struct aspeed_i3c_cmd *cmd;
+		u32 resp;
+
+		resp = readl(master->regs + RESPONSE_QUEUE_PORT);
+
+		cmd = &xfer->cmds[RESPONSE_PORT_TID(resp)];
+		cmd->rx_len = RESPONSE_PORT_DATA_LEN(resp);
+		cmd->error = RESPONSE_PORT_ERR_STATUS(resp);
+		if (cmd->rx_len && !cmd->error)
+			aspeed_i3c_master_read_rx_fifo(master, cmd->rx_buf,
+						   cmd->rx_len);
+	}
+
+	for (i = 0; i < nresp; i++) {
+		switch (xfer->cmds[i].error) {
+		case RESPONSE_NO_ERROR:
+			break;
+		case RESPONSE_ERROR_PARITY:
+		case RESPONSE_ERROR_IBA_NACK:
+		case RESPONSE_ERROR_TRANSF_ABORT:
+		case RESPONSE_ERROR_CRC:
+		case RESPONSE_ERROR_FRAME:
+		case RESPONSE_ERROR_PEC_ERR:
+			ret = -EIO;
+			break;
+		case RESPONSE_ERROR_OVER_UNDER_FLOW:
+			ret = -ENOSPC;
+			break;
+		case RESPONSE_ERROR_I2C_W_NACK_ERR:
+		case RESPONSE_ERROR_ADDRESS_NACK:
+		default:
+			ret = -EINVAL;
+			break;
+		}
+	}
+
+	xfer->ret = ret;
+	complete(&xfer->comp);
+
+	if (ret < 0) {
+		/* Enter halt guarantee by the HW */
+		aspeed_i3c_master_enter_halt(master, false);
+		aspeed_i3c_master_dequeue_xfer_locked(master, xfer);
+		aspeed_i3c_master_resume(master);
+	}
+
+	xfer = list_first_entry_or_null(&master->xferqueue.list,
+					struct aspeed_i3c_xfer,
+					node);
+	if (xfer)
+		list_del_init(&xfer->node);
+
+	master->xferqueue.cur = xfer;
+	aspeed_i3c_master_start_xfer_locked(master);
+}
+
+struct i3c_scl_timing_cfg {
+	unsigned long fscl;
+	u16 period_hi;
+	u16 period_lo;
+};
+
+static struct i3c_scl_timing_cfg jesd403_timing_cfg[5] = {
+	{ .fscl = I3C_BUS_TYP_I3C_SCL_RATE, .period_hi = 40, .period_lo = 40 },
+	{ .fscl = I3C_BUS_SDR1_SCL_RATE, .period_hi = 50, .period_lo = 75 },
+	{ .fscl = I3C_BUS_SDR2_SCL_RATE, .period_hi = 65, .period_lo = 100 },
+	{ .fscl = I3C_BUS_SDR3_SCL_RATE, .period_hi = 100, .period_lo = 150 },
+	{ .fscl = I3C_BUS_SDR4_SCL_RATE, .period_hi = 200, .period_lo = 300 }
+};
+
+struct i3c_scl_timing_cfg *ast2600_i3c_jesd403_scl_search(unsigned long fscl)
+{
+	int i;
+
+	for (i = 0; i < 5; i++) {
+		if (fscl == jesd403_timing_cfg[i].fscl)
+			return &jesd403_timing_cfg[i];
+	}
+
+	/* use typical 12.5M SCL if not found */
+	return &jesd403_timing_cfg[0];
+}
+
+static int calc_i2c_clk(struct aspeed_i3c_master *master, unsigned long fscl,
+			u16 *hcnt, u16 *lcnt)
+{
+	unsigned long core_rate, core_period;
+	u32 period_cnt, margin;
+	u32 hcnt_min, lcnt_min;
+
+	core_rate = master->timing.core_rate;
+	core_period = master->timing.core_period;
+
+	if (fscl <= 100000) {
+		lcnt_min = DIV_ROUND_UP(I3C_BUS_I2C_STD_TLOW_MIN_NS +
+						I3C_BUS_I2C_STD_TF_MAX_NS,
+					core_period);
+		hcnt_min = DIV_ROUND_UP(I3C_BUS_I2C_STD_THIGH_MIN_NS +
+						I3C_BUS_I2C_STD_TR_MAX_NS,
+					core_period);
+	} else if (fscl <= 400000) {
+		lcnt_min = DIV_ROUND_UP(I3C_BUS_I2C_FM_TLOW_MIN_NS +
+						I3C_BUS_I2C_FM_TF_MAX_NS,
+					core_period);
+		hcnt_min = DIV_ROUND_UP(I3C_BUS_I2C_FM_THIGH_MIN_NS +
+						I3C_BUS_I2C_FM_TR_MAX_NS,
+					core_period);
+	} else {
+		lcnt_min = DIV_ROUND_UP(I3C_BUS_I2C_FMP_TLOW_MIN_NS +
+						I3C_BUS_I2C_FMP_TF_MAX_NS,
+					core_period);
+		hcnt_min = DIV_ROUND_UP(I3C_BUS_I2C_FMP_THIGH_MIN_NS +
+						I3C_BUS_I2C_FMP_TR_MAX_NS,
+					core_period);
+	}
+
+	period_cnt = DIV_ROUND_UP(core_rate, fscl);
+	margin = (period_cnt - hcnt_min - lcnt_min) >> 1;
+	*lcnt = lcnt_min + margin;
+	*hcnt = max(period_cnt - *lcnt, hcnt_min);
+
+	return 0;
+}
+
+static int aspeed_i3c_clk_cfg(struct aspeed_i3c_master *master)
+{
+	unsigned long core_rate, core_period;
+	u32 scl_timing;
+	u16 hcnt, lcnt;
+
+	core_rate = master->timing.core_rate;
+	core_period = master->timing.core_period;
+
+	/* I3C PP mode */
+	if (master->timing.i3c_pp_scl_high && master->timing.i3c_pp_scl_low) {
+		hcnt = DIV_ROUND_CLOSEST(master->timing.i3c_pp_scl_high,
+					 core_period);
+		lcnt = DIV_ROUND_CLOSEST(master->timing.i3c_pp_scl_low,
+					 core_period);
+	} else if (master->base.jdec_spd) {
+		struct i3c_scl_timing_cfg *pp_timing;
+
+		pp_timing = ast2600_i3c_jesd403_scl_search(
+			master->base.bus.scl_rate.i3c);
+		hcnt = DIV_ROUND_UP(pp_timing->period_hi, core_period);
+		lcnt = DIV_ROUND_UP(pp_timing->period_lo, core_period);
+	} else {
+		hcnt = DIV_ROUND_UP(I3C_BUS_THIGH_MAX_NS, core_period) - 1;
+		if (hcnt < SCL_I3C_TIMING_CNT_MIN)
+			hcnt = SCL_I3C_TIMING_CNT_MIN;
+
+		lcnt = DIV_ROUND_UP(core_rate, I3C_BUS_TYP_I3C_SCL_RATE) - hcnt;
+		if (lcnt < SCL_I3C_TIMING_CNT_MIN)
+			lcnt = SCL_I3C_TIMING_CNT_MIN;
+	}
+	hcnt = min_t(u16, hcnt, FIELD_MAX(SCL_I3C_TIMING_HCNT));
+	lcnt = min_t(u16, lcnt, FIELD_MAX(SCL_I3C_TIMING_LCNT));
+	scl_timing = FIELD_PREP(SCL_I3C_TIMING_HCNT, hcnt) |
+		     FIELD_PREP(SCL_I3C_TIMING_LCNT, lcnt);
+	writel(scl_timing, master->regs + SCL_I3C_PP_TIMING);
+
+	/* I3C OD mode:
+	 * User defined
+	 *     check if hcnt/lcnt exceed the max value of the register
+	 *
+	 * JESD403 timing constrain for I2C/I3C OP mode
+	 *     tHIGH > 260, tLOW > 500 (same with MIPI 1.1 FMP constrain)
+	 *
+	 * MIPI 1.1 timing constrain for I3C OP mode
+	 *     tHIGH < 41, tLOW > 200
+	 */
+	if (master->timing.i3c_od_scl_high && master->timing.i3c_od_scl_low) {
+		hcnt = DIV_ROUND_CLOSEST(master->timing.i3c_od_scl_high,
+					 core_period);
+		lcnt = DIV_ROUND_CLOSEST(master->timing.i3c_od_scl_low,
+					 core_period);
+	} else if (master->base.jdec_spd) {
+		calc_i2c_clk(master, I3C_BUS_I2C_FM_PLUS_SCL_RATE, &hcnt, &lcnt);
+	} else {
+		lcnt = DIV_ROUND_UP(I3C_BUS_TLOW_OD_MIN_NS, core_period);
+		scl_timing = readl(master->regs + SCL_I3C_PP_TIMING);
+		hcnt = FIELD_GET(SCL_I3C_TIMING_HCNT, scl_timing);
+	}
+	hcnt = min_t(u16, hcnt, FIELD_MAX(SCL_I3C_TIMING_HCNT));
+	lcnt = min_t(u16, lcnt, FIELD_MAX(SCL_I3C_TIMING_LCNT));
+	scl_timing = FIELD_PREP(SCL_I3C_TIMING_HCNT, hcnt) |
+		     FIELD_PREP(SCL_I3C_TIMING_LCNT, lcnt);
+	writel(scl_timing, master->regs + SCL_I3C_OD_TIMING);
+
+	/* I2C FM mode */
+	calc_i2c_clk(master, master->base.bus.scl_rate.i2c, &hcnt, &lcnt);
+	scl_timing = FIELD_PREP(SCL_I2C_FM_TIMING_HCNT, hcnt) |
+		     FIELD_PREP(SCL_I2C_FM_TIMING_LCNT, lcnt);
+	writel(scl_timing, master->regs + SCL_I2C_FM_TIMING);
+
+	/*
+	 * I3C register 0xd4[15:0] BUS_FREE_TIMING used to control several parameters:
+	 * - tCAS & tCASr (tHD_STA in JESD403)
+	 * - tCBP & tCBPr (tSU_STO in JESD403)
+	 * - bus free time between a STOP condition and a START condition
+	 *
+	 * The constraints of these two parameters are different in different bus contexts
+	 * - MIPI I3C, mixed bus: 0xd4[15:0] = I2C SCL low period (handled in aspeed_i2c_clk_cfg)
+	 * - MIPI I3C, pure bus : 0xd4[15:0] = I3C SCL PP low period
+	 * - JESD403            : 0xd4[15:0] = I3C SCL OD low period
+	 */
+	if (!(readl(master->regs + DEVICE_CTRL) & DEV_CTRL_I2C_SLAVE_PRESENT)) {
+		if (master->base.jdec_spd)
+			scl_timing = readl(master->regs + SCL_I3C_OD_TIMING);
+		else
+			scl_timing = readl(master->regs + SCL_I3C_PP_TIMING);
+
+		lcnt = FIELD_GET(SCL_I3C_TIMING_LCNT, scl_timing);
+		scl_timing = BUS_I3C_AVAILABLE_TIME(0xffff);
+		scl_timing |= BUS_I3C_MST_FREE(lcnt);
+		writel(scl_timing, master->regs + BUS_FREE_TIMING);
+	}
+
+	/* Extend SDR: use PP mode hcnt */
+	scl_timing = readl(master->regs + SCL_I3C_PP_TIMING);
+	hcnt = scl_timing >> 16;
+	lcnt = DIV_ROUND_UP(core_rate, I3C_BUS_SDR1_SCL_RATE) - hcnt;
+	scl_timing = SCL_EXT_LCNT_1(lcnt);
+	lcnt = DIV_ROUND_UP(core_rate, I3C_BUS_SDR2_SCL_RATE) - hcnt;
+	scl_timing |= SCL_EXT_LCNT_2(lcnt);
+	lcnt = DIV_ROUND_UP(core_rate, I3C_BUS_SDR3_SCL_RATE) - hcnt;
+	scl_timing |= SCL_EXT_LCNT_3(lcnt);
+	lcnt = DIV_ROUND_UP(core_rate, I3C_BUS_SDR4_SCL_RATE) - hcnt;
+	scl_timing |= SCL_EXT_LCNT_4(lcnt);
+	writel(scl_timing, master->regs + SCL_EXT_LCNT_TIMING);
+
+	ast_clrsetbits(master->regs + SCL_EXT_TERMN_LCNT_TIMING, GENMASK(3, 0),
+		      I3C_BUS_EXT_TERMN_CNT);
+
+	return 0;
+}
+
+static int aspeed_i2c_clk_cfg(struct aspeed_i3c_master *master)
+{
+	unsigned long core_rate, core_period;
+	u16 hcnt, lcnt;
+	u32 scl_timing;
+
+	core_rate = master->timing.core_rate;
+	core_period = master->timing.core_period;
+
+	calc_i2c_clk(master, I3C_BUS_I2C_FM_PLUS_SCL_RATE, &hcnt, &lcnt);
+	hcnt = min_t(u16, hcnt, FIELD_MAX(SCL_I2C_FMP_TIMING_HCNT));
+	lcnt = min_t(u16, lcnt, FIELD_MAX(SCL_I2C_FMP_TIMING_LCNT));
+	scl_timing = FIELD_PREP(SCL_I2C_FMP_TIMING_HCNT, hcnt) |
+		     FIELD_PREP(SCL_I2C_FMP_TIMING_LCNT, lcnt);
+	writel(scl_timing, master->regs + SCL_I2C_FMP_TIMING);
+
+	calc_i2c_clk(master, master->base.bus.scl_rate.i2c, &hcnt, &lcnt);
+	scl_timing = FIELD_PREP(SCL_I2C_FM_TIMING_HCNT, hcnt) |
+		     FIELD_PREP(SCL_I2C_FM_TIMING_LCNT, lcnt);
+	writel(scl_timing, master->regs + SCL_I2C_FM_TIMING);
+
+	scl_timing = BUS_I3C_AVAILABLE_TIME(0xffff);
+	scl_timing |= BUS_I3C_MST_FREE(lcnt);
+	writel(scl_timing, master->regs + BUS_FREE_TIMING);
+	writel(readl(master->regs + DEVICE_CTRL) | DEV_CTRL_I2C_SLAVE_PRESENT,
+	       master->regs + DEVICE_CTRL);
+
+	return 0;
+}
+
+static int aspeed_i3c_master_set_info(struct aspeed_i3c_master *master,
+				       struct i3c_device_info *info)
+{
+#define ASPEED_SCU_REV_ID_REG 0x14
+#define ASPEED_HW_REV(x) (((x)&GENMASK(31, 16)) >> 16)
+
+	struct regmap *scu;
+	unsigned int reg;
+	u32 part_id, inst_id;
+
+	writel(PID_MANUF_ID_ASPEED << 1, master->regs + SLV_MIPI_PID_VALUE);
+
+	scu = syscon_regmap_lookup_by_phandle(master->dev->of_node, "aspeed,scu");
+	if (IS_ERR(scu)) {
+		dev_err(master->dev, "cannot to find SCU regmap\n");
+		return -ENODEV;
+	}
+	regmap_read(scu, ASPEED_SCU_REV_ID_REG, &reg);
+	part_id = ASPEED_HW_REV(reg);
+	inst_id = master->base.bus.id;
+
+	reg = SLV_PID_PART_ID(part_id) | SLV_PID_INST_ID(inst_id) |
+	      SLV_PID_DCR(0);
+	writel(reg, master->regs + SLV_PID_VALUE);
+
+	reg = readl(master->regs + SLV_CHAR_CTRL);
+	info->dcr = SLV_CHAR_GET_DCR(reg);
+	info->bcr = SLV_CHAR_GET_BCR(reg);
+	info->pid = (u64)readl(master->regs + SLV_MIPI_PID_VALUE) << 32;
+	info->pid |= readl(master->regs + SLV_PID_VALUE);
+	info->hdr_cap = I3C_CCC_HDR_MODE(I3C_HDR_DDR);
+
+	return 0;
+};
+
+static int aspeed_i3c_master_bus_init(struct i3c_master_controller *m)
+{
+	struct aspeed_i3c_master *master = to_aspeed_i3c_master(m);
+	struct i3c_bus *bus = i3c_master_get_bus(m);
+	struct i3c_device_info info = { };
+	u32 thld_ctrl;
+	int ret;
+
+	aspeed_i3c_master_set_role(master);
+
+	switch (bus->mode) {
+	case I3C_BUS_MODE_MIXED_FAST:
+	case I3C_BUS_MODE_MIXED_LIMITED:
+		ret = aspeed_i2c_clk_cfg(master);
+		if (ret)
+			return ret;
+		fallthrough;
+	case I3C_BUS_MODE_PURE:
+		ret = aspeed_i3c_clk_cfg(master);
+		if (ret)
+			return ret;
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	thld_ctrl = readl(master->regs + QUEUE_THLD_CTRL);
+	thld_ctrl &= ~QUEUE_THLD_CTRL_RESP_BUF_MASK;
+	writel(thld_ctrl, master->regs + QUEUE_THLD_CTRL);
+
+	thld_ctrl = readl(master->regs + DATA_BUFFER_THLD_CTRL);
+	thld_ctrl &= ~DATA_BUFFER_THLD_CTRL_RX_BUF;
+	writel(thld_ctrl, master->regs + DATA_BUFFER_THLD_CTRL);
+
+	writel(INTR_ALL, master->regs + INTR_STATUS);
+	if (master->secondary) {
+		writel(INTR_2ND_MASTER_MASK, master->regs + INTR_STATUS_EN);
+		/*
+		 * No need for INTR_IBI_UPDATED_STAT signal, check this bit
+		 * when INTR_RESP_READY_STAT signal is up.  This can guarantee
+		 * the SIR payload is ACKed by the master.
+		 */
+		writel(INTR_2ND_MASTER_MASK & ~INTR_IBI_UPDATED_STAT,
+		       master->regs + INTR_SIGNAL_EN);
+	} else {
+		writel(INTR_MASTER_MASK, master->regs + INTR_STATUS_EN);
+		writel(INTR_MASTER_MASK, master->regs + INTR_SIGNAL_EN);
+	}
+
+	memset(&info, 0, sizeof(info));
+	ret = aspeed_i3c_master_set_info(master, &info);
+	if (ret < 0)
+		return ret;
+
+	ret = i3c_master_get_free_addr(m, 0);
+	if (ret < 0)
+		return ret;
+
+	if (master->secondary)
+		writel(DEV_ADDR_STATIC_ADDR_VALID | DEV_ADDR_STATIC(ret),
+		       master->regs + DEVICE_ADDR);
+	else
+		writel(DEV_ADDR_DYNAMIC_ADDR_VALID | DEV_ADDR_DYNAMIC(ret),
+		       master->regs + DEVICE_ADDR);
+
+	info.dyn_addr = ret;
+
+	ret = i3c_master_set_info(&master->base, &info);
+	if (ret)
+		return ret;
+
+	thld_ctrl = readl(master->regs + QUEUE_THLD_CTRL);
+	thld_ctrl &=
+		~(QUEUE_THLD_CTRL_IBI_STA_MASK | QUEUE_THLD_CTRL_IBI_DAT_MASK);
+	thld_ctrl |= QUEUE_THLD_CTRL_IBI_STA(1);
+	thld_ctrl |= QUEUE_THLD_CTRL_IBI_DAT(MAX_IBI_FRAG_SIZE >> 2);
+	writel(thld_ctrl, master->regs + QUEUE_THLD_CTRL);
+
+	writel(IBI_REQ_REJECT_ALL, master->regs + IBI_SIR_REQ_REJECT);
+	writel(IBI_REQ_REJECT_ALL, master->regs + IBI_MR_REQ_REJECT);
+
+	/* For now don't support Hot-Join */
+	ast_setbits(master->regs + DEVICE_CTRL,
+		   DEV_CTRL_AUTO_HJ_DISABLE |
+		   DEV_CTRL_HOT_JOIN_NACK |
+		   DEV_CRTL_IBI_PAYLOAD_EN);
+
+	ret = aspeed_i3c_master_enable(master);
+	if (ret)
+		return ret;
+	/* workaround for aspeed slave devices.  The aspeed slave devices need
+	 * for a dummy ccc and resume before accessing. Hide this workarond here
+	 * and later the i3c subsystem code will do the rstdaa again.
+	 */
+	if ((!master->secondary) &&
+	    (master->base.jdec_spd && master->base.bus.mode == I3C_BUS_MODE_PURE))
+		i3c_master_rstdaa_locked(m, I3C_BROADCAST_ADDR);
+
+	return 0;
+}
+
+static void aspeed_i3c_master_bus_cleanup(struct i3c_master_controller *m)
+{
+	struct aspeed_i3c_master *master = to_aspeed_i3c_master(m);
+
+	aspeed_i3c_master_disable(master);
+}
+
+static void aspeed_i3c_master_bus_reset(struct i3c_master_controller *m)
+{
+	struct aspeed_i3c_master *master = to_aspeed_i3c_master(m);
+	u32 reset;
+	int i;
+
+	if (master->base.jdec_spd) {
+		reset = RESET_CTRL_BUS |
+			FIELD_PREP(RESET_CTRL_BUS_RESET_TYPE, BUS_RESET_TYPE_SCL_LOW);
+
+		writel(reset, master->regs + RESET_CTRL);
+	} else {
+		regmap_write_bits(master->i3cg, I3CG_REG1(master->channel),
+				  SDA_OUT_SW_MODE_VAL | SCL_OUT_SW_MODE_VAL,
+				  SDA_OUT_SW_MODE_VAL | SCL_OUT_SW_MODE_VAL);
+		regmap_write_bits(master->i3cg, I3CG_REG1(master->channel),
+				  SDA_SW_MODE_OE | SCL_SW_MODE_OE,
+				  SDA_SW_MODE_OE | SCL_SW_MODE_OE);
+		regmap_write_bits(master->i3cg, I3CG_REG1(master->channel),
+				  SDA_OUT_SW_MODE_EN | SCL_OUT_SW_MODE_EN,
+				  SDA_OUT_SW_MODE_EN | SCL_OUT_SW_MODE_EN);
+		regmap_write_bits(master->i3cg, I3CG_REG1(master->channel),
+				  SDA_IN_SW_MODE_VAL | SCL_IN_SW_MODE_VAL,
+				  SDA_IN_SW_MODE_VAL | SCL_IN_SW_MODE_VAL);
+		regmap_write_bits(master->i3cg, I3CG_REG1(master->channel),
+				  SDA_IN_SW_MODE_EN | SCL_IN_SW_MODE_EN,
+				  SDA_IN_SW_MODE_EN | SCL_IN_SW_MODE_EN);
+		regmap_write_bits(master->i3cg, I3CG_REG1(master->channel),
+				  SCL_OUT_SW_MODE_VAL, 0);
+		for (i = 0; i < 7; i++) {
+			regmap_write_bits(master->i3cg, I3CG_REG1(master->channel),
+					  SDA_OUT_SW_MODE_VAL, 0);
+			regmap_write_bits(master->i3cg, I3CG_REG1(master->channel),
+					  SDA_OUT_SW_MODE_VAL,
+					  SDA_OUT_SW_MODE_VAL);
+		}
+		regmap_write_bits(master->i3cg, I3CG_REG1(master->channel),
+				  SCL_OUT_SW_MODE_VAL, SCL_OUT_SW_MODE_VAL);
+		regmap_write_bits(master->i3cg, I3CG_REG1(master->channel),
+				  SDA_OUT_SW_MODE_VAL, 0);
+		regmap_write_bits(master->i3cg, I3CG_REG1(master->channel),
+				  SDA_OUT_SW_MODE_VAL, SDA_OUT_SW_MODE_VAL);
+		regmap_write_bits(master->i3cg, I3CG_REG1(master->channel),
+				  SDA_OUT_SW_MODE_EN | SCL_OUT_SW_MODE_EN, 0);
+		regmap_write_bits(master->i3cg, I3CG_REG1(master->channel),
+				  SDA_IN_SW_MODE_EN | SCL_IN_SW_MODE_EN, 0);
+	}
+}
+
+static int aspeed_i3c_ccc_set(struct aspeed_i3c_master *master,
+			  struct i3c_ccc_cmd *ccc)
+{
+	struct aspeed_i3c_xfer *xfer;
+	struct aspeed_i3c_cmd *cmd;
+	int ret, pos = 0;
+
+	if (ccc->id & I3C_CCC_DIRECT) {
+		pos = aspeed_i3c_master_sync_hw_dat(master, ccc->dests[0].addr);
+		if (pos < 0)
+			return pos;
+	}
+
+	xfer = aspeed_i3c_master_alloc_xfer(master, 1);
+	if (!xfer)
+		return -ENOMEM;
+
+	cmd = xfer->cmds;
+	cmd->tx_buf = ccc->dests[0].payload.data;
+	cmd->tx_len = ccc->dests[0].payload.len;
+
+	cmd->cmd_hi = COMMAND_PORT_ARG_DATA_LEN(ccc->dests[0].payload.len) |
+		      COMMAND_PORT_TRANSFER_ARG | COMMAND_PORT_ARG_DBP(ccc->db);
+
+	cmd->cmd_lo = COMMAND_PORT_CP |
+		      COMMAND_PORT_DEV_INDEX(pos) |
+		      COMMAND_PORT_CMD(ccc->id) |
+		      COMMAND_PORT_TOC |
+		      COMMAND_PORT_ROC |
+		      COMMAND_PORT_DBP(ccc->dbp);
+
+	if (ccc->id == I3C_CCC_SETHID || ccc->id == I3C_CCC_DEVCTRL)
+		cmd->cmd_lo |= COMMAND_PORT_SPEED(SPEED_I3C_I2C_FM);
+
+	dev_dbg(master->dev, "%s:cmd_hi=0x%08x cmd_lo=0x%08x tx_len=%d id=%x\n",
+		__func__, cmd->cmd_hi, cmd->cmd_lo, cmd->tx_len, ccc->id);
+
+	aspeed_i3c_master_enqueue_xfer(master, xfer);
+	if (!wait_for_completion_timeout(&xfer->comp, XFER_TIMEOUT)) {
+		aspeed_i3c_master_enter_halt(master, true);
+		aspeed_i3c_master_dequeue_xfer(master, xfer);
+		aspeed_i3c_master_resume(master);
+	}
+
+	ret = xfer->ret;
+	if (ret)
+		dev_err(master->dev, "xfer error: %x\n", xfer->cmds[0].error);
+	if (xfer->cmds[0].error == RESPONSE_ERROR_IBA_NACK)
+		ccc->err = I3C_ERROR_M2;
+
+	aspeed_i3c_master_free_xfer(xfer);
+
+	return ret;
+}
+
+static int aspeed_i3c_ccc_get(struct aspeed_i3c_master *master, struct i3c_ccc_cmd *ccc)
+{
+	struct aspeed_i3c_xfer *xfer;
+	struct aspeed_i3c_cmd *cmd;
+	int ret, pos;
+
+	pos = aspeed_i3c_master_sync_hw_dat(master, ccc->dests[0].addr);
+	if (pos < 0)
+		return pos;
+
+	xfer = aspeed_i3c_master_alloc_xfer(master, 1);
+	if (!xfer)
+		return -ENOMEM;
+
+	cmd = xfer->cmds;
+	cmd->rx_buf = ccc->dests[0].payload.data;
+	cmd->rx_len = ccc->dests[0].payload.len;
+
+	cmd->cmd_hi = COMMAND_PORT_ARG_DATA_LEN(ccc->dests[0].payload.len) |
+		      COMMAND_PORT_TRANSFER_ARG | COMMAND_PORT_ARG_DBP(ccc->db);
+
+	cmd->cmd_lo = COMMAND_PORT_READ_TRANSFER |
+		      COMMAND_PORT_CP |
+		      COMMAND_PORT_DEV_INDEX(pos) |
+		      COMMAND_PORT_CMD(ccc->id) |
+		      COMMAND_PORT_TOC |
+		      COMMAND_PORT_ROC |
+		      COMMAND_PORT_DBP(ccc->dbp);
+
+	dev_dbg(master->dev, "%s:cmd_hi=0x%08x cmd_lo=0x%08x rx_len=%d id=%x\n",
+		__func__, cmd->cmd_hi, cmd->cmd_lo, cmd->rx_len, ccc->id);
+
+	aspeed_i3c_master_enqueue_xfer(master, xfer);
+	if (!wait_for_completion_timeout(&xfer->comp, XFER_TIMEOUT)) {
+		aspeed_i3c_master_enter_halt(master, true);
+		aspeed_i3c_master_dequeue_xfer(master, xfer);
+		aspeed_i3c_master_resume(master);
+	}
+
+	ret = xfer->ret;
+	if (ret)
+		dev_err(master->dev, "xfer error: %x\n", xfer->cmds[0].error);
+	if (xfer->cmds[0].error == RESPONSE_ERROR_IBA_NACK)
+		ccc->err = I3C_ERROR_M2;
+	aspeed_i3c_master_free_xfer(xfer);
+
+	return ret;
+}
+
+static int aspeed_i3c_master_send_ccc_cmd(struct i3c_master_controller *m,
+				      struct i3c_ccc_cmd *ccc)
+{
+	struct aspeed_i3c_master *master = to_aspeed_i3c_master(m);
+	int ret = 0;
+
+	if (ccc->id == I3C_CCC_ENTDAA)
+		return -EINVAL;
+
+	dev_dbg(master->dev, "ccc-id %02x rnw=%d\n", ccc->id, ccc->rnw);
+
+	if (ccc->rnw)
+		ret = aspeed_i3c_ccc_get(master, ccc);
+	else
+		ret = aspeed_i3c_ccc_set(master, ccc);
+
+	dev_err(master->dev, "ccc-id %02x rnw=%d, ret = %d", ccc->id, ccc->rnw, ret);
+
+	return ret;
+}
+
+#define IS_MANUF_ID_ASPEED(x) (I3C_PID_MANUF_ID(x) == PID_MANUF_ID_ASPEED)
+#define IS_PART_ID_AST2600_SERIES(x)                                           \
+	((I3C_PID_PART_ID(x) & PID_PART_ID_AST2600_SERIES) ==                  \
+	 PID_PART_ID_AST2600_SERIES)
+#define IS_PART_ID_AST1030_A0(x)                                               \
+	((I3C_PID_PART_ID(x) & PID_PART_ID_AST1030_A0) ==                      \
+	 PID_PART_ID_AST1030_A0)
+
+static int aspeed_i3c_master_daa(struct i3c_master_controller *m)
+{
+	struct aspeed_i3c_master *master = to_aspeed_i3c_master(m);
+	struct aspeed_i3c_xfer *xfer;
+	struct aspeed_i3c_cmd *cmd;
+	u32 olddevs, newdevs, dat;
+	u8 p, last_addr = 0;
+	int ret, pos, ndevs;
+
+	olddevs = ~(master->free_pos);
+	ndevs = 0;
+
+	/* Prepare DAT before launching DAA. */
+	for (pos = 0; pos < master->maxdevs; pos++) {
+		if (olddevs & BIT(pos))
+			continue;
+
+		ret = i3c_master_get_free_addr(m, last_addr + 1);
+		if (ret < 0)
+			break;
+
+		ndevs++;
+
+		master->addrs[pos] = ret;
+		p = even_parity(ret);
+		last_addr = ret;
+
+		dat = readl(master->regs +
+			    DEV_ADDR_TABLE_LOC(master->datstartaddr, pos));
+		dat &= ~(DEV_ADDR_TABLE_DYNAMIC_ADDR |
+			 DEV_ADDR_TABLE_DA_PARITY);
+		dat |= FIELD_PREP(DEV_ADDR_TABLE_DYNAMIC_ADDR, ret) |
+		       FIELD_PREP(DEV_ADDR_TABLE_DA_PARITY, p);
+		writel(dat, master->regs + DEV_ADDR_TABLE_LOC(
+						   master->datstartaddr, pos));
+	}
+
+	if (!ndevs)
+		return -ENOSPC;
+
+	xfer = aspeed_i3c_master_alloc_xfer(master, 1);
+	if (!xfer)
+		return -ENOMEM;
+
+	pos = aspeed_i3c_master_get_free_pos(master);
+	if (pos < 0) {
+		aspeed_i3c_master_free_xfer(xfer);
+		return pos;
+	}
+	cmd = &xfer->cmds[0];
+	cmd->cmd_hi = 0x1;
+	cmd->cmd_lo = COMMAND_PORT_DEV_COUNT(ndevs) |
+		      COMMAND_PORT_DEV_INDEX(pos) |
+		      COMMAND_PORT_CMD(I3C_CCC_ENTDAA) |
+		      COMMAND_PORT_ADDR_ASSGN_CMD |
+		      COMMAND_PORT_TOC |
+		      COMMAND_PORT_ROC;
+
+	aspeed_i3c_master_enqueue_xfer(master, xfer);
+	if (!wait_for_completion_timeout(&xfer->comp, XFER_TIMEOUT)) {
+		aspeed_i3c_master_enter_halt(master, true);
+		aspeed_i3c_master_dequeue_xfer(master, xfer);
+		aspeed_i3c_master_resume(master);
+	}
+
+	newdevs = GENMASK(ndevs - cmd->rx_len - 1, 0) << pos;
+	for (pos = 0; pos < master->maxdevs; pos++) {
+		if (newdevs & BIT(pos)) {
+			u32 addr;
+
+			dat = GET_DAT_FROM_POS(master, pos);
+			addr = FIELD_GET(DEV_ADDR_TABLE_DYNAMIC_ADDR, dat);
+
+			aspeed_i3c_master_set_group_dat(master, addr, dat);
+			i3c_master_add_i3c_dev_locked(m, addr);
+		}
+
+		/* cleanup the free HW DATs */
+		if (master->free_pos & BIT(pos)) {
+			dat = readl(
+				master->regs +
+				DEV_ADDR_TABLE_LOC(master->datstartaddr, pos));
+			dat &= ~(DEV_ADDR_TABLE_DYNAMIC_ADDR |
+				 DEV_ADDR_TABLE_DA_PARITY);
+			dat |= FIELD_PREP(DEV_ADDR_TABLE_DA_PARITY,
+					  even_parity(0));
+			writel(dat, master->regs +
+					    DEV_ADDR_TABLE_LOC(
+						    master->datstartaddr, pos));
+		}
+	}
+
+	aspeed_i3c_master_free_xfer(xfer);
+
+	return 0;
+}
+#ifdef CONFIG_AST2600_I3C_CCC_WORKAROUND
+/*
+ * Provide an interface for sending CCC from userspace.  Especially for the
+ * transfers with PEC and direct CCC.
+ */
+static int aspeed_i3c_master_ccc_xfers(struct i3c_dev_desc *dev,
+				    struct i3c_priv_xfer *i3c_xfers,
+				    int i3c_nxfers)
+{
+	struct aspeed_i3c_i2c_dev_data *data = i3c_dev_get_master_data(dev);
+	struct i3c_master_controller *m = i3c_dev_get_master(dev);
+	struct aspeed_i3c_master *master = to_aspeed_i3c_master(m);
+	struct aspeed_i3c_xfer *xfer;
+	int i, ret = 0;
+	struct aspeed_i3c_cmd *cmd_ccc;
+
+	xfer = aspeed_i3c_master_alloc_xfer(master, i3c_nxfers);
+	if (!xfer)
+		return -ENOMEM;
+
+	/* i3c_xfers[0] handles the CCC data */
+	cmd_ccc = &xfer->cmds[0];
+	cmd_ccc->cmd_hi = COMMAND_PORT_ARG_DATA_LEN(i3c_xfers[0].len - 1) |
+			  COMMAND_PORT_TRANSFER_ARG;
+	cmd_ccc->tx_buf = i3c_xfers[0].data.out + 1;
+	cmd_ccc->tx_len = i3c_xfers[0].len - 1;
+	cmd_ccc->cmd_lo = COMMAND_PORT_SPEED(dev->info.max_write_ds);
+	cmd_ccc->cmd_lo |= COMMAND_PORT_TID(0) |
+			   COMMAND_PORT_DEV_INDEX(master->maxdevs - 1) |
+			   COMMAND_PORT_ROC;
+	if (i3c_nxfers == 1)
+		cmd_ccc->cmd_lo |= COMMAND_PORT_TOC;
+
+	dev_dbg(master->dev,
+		"%s:cmd_ccc_hi=0x%08x cmd_ccc_lo=0x%08x tx_len=%d\n", __func__,
+		cmd_ccc->cmd_hi, cmd_ccc->cmd_lo, cmd_ccc->tx_len);
+
+	for (i = 1; i < i3c_nxfers; i++) {
+		struct aspeed_i3c_cmd *cmd = &xfer->cmds[i];
+
+		cmd->cmd_hi = COMMAND_PORT_ARG_DATA_LEN(i3c_xfers[i].len) |
+			COMMAND_PORT_TRANSFER_ARG;
+
+		if (i3c_xfers[i].rnw) {
+			cmd->rx_buf = i3c_xfers[i].data.in;
+			cmd->rx_len = i3c_xfers[i].len;
+			cmd->cmd_lo = COMMAND_PORT_READ_TRANSFER |
+				      COMMAND_PORT_SPEED(dev->info.max_read_ds);
+
+		} else {
+			cmd->tx_buf = i3c_xfers[i].data.out;
+			cmd->tx_len = i3c_xfers[i].len;
+			cmd->cmd_lo =
+				COMMAND_PORT_SPEED(dev->info.max_write_ds);
+		}
+
+		cmd->cmd_lo |= COMMAND_PORT_TID(i) |
+			       COMMAND_PORT_DEV_INDEX(data->index) |
+			       COMMAND_PORT_ROC;
+
+		if (i == (i3c_nxfers - 1))
+			cmd->cmd_lo |= COMMAND_PORT_TOC;
+
+		dev_dbg(master->dev,
+			"%s:cmd_hi=0x%08x cmd_lo=0x%08x tx_len=%d rx_len=%d\n",
+			__func__, cmd->cmd_hi, cmd->cmd_lo, cmd->tx_len,
+			cmd->rx_len);
+	}
+
+	aspeed_i3c_master_enqueue_xfer(master, xfer);
+	if (!wait_for_completion_timeout(&xfer->comp, XFER_TIMEOUT)) {
+		aspeed_i3c_master_enter_halt(master, true);
+		aspeed_i3c_master_dequeue_xfer(master, xfer);
+		aspeed_i3c_master_resume(master);
+	}
+
+	ret = xfer->ret;
+	aspeed_i3c_master_free_xfer(xfer);
+
+	return ret;
+}
+#endif
+static int aspeed_i3c_master_priv_xfers(struct i3c_dev_desc *dev,
+				    struct i3c_priv_xfer *i3c_xfers,
+				    int i3c_nxfers)
+{
+	struct aspeed_i3c_i2c_dev_data *data = i3c_dev_get_master_data(dev);
+	struct i3c_master_controller *m = i3c_dev_get_master(dev);
+	struct aspeed_i3c_master *master = to_aspeed_i3c_master(m);
+	unsigned int nrxwords = 0, ntxwords = 0;
+	struct aspeed_i3c_xfer *xfer;
+	int i, ret = 0;
+
+	if (!i3c_nxfers)
+		return 0;
+
+	if (i3c_nxfers > master->caps.cmdfifodepth)
+		return -ENOTSUPP;
+
+	for (i = 0; i < i3c_nxfers; i++) {
+		if (i3c_xfers[i].rnw)
+			nrxwords += DIV_ROUND_UP(i3c_xfers[i].len, 4);
+		else
+			ntxwords += DIV_ROUND_UP(i3c_xfers[i].len, 4);
+	}
+
+	if (ntxwords > master->caps.datafifodepth ||
+	    nrxwords > master->caps.datafifodepth)
+		return -ENOTSUPP;
+
+#ifdef CONFIG_AST2600_I3C_CCC_WORKAROUND
+	if (i3c_xfers[0].rnw == 0) {
+		/* write command: check if hit special address */
+		u8 tmp;
+
+		memcpy(&tmp, i3c_xfers[0].data.out, 1);
+		if (tmp == 0xff)
+			return aspeed_i3c_master_ccc_xfers(dev, i3c_xfers, i3c_nxfers);
+	}
+#endif
+
+	xfer = aspeed_i3c_master_alloc_xfer(master, i3c_nxfers);
+	if (!xfer)
+		return -ENOMEM;
+
+	data->index = aspeed_i3c_master_sync_hw_dat(master, dev->info.dyn_addr);
+
+	for (i = 0; i < i3c_nxfers; i++) {
+		struct aspeed_i3c_cmd *cmd = &xfer->cmds[i];
+
+		cmd->cmd_hi = COMMAND_PORT_ARG_DATA_LEN(i3c_xfers[i].len) |
+			COMMAND_PORT_TRANSFER_ARG;
+
+		if (i3c_xfers[i].rnw) {
+			cmd->rx_buf = i3c_xfers[i].data.in;
+			cmd->rx_len = i3c_xfers[i].len;
+			cmd->cmd_lo = COMMAND_PORT_READ_TRANSFER |
+				      COMMAND_PORT_SPEED(dev->info.max_read_ds);
+
+		} else {
+			cmd->tx_buf = i3c_xfers[i].data.out;
+			cmd->tx_len = i3c_xfers[i].len;
+			cmd->cmd_lo =
+				COMMAND_PORT_SPEED(dev->info.max_write_ds);
+		}
+
+		cmd->cmd_lo |= COMMAND_PORT_TID(i) |
+			       COMMAND_PORT_DEV_INDEX(data->index) |
+			       COMMAND_PORT_ROC;
+
+		if (i == (i3c_nxfers - 1))
+			cmd->cmd_lo |= COMMAND_PORT_TOC;
+
+		if (dev->info.pec)
+			cmd->cmd_lo |= COMMAND_PORT_PEC;
+
+		dev_dbg(master->dev,
+			"%s:cmd_hi=0x%08x cmd_lo=0x%08x tx_len=%d rx_len=%d\n",
+			__func__, cmd->cmd_hi, cmd->cmd_lo, cmd->tx_len,
+			cmd->rx_len);
+	}
+
+	aspeed_i3c_master_enqueue_xfer(master, xfer);
+	if (!wait_for_completion_timeout(&xfer->comp, XFER_TIMEOUT)) {
+		aspeed_i3c_master_enter_halt(master, true);
+		aspeed_i3c_master_dequeue_xfer(master, xfer);
+		aspeed_i3c_master_resume(master);
+	}
+
+	for (i = 0; i < i3c_nxfers; i++) {
+		struct aspeed_i3c_cmd *cmd = &xfer->cmds[i];
+
+		if (i3c_xfers[i].rnw)
+			i3c_xfers[i].len = cmd->rx_len;
+	}
+
+	ret = xfer->ret;
+	if (ret)
+		dev_err(master->dev, "xfer error: %x\n", xfer->cmds[0].error);
+	aspeed_i3c_master_free_xfer(xfer);
+
+	return ret;
+}
+
+static int aspeed_i3c_master_send_hdr_cmd(struct i3c_master_controller *m,
+					  struct i3c_hdr_cmd *cmds,
+					  int ncmds)
+{
+	struct aspeed_i3c_master *master = to_aspeed_i3c_master(m);
+	u8 dat_index;
+	int ret, i, ntxwords = 0, nrxwords = 0;
+	struct aspeed_i3c_xfer *xfer;
+
+	if (ncmds < 1)
+		return 0;
+
+	dev_dbg(master->dev, "ncmds = %x", ncmds);
+
+	if (ncmds > master->caps.cmdfifodepth)
+		return -ENOTSUPP;
+
+	for (i = 0; i < ncmds; i++) {
+		dev_dbg(master->dev, "cmds[%d] mode = %x", i, cmds[i].mode);
+		if (cmds[i].mode != I3C_HDR_DDR)
+			return -ENOTSUPP;
+		if (cmds[i].code & 0x80)
+			nrxwords += DIV_ROUND_UP(cmds[i].ndatawords, 2);
+		else
+			ntxwords += DIV_ROUND_UP(cmds[i].ndatawords, 2);
+	}
+	dev_dbg(master->dev, "ntxwords = %x, nrxwords = %x", ntxwords,
+		 nrxwords);
+	if (ntxwords > master->caps.datafifodepth ||
+	    nrxwords > master->caps.datafifodepth)
+		return -ENOTSUPP;
+
+	xfer = aspeed_i3c_master_alloc_xfer(master, ncmds);
+	if (!xfer)
+		return -ENOMEM;
+
+	for (i = 0; i < ncmds; i++) {
+		struct aspeed_i3c_cmd *cmd = &xfer->cmds[i];
+
+		dat_index = aspeed_i3c_master_sync_hw_dat(master, cmds[i].addr);
+
+		cmd->cmd_hi = COMMAND_PORT_ARG_DATA_LEN(cmds[i].ndatawords << 1) |
+			      COMMAND_PORT_TRANSFER_ARG;
+
+		if (cmds[i].code & 0x80) {
+			cmd->rx_buf = cmds[i].data.in;
+			cmd->rx_len = cmds[i].ndatawords << 1;
+			cmd->cmd_lo = COMMAND_PORT_READ_TRANSFER |
+				      COMMAND_PORT_CP |
+				      COMMAND_PORT_CMD(cmds[i].code) |
+				      COMMAND_PORT_SPEED(SPEED_I3C_HDR_DDR);
+
+		} else {
+			cmd->tx_buf = cmds[i].data.out;
+			cmd->tx_len = cmds[i].ndatawords << 1;
+			cmd->cmd_lo = COMMAND_PORT_CP |
+				      COMMAND_PORT_CMD(cmds[i].code) |
+				      COMMAND_PORT_SPEED(SPEED_I3C_HDR_DDR);
+		}
+
+		cmd->cmd_lo |= COMMAND_PORT_TID(i) |
+			       COMMAND_PORT_DEV_INDEX(dat_index) |
+			       COMMAND_PORT_ROC;
+
+		if (i == (ncmds - 1))
+			cmd->cmd_lo |= COMMAND_PORT_TOC;
+
+		dev_dbg(master->dev,
+			 "%s:cmd_hi=0x%08x cmd_lo=0x%08x tx_len=%d rx_len=%d\n",
+			 __func__, cmd->cmd_hi, cmd->cmd_lo, cmd->tx_len,
+			 cmd->rx_len);
+	}
+
+	aspeed_i3c_master_enqueue_xfer(master, xfer);
+	if (!wait_for_completion_timeout(&xfer->comp, XFER_TIMEOUT)) {
+		aspeed_i3c_master_enter_halt(master, true);
+		aspeed_i3c_master_dequeue_xfer(master, xfer);
+		aspeed_i3c_master_resume(master);
+	}
+
+	for (i = 0; i < ncmds; i++) {
+		struct aspeed_i3c_cmd *cmd = &xfer->cmds[i];
+
+		if (cmds[i].code & 0x80)
+			cmds[i].ndatawords = DIV_ROUND_UP(cmd->rx_len, 2);
+	}
+
+	ret = xfer->ret;
+	if (ret)
+		dev_err(master->dev, "xfer error: %x\n", xfer->cmds[0].error);
+	aspeed_i3c_master_free_xfer(xfer);
+
+	return ret;
+}
+
+static int aspeed_i3c_master_reattach_i3c_dev(struct i3c_dev_desc *dev,
+					  u8 old_dyn_addr)
+{
+	struct aspeed_i3c_i2c_dev_data *data = i3c_dev_get_master_data(dev);
+	struct i3c_master_controller *m = i3c_dev_get_master(dev);
+	struct aspeed_i3c_master *master = to_aspeed_i3c_master(m);
+
+	aspeed_i3c_master_set_group_dat(
+		master, dev->info.dyn_addr,
+		FIELD_PREP(DEV_ADDR_TABLE_DYNAMIC_ADDR, dev->info.dyn_addr));
+
+	master->addrs[data->index] = dev->info.dyn_addr;
+
+	return 0;
+}
+
+static int aspeed_i3c_master_attach_i3c_dev(struct i3c_dev_desc *dev)
+{
+	struct i3c_master_controller *m = i3c_dev_get_master(dev);
+	struct aspeed_i3c_master *master = to_aspeed_i3c_master(m);
+	struct aspeed_i3c_i2c_dev_data *data;
+	int pos;
+	u8 addr = dev->info.dyn_addr ? : dev->info.static_addr;
+
+	pos = aspeed_i3c_master_set_group_dat(
+		master, addr, FIELD_PREP(DEV_ADDR_TABLE_DYNAMIC_ADDR, addr));
+	if (pos < 0)
+		return pos;
+
+	data = kzalloc(sizeof(*data), GFP_KERNEL);
+	if (!data)
+		return -ENOMEM;
+
+	data->index = aspeed_i3c_master_get_group_hw_index(master, addr);
+	master->addrs[pos] = addr;
+	i3c_dev_set_master_data(dev, data);
+
+	if (master->base.jdec_spd)
+		dev->info.max_write_ds = dev->info.max_read_ds = 0;
+
+	return 0;
+}
+
+static void aspeed_i3c_master_detach_i3c_dev(struct i3c_dev_desc *dev)
+{
+	struct aspeed_i3c_i2c_dev_data *data = i3c_dev_get_master_data(dev);
+	struct i3c_master_controller *m = i3c_dev_get_master(dev);
+	struct aspeed_i3c_master *master = to_aspeed_i3c_master(m);
+
+	aspeed_i3c_master_set_group_dat(master, dev->info.dyn_addr, 0);
+
+	i3c_dev_set_master_data(dev, NULL);
+	master->addrs[data->index] = 0;
+	kfree(data);
+}
+
+static int aspeed_i3c_master_i2c_xfers(struct i2c_dev_desc *dev,
+				   const struct i2c_msg *i2c_xfers,
+				   int i2c_nxfers)
+{
+	struct aspeed_i3c_i2c_dev_data *data = i2c_dev_get_master_data(dev);
+	struct i3c_master_controller *m = i2c_dev_get_master(dev);
+	struct aspeed_i3c_master *master = to_aspeed_i3c_master(m);
+	unsigned int nrxwords = 0, ntxwords = 0;
+	struct aspeed_i3c_xfer *xfer;
+	int i, ret = 0;
+
+	if (!i2c_nxfers)
+		return 0;
+
+	if (i2c_nxfers > master->caps.cmdfifodepth)
+		return -ENOTSUPP;
+
+	for (i = 0; i < i2c_nxfers; i++) {
+		if (i2c_xfers[i].flags & I2C_M_RD)
+			nrxwords += DIV_ROUND_UP(i2c_xfers[i].len, 4);
+		else
+			ntxwords += DIV_ROUND_UP(i2c_xfers[i].len, 4);
+	}
+
+	if (ntxwords > master->caps.datafifodepth ||
+	    nrxwords > master->caps.datafifodepth)
+		return -ENOTSUPP;
+
+	if (ntxwords == 0 && nrxwords == 0) {
+		dev_warn(master->dev, "Transfers w/o data bytes are not supported");
+		return -ENOTSUPP;
+	}
+
+	xfer = aspeed_i3c_master_alloc_xfer(master, i2c_nxfers);
+	if (!xfer)
+		return -ENOMEM;
+
+	data->index = aspeed_i3c_master_sync_hw_dat(master, dev->addr);
+
+	for (i = 0; i < i2c_nxfers; i++) {
+		struct aspeed_i3c_cmd *cmd = &xfer->cmds[i];
+
+		cmd->cmd_hi = COMMAND_PORT_ARG_DATA_LEN(i2c_xfers[i].len) |
+			COMMAND_PORT_TRANSFER_ARG;
+
+		cmd->cmd_lo = COMMAND_PORT_TID(i) |
+			      COMMAND_PORT_DEV_INDEX(data->index) |
+			      COMMAND_PORT_ROC;
+
+		if (i2c_xfers[i].flags & I2C_M_RD) {
+			cmd->cmd_lo |= COMMAND_PORT_READ_TRANSFER;
+			cmd->rx_buf = i2c_xfers[i].buf;
+			cmd->rx_len = i2c_xfers[i].len;
+		} else {
+			cmd->tx_buf = i2c_xfers[i].buf;
+			cmd->tx_len = i2c_xfers[i].len;
+		}
+
+		if (i == (i2c_nxfers - 1))
+			cmd->cmd_lo |= COMMAND_PORT_TOC;
+
+		dev_dbg(master->dev,
+			"%s:cmd_hi=0x%08x cmd_lo=0x%08x tx_len=%d rx_len=%d\n",
+			__func__, cmd->cmd_hi, cmd->cmd_lo, cmd->tx_len,
+			cmd->rx_len);
+	}
+
+	aspeed_i3c_master_enqueue_xfer(master, xfer);
+	if (!wait_for_completion_timeout(&xfer->comp, XFER_TIMEOUT)) {
+		aspeed_i3c_master_enter_halt(master, true);
+		aspeed_i3c_master_dequeue_xfer(master, xfer);
+		aspeed_i3c_master_resume(master);
+	}
+
+	ret = xfer->ret;
+	if (ret)
+		dev_err(master->dev, "xfer error: %x\n", xfer->cmds[0].error);
+	aspeed_i3c_master_free_xfer(xfer);
+
+	return ret;
+}
+
+static int aspeed_i3c_master_attach_i2c_dev(struct i2c_dev_desc *dev)
+{
+	struct i3c_master_controller *m = i2c_dev_get_master(dev);
+	struct aspeed_i3c_master *master = to_aspeed_i3c_master(m);
+	struct aspeed_i3c_i2c_dev_data *data;
+	int pos;
+
+	pos = aspeed_i3c_master_set_group_dat(
+		master, dev->addr,
+		DEV_ADDR_TABLE_LEGACY_I2C_DEV |
+			FIELD_PREP(DEV_ADDR_TABLE_STATIC_ADDR, dev->addr));
+
+	if (pos < 0)
+		return pos;
+
+	data = kzalloc(sizeof(*data), GFP_KERNEL);
+	if (!data)
+		return -ENOMEM;
+
+	data->index = aspeed_i3c_master_get_group_hw_index(master, dev->addr);
+	master->addrs[data->index] = dev->addr;
+	i2c_dev_set_master_data(dev, data);
+
+
+	return 0;
+}
+
+static void aspeed_i3c_master_detach_i2c_dev(struct i2c_dev_desc *dev)
+{
+	struct aspeed_i3c_i2c_dev_data *data = i2c_dev_get_master_data(dev);
+	struct i3c_master_controller *m = i2c_dev_get_master(dev);
+	struct aspeed_i3c_master *master = to_aspeed_i3c_master(m);
+
+	aspeed_i3c_master_set_group_dat(master, dev->addr, 0);
+
+	i2c_dev_set_master_data(dev, NULL);
+	master->addrs[data->index] = 0;
+	kfree(data);
+}
+
+static void aspeed_i3c_slave_event_handler(struct aspeed_i3c_master *master)
+{
+	u32 event = readl(master->regs + SLV_EVENT_CTRL);
+	u32 reg = readl(master->regs + PRESENT_STATE);
+	u32 cm_state = FIELD_GET(CM_TFR_STS, reg);
+
+	if (cm_state == CM_TFR_STS_SLAVE_HALT) {
+		dev_dbg(master->dev, "slave in halt state\n");
+		aspeed_i3c_master_resume(master);
+	}
+
+	dev_dbg(master->dev, "slave event=%08x\n", event);
+	if (event & SLV_EVENT_CTRL_MRL_UPD)
+		dev_dbg(master->dev, "isr: master set mrl=%d\n",
+			readl(master->regs + SLV_MAX_LEN) >> 16);
+
+	if (event & SLV_EVENT_CTRL_MWL_UPD)
+		dev_dbg(master->dev, "isr: master set mwl=%ld\n",
+			readl(master->regs + SLV_MAX_LEN) & GENMASK(15, 0));
+
+	writel(event, master->regs + SLV_EVENT_CTRL);
+}
+
+static void aspeed_i3c_slave_resp_handler(struct aspeed_i3c_master *master,
+					  u32 status)
+{
+	int i, has_error = 0;
+	u32 resp, nbytes, nresp;
+	u8 error, tid;
+	u32 *buf = master->slave_data.buf;
+	struct i3c_slave_payload payload;
+
+	nresp = readl(master->regs + QUEUE_STATUS_LEVEL);
+	nresp = QUEUE_STATUS_LEVEL_RESP(nresp);
+
+	for (i = 0; i < nresp; i++) {
+		resp = readl(master->regs + RESPONSE_QUEUE_PORT);
+		error = RESPONSE_PORT_ERR_STATUS(resp);
+		nbytes = RESPONSE_PORT_DATA_LEN(resp);
+		tid = RESPONSE_PORT_TID(resp);
+
+		if (error) {
+			has_error = 1;
+			if (error == RESPONSE_ERROR_EARLY_TERMINATE)
+				dev_dbg(master->dev,
+					"early termination, remain length %d\n",
+					nbytes);
+		}
+
+		if (!error && nbytes) {
+			aspeed_i3c_master_read_rx_fifo(master, (u8 *)buf, nbytes);
+
+			payload.len = nbytes;
+			payload.data = buf;
+			/* currently only support master write transfer */
+			if (master->slave_data.callback && (tid == TID_MASTER_WRITE_DATA))
+				master->slave_data.callback(&master->base, &payload);
+		}
+
+		if (!error && !nbytes) {
+			if (status & INTR_IBI_UPDATED_STAT && tid == TID_SLAVE_IBI_DONE)
+				complete(&master->sir_complete);
+			else if (tid == TID_MASTER_READ_DATA)
+				complete(&master->data_read_complete);
+			else
+				dev_warn(master->dev, "Unreogized response %x",
+					 resp);
+		}
+	}
+
+	if (has_error) {
+		aspeed_i3c_master_reset_ctrl(master, RESET_CTRL_QUEUES);
+		aspeed_i3c_master_resume(master);
+	}
+}
+
+static irqreturn_t aspeed_i3c_master_irq_handler(int irq, void *dev_id)
+{
+	struct aspeed_i3c_master *master = dev_id;
+	u32 status;
+
+	status = readl(master->regs + INTR_STATUS);
+
+	if (!(status & readl(master->regs + INTR_STATUS_EN))) {
+		writel(INTR_ALL, master->regs + INTR_STATUS);
+		return IRQ_NONE;
+	}
+
+	if (master->secondary) {
+		if (status & INTR_READ_REQ_RECV_STAT)
+			dev_dbg(master->dev, "read queue received\n");
+
+		if (status & INTR_RESP_READY_STAT)
+			aspeed_i3c_slave_resp_handler(master, status);
+
+		if (status & INTR_CCC_UPDATED_STAT)
+			aspeed_i3c_slave_event_handler(master);
+	} else {
+		u32 reg, cm_state, xfr_state;
+
+		if (status & INTR_RESP_READY_STAT ||
+		    status & INTR_TRANSFER_ERR_STAT) {
+			spin_lock(&master->xferqueue.lock);
+			aspeed_i3c_master_end_xfer_locked(master, status);
+			if (status & INTR_TRANSFER_ERR_STAT)
+				writel(INTR_TRANSFER_ERR_STAT, master->regs + INTR_STATUS);
+			spin_unlock(&master->xferqueue.lock);
+		}
+
+		if (status & INTR_IBI_THLD_STAT)
+			aspeed_i3c_master_demux_ibis(master);
+
+		/*
+		 * check whether the controller is in halt state and resume the
+		 * controller if it is in halt state
+		 */
+		reg = readl(master->regs + PRESENT_STATE);
+		cm_state = FIELD_GET(CM_TFR_ST_STS, reg);
+		xfr_state = FIELD_GET(CM_TFR_STS, reg);
+
+		if (cm_state == CM_TFR_ST_STS_HALT ||
+		    xfr_state == CM_TFR_STS_MASTER_HALT) {
+			dev_dbg(master->dev, "master in halt state, resume\n");
+			aspeed_i3c_master_reset_ctrl(master, RESET_CTRL_QUEUES);
+			aspeed_i3c_master_resume(master);
+		}
+	}
+
+	writel(status, master->regs + INTR_STATUS);
+
+	return IRQ_HANDLED;
+}
+
+static void aspeed_i3c_master_enable_ibi_irq(struct aspeed_i3c_master *master)
+{
+	u32 reg;
+
+	reg = readl(master->regs + INTR_STATUS_EN);
+	reg |= INTR_IBI_THLD_STAT;
+	writel(reg, master->regs + INTR_STATUS_EN);
+
+	reg = readl(master->regs + INTR_SIGNAL_EN);
+	reg |= INTR_IBI_THLD_STAT;
+	writel(reg, master->regs + INTR_SIGNAL_EN);
+}
+
+static void aspeed_i3c_master_disable_ibi_irq(struct aspeed_i3c_master *master)
+{
+	u32 reg;
+
+	reg = readl(master->regs + INTR_STATUS_EN);
+	reg &= ~INTR_IBI_THLD_STAT;
+	writel(reg, master->regs + INTR_STATUS_EN);
+
+	reg = readl(master->regs + INTR_SIGNAL_EN);
+	reg &= ~INTR_IBI_THLD_STAT;
+	writel(reg, master->regs + INTR_SIGNAL_EN);
+}
+
+static int aspeed_i3c_master_disable_ibi(struct i3c_dev_desc *dev)
+{
+	struct i3c_master_controller *m = i3c_dev_get_master(dev);
+	struct aspeed_i3c_master *master = to_aspeed_i3c_master(m);
+	struct aspeed_i3c_i2c_dev_data *data = i3c_dev_get_master_data(dev);
+	struct aspeed_i3c_dev_group *dev_grp =
+		aspeed_i3c_master_get_group(master, dev->info.dyn_addr);
+	unsigned long flags;
+	u32 sirmap, dat, hj_nack;
+	int ret, i;
+	bool ibi_enable = false;
+
+	ret = i3c_master_disec_locked(m, dev->info.dyn_addr,
+				      I3C_CCC_EVENT_SIR);
+	if (ret)
+		return ret;
+
+	spin_lock_irqsave(&master->ibi.lock, flags);
+	dat = aspeed_i3c_master_get_group_dat(master, dev->info.dyn_addr);
+	dat |= DEV_ADDR_TABLE_SIR_REJECT;
+	dat &= ~DEV_ADDR_TABLE_IBI_WITH_DATA;
+	aspeed_i3c_master_set_group_dat(master, dev->info.dyn_addr, dat);
+
+	/*
+	 * if any available device in this group still needs to enable ibi, then
+	 * just keep the hw setting until all of the devices agree to disable ibi
+	 */
+	for (i = 0; i < MAX_DEVS_IN_GROUP; i++) {
+		if ((!(dev_grp->free_pos & BIT(i))) &&
+		    (!(dev_grp->dat[i] & DEV_ADDR_TABLE_SIR_REJECT))) {
+			ibi_enable = true;
+			break;
+		}
+	}
+
+	if (!ibi_enable) {
+		sirmap = readl(master->regs + IBI_SIR_REQ_REJECT);
+		sirmap |= BIT(data->ibi);
+		writel(sirmap, master->regs + IBI_SIR_REQ_REJECT);
+
+		dev_grp->mask.clr |= DEV_ADDR_TABLE_IBI_WITH_DATA |
+				     DEV_ADDR_TABLE_IBI_ADDR_MASK;
+		dev_grp->mask.set &= ~DEV_ADDR_TABLE_IBI_WITH_DATA;
+		dev_grp->mask.set |= DEV_ADDR_TABLE_SIR_REJECT;
+	}
+
+	sirmap = readl(master->regs + IBI_SIR_REQ_REJECT);
+	hj_nack = readl(master->regs + DEVICE_CTRL) & DEV_CTRL_HOT_JOIN_NACK;
+	if (sirmap == IBI_REQ_REJECT_ALL && hj_nack)
+		aspeed_i3c_master_disable_ibi_irq(master);
+	else
+		aspeed_i3c_master_enable_ibi_irq(master);
+
+	spin_unlock_irqrestore(&master->ibi.lock, flags);
+
+	return ret;
+}
+
+static int aspeed_i3c_master_enable_ibi(struct i3c_dev_desc *dev)
+{
+	struct i3c_master_controller *m = i3c_dev_get_master(dev);
+	struct aspeed_i3c_master *master = to_aspeed_i3c_master(m);
+	struct aspeed_i3c_i2c_dev_data *data = i3c_dev_get_master_data(dev);
+	struct aspeed_i3c_dev_group *dev_grp =
+		aspeed_i3c_master_get_group(master, dev->info.dyn_addr);
+	unsigned long flags;
+	u32 sirmap, hj_nack;
+	u32 sirmap_backup, mask_clr_backup, mask_set_backup;
+	int ret;
+
+	spin_lock_irqsave(&master->ibi.lock, flags);
+	sirmap_backup = readl(master->regs + IBI_SIR_REQ_REJECT);
+	sirmap = sirmap_backup & ~BIT(data->ibi);
+	writel(sirmap, master->regs + IBI_SIR_REQ_REJECT);
+
+	mask_clr_backup = dev_grp->mask.clr;
+	mask_set_backup = dev_grp->mask.set;
+	dev_grp->mask.clr |= DEV_ADDR_TABLE_SIR_REJECT | DEV_ADDR_TABLE_IBI_ADDR_MASK;
+	dev_grp->mask.set &= ~DEV_ADDR_TABLE_SIR_REJECT;
+	dev_grp->mask.set |= FIELD_PREP(DEV_ADDR_TABLE_IBI_ADDR_MASK,
+					IBI_ADDR_MASK_LAST_3BITS);
+	/* Enable the PEC to avoid issue of IBI with the payload length 4n+1 */
+	dev_grp->mask.set |= DEV_ADDR_TABLE_IBI_PEC_EN;
+	if (dev->info.bcr & I3C_BCR_IBI_PAYLOAD)
+		dev_grp->mask.set |= DEV_ADDR_TABLE_IBI_WITH_DATA;
+
+	spin_unlock_irqrestore(&master->ibi.lock, flags);
+
+	dev_dbg(master->dev, "addr:%x, hw_index:%d, data->ibi:%d, mask: %08x %08x\n",
+		dev->info.dyn_addr, dev_grp->hw_index, data->ibi, dev_grp->mask.set,
+		dev_grp->mask.clr);
+
+	/* Dat will be synchronized before sending the CCC */
+	ret = i3c_master_enec_locked(m, dev->info.dyn_addr,
+				     I3C_CCC_EVENT_SIR);
+
+	if (ret) {
+		spin_lock_irqsave(&master->ibi.lock, flags);
+		writel(sirmap_backup, master->regs + IBI_SIR_REQ_REJECT);
+
+		dev_grp->mask.clr = mask_clr_backup;
+		dev_grp->mask.set = mask_set_backup;
+		aspeed_i3c_master_sync_hw_dat(master, dev->info.dyn_addr);
+		spin_unlock_irqrestore(&master->ibi.lock, flags);
+	}
+
+	sirmap = readl(master->regs + IBI_SIR_REQ_REJECT);
+	hj_nack = readl(master->regs + DEVICE_CTRL) & DEV_CTRL_HOT_JOIN_NACK;
+	if (sirmap == IBI_REQ_REJECT_ALL && hj_nack)
+		aspeed_i3c_master_disable_ibi_irq(master);
+	else
+		aspeed_i3c_master_enable_ibi_irq(master);
+
+	return ret;
+}
+
+static int aspeed_i3c_master_request_ibi(struct i3c_dev_desc *dev,
+				       const struct i3c_ibi_setup *req)
+{
+	struct i3c_master_controller *m = i3c_dev_get_master(dev);
+	struct aspeed_i3c_master *master = to_aspeed_i3c_master(m);
+	struct aspeed_i3c_i2c_dev_data *data = i3c_dev_get_master_data(dev);
+	unsigned long flags;
+	unsigned int i;
+
+	data->ibi_pool = i3c_generic_ibi_alloc_pool(dev, req);
+	if (IS_ERR(data->ibi_pool))
+		return PTR_ERR(data->ibi_pool);
+
+	spin_lock_irqsave(&master->ibi.lock, flags);
+	master->ibi.slots[dev->info.dyn_addr & 0x7f] = dev;
+	master->ibi.received_ibi_len[dev->info.dyn_addr & 0x7f] = 0;
+	data->ibi = aspeed_i3c_master_get_group_hw_index(master,
+							 dev->info.dyn_addr);
+	spin_unlock_irqrestore(&master->ibi.lock, flags);
+
+	if (i < MAX_DEVS)
+		return 0;
+
+	i3c_generic_ibi_free_pool(data->ibi_pool);
+	data->ibi_pool = NULL;
+
+	return -ENOSPC;
+}
+
+static void aspeed_i3c_master_free_ibi(struct i3c_dev_desc *dev)
+{
+	struct i3c_master_controller *m = i3c_dev_get_master(dev);
+	struct aspeed_i3c_master *master = to_aspeed_i3c_master(m);
+	struct aspeed_i3c_i2c_dev_data *data = i3c_dev_get_master_data(dev);
+	unsigned long flags;
+
+	spin_lock_irqsave(&master->ibi.lock, flags);
+	master->ibi.slots[dev->info.dyn_addr] = NULL;
+	data->ibi = -1;
+	spin_unlock_irqrestore(&master->ibi.lock, flags);
+
+	i3c_generic_ibi_free_pool(data->ibi_pool);
+}
+
+static void aspeed_i3c_master_recycle_ibi_slot(struct i3c_dev_desc *dev,
+					     struct i3c_ibi_slot *slot)
+{
+	struct aspeed_i3c_i2c_dev_data *data = i3c_dev_get_master_data(dev);
+
+	i3c_generic_ibi_recycle_slot(data->ibi_pool, slot);
+}
+
+static uint8_t *pec_append(struct aspeed_i3c_master *master, uint8_t *ptr, uint8_t len)
+{
+	uint8_t *xfer_buf;
+	uint8_t pec_v;
+	uint8_t addr_rnw;
+
+	addr_rnw = FIELD_GET(DEV_ADDR_DYNAMIC_MASK,
+			     readl(master->regs + DEVICE_ADDR));
+	addr_rnw = addr_rnw << 1 | 0x1;
+	xfer_buf = kmalloc(len + 1, GFP_KERNEL);
+	memcpy(xfer_buf, ptr, len);
+
+	pec_v = crc8(i3c_crc8_table, &addr_rnw, 1, 0);
+	pec_v = crc8(i3c_crc8_table, xfer_buf, len, pec_v);
+	xfer_buf[len] = pec_v;
+
+	return xfer_buf;
+}
+
+static int aspeed_i3c_master_register_slave(struct i3c_master_controller *m,
+			      const struct i3c_slave_setup *req)
+{
+	struct aspeed_i3c_master *master = to_aspeed_i3c_master(m);
+	u32 *buf;
+
+	buf = kzalloc(req->max_payload_len, GFP_KERNEL);
+	if (!buf)
+		return -ENOMEM;
+
+	master->slave_data.callback = req->handler;
+	master->slave_data.buf = buf;
+
+	return 0;
+}
+
+static int aspeed_i3c_master_unregister_slave(struct i3c_master_controller *m)
+{
+	struct aspeed_i3c_master *master = to_aspeed_i3c_master(m);
+
+	master->slave_data.callback = NULL;
+	kfree(master->slave_data.buf);
+
+	return 0;
+}
+
+static int aspeed_i3c_master_send_sir(struct i3c_master_controller *m,
+				      struct i3c_slave_payload *payload)
+{
+	struct aspeed_i3c_master *master = to_aspeed_i3c_master(m);
+	uint32_t slv_event, intr_req, reg, thld_ctrl,
+		payload_len = payload->len;
+	uint8_t *data = (uint8_t *)payload->data;
+
+	slv_event = readl(master->regs + SLV_EVENT_CTRL);
+	if ((slv_event & SLV_EVENT_CTRL_SIR_EN) == 0)
+		return -EPERM;
+
+	if (!payload)
+		return -ENXIO;
+
+	if (payload_len > (CONFIG_AST2600_I3C_IBI_MAX_PAYLOAD + 1)) {
+		dev_err(master->dev,
+			"input length %d exceeds max ibi payload size %d\n",
+			payload_len, CONFIG_AST2600_I3C_IBI_MAX_PAYLOAD + 1);
+		return -E2BIG;
+	}
+
+	init_completion(&master->sir_complete);
+
+	reg = readl(master->regs + DEVICE_CTRL);
+	reg &= ~DEV_CTRL_SLAVE_MDB;
+	reg |= FIELD_PREP(DEV_CTRL_SLAVE_MDB, data[0]);
+	writel(reg, master->regs + DEVICE_CTRL);
+
+	if (!master->ibi_wo_pec) {
+		data = pec_append(master, data, payload_len);
+		payload_len += 1;
+	}
+
+	aspeed_i3c_master_wr_tx_fifo(master, data, payload_len);
+
+	if (!master->ibi_wo_pec)
+		kfree(data);
+
+	reg = FIELD_PREP(COMMAND_PORT_SLAVE_DATA_LEN, payload_len);
+	writel(reg, master->regs + COMMAND_QUEUE_PORT);
+
+	thld_ctrl = readl(master->regs + QUEUE_THLD_CTRL);
+	thld_ctrl &= ~QUEUE_THLD_CTRL_RESP_BUF_MASK;
+	thld_ctrl |= QUEUE_THLD_CTRL_RESP_BUF(1);
+	writel(thld_ctrl, master->regs + QUEUE_THLD_CTRL);
+
+	writel(1, master->regs + SLV_INTR_REQ);
+	if (!wait_for_completion_timeout(&master->sir_complete, XFER_TIMEOUT)) {
+		dev_err(master->dev, "send sir timeout\n");
+		aspeed_i3c_master_reset_ctrl(master, RESET_CTRL_XFER_QUEUES);
+	}
+
+	intr_req = readl(master->regs + SLV_INTR_REQ);
+	if (SLV_INTR_REQ_IBI_STS(intr_req) != SLV_IBI_STS_OK) {
+		slv_event = readl(master->regs + SLV_EVENT_CTRL);
+		if ((slv_event & SLV_EVENT_CTRL_SIR_EN) == 0)
+			pr_warn("sir is disabled by master\n");
+		return -EACCES;
+	}
+
+	return 0;
+}
+
+static int aspeed_i3c_slave_reset_queue(struct aspeed_i3c_master *master)
+{
+	int ret = 0;
+
+	ret = aspeed_i3c_master_disable(master);
+	if (ret)
+		return ret;
+	aspeed_i3c_master_reset_ctrl(master, RESET_CTRL_QUEUES);
+	ret = aspeed_i3c_master_enable(master);
+	if (ret)
+		return ret;
+	return ret;
+}
+
+static int aspeed_i3c_master_put_read_data(struct i3c_master_controller *m,
+					   struct i3c_slave_payload *data,
+					   struct i3c_slave_payload *ibi_notify)
+{
+	struct aspeed_i3c_master *master = to_aspeed_i3c_master(m);
+	u32 reg, thld_ctrl, slv_event, ibi_len = ibi_notify->len;
+	u8 *buf;
+	int ret;
+
+	if (!data)
+		return -ENXIO;
+
+	if (ibi_notify) {
+		slv_event = readl(master->regs + SLV_EVENT_CTRL);
+		if ((slv_event & SLV_EVENT_CTRL_SIR_EN) == 0)
+			return -EPERM;
+		buf = (u8 *)ibi_notify->data;
+		init_completion(&master->sir_complete);
+
+		reg = readl(master->regs + DEVICE_CTRL);
+		reg &= ~DEV_CTRL_SLAVE_MDB;
+		reg |= FIELD_PREP(DEV_CTRL_SLAVE_MDB, buf[0]);
+		writel(reg, master->regs + DEVICE_CTRL);
+
+		if (!master->ibi_wo_pec) {
+			buf = pec_append(master, buf, ibi_len);
+			ibi_len += 1;
+		}
+		aspeed_i3c_master_wr_tx_fifo(master, buf, ibi_len);
+		if (!master->ibi_wo_pec)
+			kfree(buf);
+		reg = FIELD_PREP(COMMAND_PORT_SLAVE_DATA_LEN, ibi_len) |
+		      COMMAND_PORT_SLAVE_TID(TID_SLAVE_IBI_DONE);
+		writel(reg, master->regs + COMMAND_QUEUE_PORT);
+
+		thld_ctrl = readl(master->regs + QUEUE_THLD_CTRL);
+		thld_ctrl &= ~QUEUE_THLD_CTRL_RESP_BUF_MASK;
+		thld_ctrl |= QUEUE_THLD_CTRL_RESP_BUF(1);
+		writel(thld_ctrl, master->regs + QUEUE_THLD_CTRL);
+	}
+
+	buf = (u8 *)data->data;
+	init_completion(&master->data_read_complete);
+	aspeed_i3c_master_wr_tx_fifo(master, buf, data->len);
+
+	reg = FIELD_PREP(COMMAND_PORT_SLAVE_DATA_LEN, data->len) |
+	      COMMAND_PORT_SLAVE_TID(TID_MASTER_READ_DATA);
+	writel(reg, master->regs + COMMAND_QUEUE_PORT);
+
+	if (ibi_notify) {
+		writel(1, master->regs + SLV_INTR_REQ);
+		if (!wait_for_completion_timeout(&master->sir_complete,
+						 XFER_TIMEOUT)) {
+			dev_err(master->dev, "send sir timeout\n");
+			aspeed_i3c_master_reset_ctrl(master, RESET_CTRL_QUEUES);
+		}
+	}
+
+	/* Wait data to be read */
+	if (!wait_for_completion_timeout(&master->data_read_complete,
+						 XFER_TIMEOUT)) {
+		dev_err(master->dev, "wait master read timeout\n");
+		ret = aspeed_i3c_slave_reset_queue(master);
+		if (ret) {
+			dev_err(master->dev, "i3c queue reset failed");
+			return ret;
+		}
+	}
+
+	return 0;
+}
+
+static int aspeed_i3c_master_timing_config(struct aspeed_i3c_master *master,
+					   struct device_node *np)
+{
+	u32 val, reg;
+	u32 timed_reset_scl_low_ns;
+	u32 sda_tx_hold_ns;
+
+	master->timing.core_rate = clk_get_rate(master->core_clk);
+	if (!master->timing.core_rate) {
+		dev_err(master->dev, "core clock rate not found\n");
+		return -EINVAL;
+	}
+
+	/* core_period is in nanosecond */
+	master->timing.core_period =
+		DIV_ROUND_UP(1000000000, master->timing.core_rate);
+
+	/* setup default timing configuration */
+	sda_tx_hold_ns = SDA_TX_HOLD_MIN * master->timing.core_period;
+	timed_reset_scl_low_ns = JESD403_TIMED_RESET_NS_DEF;
+
+	/* parse configurations from DT */
+	if (!of_property_read_u32(np, "i3c-pp-scl-hi-period-ns", &val))
+		master->timing.i3c_pp_scl_high = val;
+
+	if (!of_property_read_u32(np, "i3c-pp-scl-lo-period-ns", &val))
+		master->timing.i3c_pp_scl_low = val;
+
+	if (!of_property_read_u32(np, "i3c-od-scl-hi-period-ns", &val))
+		master->timing.i3c_od_scl_high = val;
+
+	if (!of_property_read_u32(np, "i3c-od-scl-lo-period-ns", &val))
+		master->timing.i3c_od_scl_low = val;
+
+	if (!of_property_read_u32(np, "sda-tx-hold-ns", &val))
+		sda_tx_hold_ns = val;
+
+	if (!of_property_read_u32(np, "timed-reset-scl-low-ns", &val))
+		timed_reset_scl_low_ns = val;
+
+	val = clamp((u32)DIV_ROUND_CLOSEST(sda_tx_hold_ns,
+					   master->timing.core_period),
+		    (u32)SDA_TX_HOLD_MIN, (u32)SDA_TX_HOLD_MAX);
+	reg = readl(master->regs + SDA_HOLD_SWITCH_DLY_TIMING);
+	reg &= ~SDA_TX_HOLD;
+	reg |= FIELD_PREP(SDA_TX_HOLD, val);
+	writel(reg, master->regs + SDA_HOLD_SWITCH_DLY_TIMING);
+
+	val = DIV_ROUND_CLOSEST(timed_reset_scl_low_ns,
+				master->timing.core_period);
+	writel(val, master->regs + SCL_LOW_MST_EXT_TIMEOUT);
+
+	return 0;
+}
+
+static const struct i3c_master_controller_ops aspeed_i3c_ops = {
+	.bus_init = aspeed_i3c_master_bus_init,
+	.bus_cleanup = aspeed_i3c_master_bus_cleanup,
+	.bus_reset = aspeed_i3c_master_bus_reset,
+	.attach_i3c_dev = aspeed_i3c_master_attach_i3c_dev,
+	.reattach_i3c_dev = aspeed_i3c_master_reattach_i3c_dev,
+	.detach_i3c_dev = aspeed_i3c_master_detach_i3c_dev,
+	.do_daa = aspeed_i3c_master_daa,
+	.supports_ccc_cmd = aspeed_i3c_master_supports_ccc_cmd,
+	.send_ccc_cmd = aspeed_i3c_master_send_ccc_cmd,
+	.send_hdr_cmds = aspeed_i3c_master_send_hdr_cmd,
+	.priv_xfers = aspeed_i3c_master_priv_xfers,
+	.attach_i2c_dev = aspeed_i3c_master_attach_i2c_dev,
+	.detach_i2c_dev = aspeed_i3c_master_detach_i2c_dev,
+	.i2c_xfers = aspeed_i3c_master_i2c_xfers,
+	.enable_ibi = aspeed_i3c_master_enable_ibi,
+	.disable_ibi = aspeed_i3c_master_disable_ibi,
+	.request_ibi = aspeed_i3c_master_request_ibi,
+	.free_ibi = aspeed_i3c_master_free_ibi,
+	.recycle_ibi_slot = aspeed_i3c_master_recycle_ibi_slot,
+	.register_slave = aspeed_i3c_master_register_slave,
+	.unregister_slave = aspeed_i3c_master_unregister_slave,
+	.send_sir = aspeed_i3c_master_send_sir,
+	.put_read_data = aspeed_i3c_master_put_read_data,
+};
+
+static void aspeed_i3c_master_hj(struct work_struct *work)
+{
+	struct aspeed_i3c_master *master =
+		container_of(work, typeof(*master), hj_work);
+
+	i3c_master_do_daa(&master->base);
+}
+
+static int aspeed_i3c_master_enable_hj(struct aspeed_i3c_master *master)
+{
+	int ret;
+
+	aspeed_i3c_master_enable_ibi_irq(master);
+	ast_clrbits(master->regs + DEVICE_CTRL, DEV_CTRL_HOT_JOIN_NACK);
+	ret = i3c_master_enable_hj(&master->base);
+
+	return ret;
+}
+
+static int aspeed_i3c_probe(struct platform_device *pdev)
+{
+	struct aspeed_i3c_master *master;
+	struct device_node *np;
+	int ret, irq;
+
+	master = devm_kzalloc(&pdev->dev, sizeof(*master), GFP_KERNEL);
+	if (!master)
+		return -ENOMEM;
+
+	master->i3cg = syscon_regmap_lookup_by_phandle(pdev->dev.of_node,
+						       "aspeed,i3cg");
+	if (IS_ERR(master->i3cg)) {
+		dev_err(master->dev,
+			"i3c controller missing 'aspeed,i3cg' property\n");
+		return PTR_ERR(master->i3cg);
+	}
+
+	master->regs = devm_platform_ioremap_resource(pdev, 0);
+	if (IS_ERR(master->regs))
+		return PTR_ERR(master->regs);
+
+	master->core_clk = devm_clk_get(&pdev->dev, NULL);
+	if (IS_ERR(master->core_clk))
+		return PTR_ERR(master->core_clk);
+
+	master->core_rst = devm_reset_control_get_optional_exclusive(&pdev->dev,
+								    NULL);
+	if (IS_ERR(master->core_rst))
+		return PTR_ERR(master->core_rst);
+
+	ret = clk_prepare_enable(master->core_clk);
+	if (ret)
+		goto err_disable_core_clk;
+
+	reset_control_deassert(master->core_rst);
+
+	spin_lock_init(&master->ibi.lock);
+	spin_lock_init(&master->xferqueue.lock);
+	INIT_LIST_HEAD(&master->xferqueue.list);
+
+	ret = aspeed_i3c_master_reset_ctrl(master, RESET_CTRL_ALL);
+	if (ret)
+		goto err_assert_rst;
+
+	writel(INTR_ALL, master->regs + INTR_STATUS);
+	irq = platform_get_irq(pdev, 0);
+	ret = devm_request_irq(&pdev->dev, irq,
+			       aspeed_i3c_master_irq_handler, 0,
+			       dev_name(&pdev->dev), master);
+	if (ret)
+		goto err_assert_rst;
+
+	platform_set_drvdata(pdev, master);
+
+	np = pdev->dev.of_node;
+	if (of_get_property(np, "secondary", NULL))
+		master->secondary = true;
+	else
+		master->secondary = false;
+
+	if (master->secondary && of_get_property(np, "aspeed,ibi-wo-pec", NULL)) {
+		master->ibi_wo_pec = true;
+	} else {
+		master->ibi_wo_pec = false;
+		crc8_populate_msb(i3c_crc8_table, I3C_CRC8_POLYNOMIAL);
+	}
+
+	ret = of_property_read_u32(np, "i3c_chan", &master->channel);
+	if ((ret != 0) || (master->channel > I3C_CHANNEL_MAX)) {
+		dev_err(&pdev->dev, "no valid 'i3c_chan' %d %d configured\n", ret, master->channel);
+		return -EINVAL;
+	}
+
+	ret = aspeed_i3c_master_timing_config(master, np);
+	if (ret)
+		goto err_assert_rst;
+
+	/* Information regarding the FIFOs/QUEUEs depth */
+	ret = readl(master->regs + QUEUE_STATUS_LEVEL);
+	master->caps.cmdfifodepth = QUEUE_STATUS_LEVEL_CMD(ret);
+
+	ret = readl(master->regs + DATA_BUFFER_STATUS_LEVEL);
+	master->caps.datafifodepth = DATA_BUFFER_STATUS_LEVEL_TX(ret);
+
+	ret = readl(master->regs + DEVICE_ADDR_TABLE_POINTER);
+	master->datstartaddr = ret;
+	master->maxdevs = ret >> 16;
+	master->free_pos = GENMASK(master->maxdevs - 1, 0);
+	aspeed_i3c_master_init_group_dat(master);
+#ifdef CONFIG_AST2600_I3C_CCC_WORKAROUND
+	master->free_pos &= ~BIT(master->maxdevs - 1);
+	master->addrs[master->maxdevs - 1] = I3C_BROADCAST_ADDR;
+	ret = FIELD_PREP(DEV_ADDR_TABLE_DYNAMIC_ADDR, I3C_BROADCAST_ADDR) |
+	      FIELD_PREP(DEV_ADDR_TABLE_DA_PARITY,
+			 even_parity(I3C_BROADCAST_ADDR));
+	writel(ret, master->regs + DEV_ADDR_TABLE_LOC(master->datstartaddr,
+						      master->maxdevs - 1));
+#endif
+	master->dev = &pdev->dev;
+	master->base.pec_supported = true;
+	INIT_WORK(&master->hj_work, aspeed_i3c_master_hj);
+	ret = i3c_master_register(&master->base, &pdev->dev,
+				  &aspeed_i3c_ops, master->secondary);
+	if (ret)
+		goto err_assert_rst;
+
+	if (!master->secondary && !master->base.jdec_spd) {
+		aspeed_i3c_master_iba_ctrl(master, true);
+		ret = aspeed_i3c_master_enable_hj(master);
+		if (ret)
+			goto err_master_register;
+	}
+
+	return 0;
+
+err_master_register:
+	i3c_master_unregister(&master->base);
+
+err_assert_rst:
+	reset_control_assert(master->core_rst);
+
+err_disable_core_clk:
+	clk_disable_unprepare(master->core_clk);
+
+	return ret;
+}
+
+static int aspeed_i3c_remove(struct platform_device *pdev)
+{
+	struct aspeed_i3c_master *master = platform_get_drvdata(pdev);
+	int ret;
+
+	ret = i3c_master_unregister(&master->base);
+	if (ret)
+		return ret;
+
+	reset_control_assert(master->core_rst);
+
+	clk_disable_unprepare(master->core_clk);
+
+	return 0;
+}
+
+static const struct of_device_id aspeed_i3c_master_of_match[] = {
+	{ .compatible = "aspeed,ast2600-i3c", },
+	{},
+};
+MODULE_DEVICE_TABLE(of, aspeed_i3c_master_of_match);
+
+static struct platform_driver aspeed_i3c_driver = {
+	.probe = aspeed_i3c_probe,
+	.remove = aspeed_i3c_remove,
+	.driver = {
+		.name = "ast2600-i3c-master",
+		.of_match_table = of_match_ptr(aspeed_i3c_master_of_match),
+	},
+};
+module_platform_driver(aspeed_i3c_driver);
+
+MODULE_AUTHOR("Dylan Hung <dylan_hung@aspeedtech.com>");
+MODULE_DESCRIPTION("Aspeed MIPI I3C driver");
+MODULE_LICENSE("GPL v2");
diff --git a/drivers/i3c/master/dw-i3c-master.c b/drivers/i3c/master/dw-i3c-master.c
index e56b247f7e96..51a8608203de 100644
--- a/drivers/i3c/master/dw-i3c-master.c
+++ b/drivers/i3c/master/dw-i3c-master.c
@@ -4,6 +4,7 @@
  *
  * Author: Vitor Soares <vitor.soares@synopsys.com>
  */
+
 #include <linux/bitops.h>
 #include <linux/clk.h>
 #include <linux/completion.h>
@@ -20,14 +21,11 @@
 #include <linux/reset.h>
 #include <linux/slab.h>

-//#define IBI_WIP
-//#define CCC_WORKAROUND
 #define DEVICE_CTRL			0x0
 #define DEV_CTRL_ENABLE			BIT(31)
 #define DEV_CTRL_RESUME			BIT(30)
 #define DEV_CTRL_HOT_JOIN_NACK		BIT(8)
 #define DEV_CTRL_I2C_SLAVE_PRESENT	BIT(7)
-#define DEV_CTRL_IBI_DATA_EN		BIT(1)

 #define DEVICE_ADDR			0x4
 #define DEV_ADDR_DYNAMIC_ADDR_VALID	BIT(31)
@@ -76,14 +74,7 @@

 #define RX_TX_DATA_PORT			0x14
 #define IBI_QUEUE_STATUS		0x18
-#define IBI_QUEUE_DATA			0x18
-#define IBI_QUEUE_DATA_STATUS_MASK	GENMASK(31, 28)
-#define IBI_QUEUE_DATA_PAYLOAD_MASK	GENMASK(15, 8)
 #define QUEUE_THLD_CTRL			0x1c
-#define QUEUE_THLD_CTRL_IBI_STA_MASK	GENMASK(31, 24)
-#define QUEUE_THLD_CTRL_IBI_STA(x)	(((x) - 1) << 24)
-#define QUEUE_THLD_CTRL_IBI_DAT_MASK	GENMASK(23, 16)
-#define QUEUE_THLD_CTRL_IBI_DAT(x)	((x) << 16)
 #define QUEUE_THLD_CTRL_RESP_BUF_MASK	GENMASK(15, 8)
 #define QUEUE_THLD_CTRL_RESP_BUF(x)	(((x) - 1) << 8)

@@ -134,14 +125,9 @@
 					INTR_IBI_THLD_STAT |		\
 					INTR_TX_THLD_STAT |		\
 					INTR_RX_THLD_STAT)
-#ifdef IBI_WIP
-#define INTR_MASTER_MASK		(INTR_TRANSFER_ERR_STAT |	\
-					 INTR_RESP_READY_STAT	|	\
-					 INTR_IBI_THLD_STAT)
-#else
+
 #define INTR_MASTER_MASK		(INTR_TRANSFER_ERR_STAT |	\
 					 INTR_RESP_READY_STAT)
-#endif

 #define QUEUE_STATUS_LEVEL		0x4c
 #define QUEUE_STATUS_IBI_STATUS_CNT(x)	(((x) & GENMASK(28, 24)) >> 24)
@@ -199,28 +185,9 @@
 #define SLAVE_CONFIG			0xec

 #define DEV_ADDR_TABLE_LEGACY_I2C_DEV	BIT(31)
-#define DEV_ADDR_TABLE_DEV_NACK_RETRY(x) (((x) << 29) & GENMASK(30, 29))
-#define DEV_ADDR_TABLE_IBI_ADDR_MASK    GENMASK(25, 24)
-#define IBI_ADDR_MASK_LAST_3BITS        ((1 << 24) & GENMASK(25, 24))
-#define IBI_ADDR_MASK_LAST_4BITS        ((2 << 24) & GENMASK(25, 24))
-#define DEV_ADDR_TABLE_MR_REJECT        BIT(14)
-#define DEV_ADDR_TABLE_SIR_REJECT       BIT(13)
-#define DEV_ADDR_TABLE_IBI_WITH_DATA    BIT(12)
-#define DEV_ADDR_TABLE_IBI_PEC_EN       BIT(11)
 #define DEV_ADDR_TABLE_DYNAMIC_ADDR(x)	(((x) << 16) & GENMASK(23, 16))
 #define DEV_ADDR_TABLE_STATIC_ADDR(x)	((x) & GENMASK(6, 0))
 #define DEV_ADDR_TABLE_LOC(start, idx)	((start) + ((idx) << 2))
-#define GET_DYNAMIC_ADDR_FROM_DAT(x)    (((x)&GENMASK(22, 16)) >> 16)
-#define GET_DAT_FROM_POS(_master, _pos)                                        \
-        (readl(_master->regs + DEV_ADDR_TABLE_LOC(_master->datstartaddr, _pos)))
-
-#define DEV_ADDR_TABLE_LOC_OFFSET    0x280
-#define HW_RETRY_3_MASK              0x60000000
-#define NUM_OF_I3C_DEVICES           8
-#define SDA_DLY_TIMING_OFFSET        0xD0
-#define SDA_TX_HOLD_APML             0x00030000
-#define SDA_TX_HOLD_DIMM             0x00070000
-#define SDA_TX_MASK                  0xFFF8FFFF

 #define MAX_DEVS 32

@@ -231,21 +198,9 @@
 #define I3C_BUS_I2C_FM_TLOW_MIN_NS	1300
 #define I3C_BUS_I2C_FMP_TLOW_MIN_NS	500
 #define I3C_BUS_THIGH_MAX_NS		41
-#define I3C_BUS_OP_TLOW_MIN_NS		500
-#define I3C_BUS_OP_THIGH_MIN_NS		260
-#define I3C_BUS_PP_TLOW_MIN_NS		35
-#define I3C_BUS_PP_THIGH_MIN_NS		35

 #define XFER_TIMEOUT (msecs_to_jiffies(1000))

-#define MAX_GROUPS                      (1 << 4)
-#define MAX_DEVS_IN_GROUP               (1 << 3)
-#define ALL_DEVS_IN_GROUP_ARE_FREE      ((1 << MAX_DEVS_IN_GROUP) - 1)
-#define ADDR_GRP_MASK                   GENMASK(6, 3)
-#define ADDR_GRP(x)                     (((x) & ADDR_GRP_MASK) >> 3)
-#define ADDR_HID_MASK                   GENMASK(2, 0)
-#define ADDR_HID(x)                     ((x) & ADDR_HID_MASK)
-
 struct dw_i3c_master_caps {
 	u8 cmdfifodepth;
 	u8 datafifodepth;
@@ -266,26 +221,14 @@ struct dw_i3c_xfer {
 	struct completion comp;
 	int ret;
 	unsigned int ncmds;
-	struct dw_i3c_cmd cmds[0];
-};
-
-struct dw_i3c_dev_group {
-	u32 dat[8];
-	u32 free_pos;
-	int hw_index;
-	struct {
-		u32 set;
-		u32 clr;
-	} mask;
+	struct dw_i3c_cmd cmds[];
 };

 struct dw_i3c_master {
-	struct device *dev;
 	struct i3c_master_controller base;
 	u16 maxdevs;
 	u16 datstartaddr;
 	u32 free_pos;
-	struct dw_i3c_dev_group dev_group[MAX_GROUPS];
 	struct {
 		struct list_head list;
 		struct dw_i3c_xfer *cur;
@@ -343,8 +286,6 @@ static bool dw_i3c_master_supports_ccc_cmd(struct i3c_master_controller *m,
 	case I3C_CCC_GETSTATUS:
 	case I3C_CCC_GETMXDS:
 	case I3C_CCC_GETHDRCAP:
-	case I3C_CCC_SETAASA:
-	case I3C_CCC_SETHID:
 		return true;
 	default:
 		return false;
@@ -365,7 +306,7 @@ static void dw_i3c_master_disable(struct dw_i3c_master *master)

 static void dw_i3c_master_enable(struct dw_i3c_master *master)
 {
-	writel(readl(master->regs + DEVICE_CTRL) | DEV_CTRL_ENABLE | DEV_CTRL_IBI_DATA_EN,
+	writel(readl(master->regs + DEVICE_CTRL) | DEV_CTRL_ENABLE,
 	       master->regs + DEVICE_CTRL);
 }

@@ -388,96 +329,6 @@ static int dw_i3c_master_get_free_pos(struct dw_i3c_master *master)

 	return ffs(master->free_pos) - 1;
 }
-static void dw_i3c_master_init_group_dat(struct dw_i3c_master *master)
-{
-	struct dw_i3c_dev_group *dev_grp;
-	int i, j;
-	u32 def_set, def_clr;
-
-	def_clr = DEV_ADDR_TABLE_IBI_ADDR_MASK;
-
-	/* For now don't support Hot-Join */
-	def_set = DEV_ADDR_TABLE_MR_REJECT | DEV_ADDR_TABLE_SIR_REJECT | IBI_ADDR_MASK_LAST_3BITS;
-
-	for (i = 0; i < MAX_GROUPS; i++) {
-		dev_grp = &master->dev_group[i];
-		dev_grp->hw_index = -1;
-		dev_grp->free_pos = ALL_DEVS_IN_GROUP_ARE_FREE;
-		dev_grp->mask.set = def_set;
-		dev_grp->mask.clr = def_clr;
-		for (j = 0; j < MAX_DEVS_IN_GROUP; j++)
-			dev_grp->dat[j] = 0;
-	}
-
-	for (i = 0; i < master->maxdevs; i++)
-		writel(def_set, master->regs + DEV_ADDR_TABLE_LOC(master->datstartaddr, i));
-}
-
-static int dw_i3c_master_set_group_dat(struct dw_i3c_master *master, u8 addr, u32 val)
-{
-	struct dw_i3c_dev_group *dev_grp = &master->dev_group[ADDR_GRP(addr)];
-	u8 idx = ADDR_HID(addr);
-
-	dev_grp->dat[idx] = val;
-
-	if (val) {
-		dev_grp->free_pos &= ~BIT(idx);
-		/*
-		 * reserve the hw dat resource for the first member of the
-		 * group. all the members in the group share the same hw dat.
-		 */
-		if (dev_grp->hw_index == -1) {
-			dev_grp->hw_index = dw_i3c_master_get_free_pos(master);
-			if (dev_grp->hw_index < 0)
-				goto out;
-
-			master->free_pos &= ~BIT(dev_grp->hw_index);
-			writel(val, master->regs + DEV_ADDR_TABLE_LOC(
-							master->datstartaddr,
-							dev_grp->hw_index));
-		}
-	} else {
-		dev_grp->free_pos |= BIT(idx);
-
-		/*
-		 * release the hw dat resource if all the members in the group
-		 * are free.
-		 */
-		if (dev_grp->free_pos == ALL_DEVS_IN_GROUP_ARE_FREE) {
-			writel(0, master->regs + DEV_ADDR_TABLE_LOC(
-							master->datstartaddr,
-							dev_grp->hw_index));
-			master->free_pos |= BIT(dev_grp->hw_index);
-			dev_grp->hw_index = -1;
-		}
-	}
-out:
-	return dev_grp->hw_index;
-}
-
-static int dw_i3c_master_get_group_hw_index(struct dw_i3c_master *master,
-                                            u8 addr)
-{
-	struct dw_i3c_dev_group *dev_grp = &master->dev_group[ADDR_GRP(addr)];
-
-	return dev_grp->hw_index;
-}
-
-static int dw_i3c_master_sync_hw_dat(struct dw_i3c_master *master, u8 addr)
-{
-	struct dw_i3c_dev_group *dev_grp = &master->dev_group[ADDR_GRP(addr)];
-	u32 dat = dev_grp->dat[ADDR_HID(addr)];
-	int hw_index = dev_grp->hw_index;
-
-	if (!dat || hw_index < 0)
-		return -1;
-
-	dat &= ~dev_grp->mask.clr;
-	dat |= dev_grp->mask.set;
-	writel(dat, master->regs +
-		DEV_ADDR_TABLE_LOC(master->datstartaddr, hw_index));
-	return hw_index;
-}

 static void dw_i3c_master_wr_tx_fifo(struct dw_i3c_master *master,
 				     const u8 *bytes, int nbytes)
@@ -488,7 +339,6 @@ static void dw_i3c_master_wr_tx_fifo(struct dw_i3c_master *master,

 		memcpy(&tmp, bytes + (nbytes & ~3), nbytes & 3);
 		writesl(master->regs + RX_TX_DATA_PORT, &tmp, 1);
-		dev_dbg(master->dev, "TX data = %08x\n", tmp);
 	}
 }

@@ -604,25 +454,6 @@ static void dw_i3c_master_end_xfer_locked(struct dw_i3c_master *master, u32 isr)
 	int i, ret = 0;
 	u32 nresp;

-#ifdef IBI_WIP
-	int j = 0;
-	u32 nibi;
-
-	/* consume the IBI data */
-	nibi = readl(master->regs + QUEUE_STATUS_LEVEL);
-	nibi = QUEUE_STATUS_IBI_BUF_BLR(nibi);
-
-	if ((isr & INTR_IBI_THLD_STAT) && nibi) {
-		u32 ibi;
-		for (i = 0; i < nibi; i++) {
-			ibi = readl(master->regs + IBI_QUEUE_DATA);
-			for (j = 0; j < (ibi & 0xff); j += 4)
-				dev_dbg(master->dev, "ibi: %08x\n", readl(master->regs + IBI_QUEUE_DATA));
-		}
-		writel(RESET_CTRL_IBI_QUEUE, master->regs + RESET_CTRL);
-	}
-#endif
-
 	if (!xfer)
 		return;

@@ -657,10 +488,8 @@ static void dw_i3c_master_end_xfer_locked(struct dw_i3c_master *master, u32 isr)
 		case RESPONSE_ERROR_OVER_UNDER_FLOW:
 			ret = -ENOSPC;
 			break;
-		case RESPONSE_ERROR_ADDRESS_NACK:
-			ret = -ECONNREFUSED;
-			break;
 		case RESPONSE_ERROR_I2C_W_NACK_ERR:
+		case RESPONSE_ERROR_ADDRESS_NACK:
 		default:
 			ret = -EINVAL;
 			break;
@@ -688,7 +517,7 @@ static void dw_i3c_master_end_xfer_locked(struct dw_i3c_master *master, u32 isr)

 static int dw_i3c_clk_cfg(struct dw_i3c_master *master)
 {
-	unsigned long core_rate, core_period, scl_period_h, scl_period_l;
+	unsigned long core_rate, core_period;
 	u32 scl_timing;
 	u8 hcnt, lcnt;

@@ -698,73 +527,23 @@ static int dw_i3c_clk_cfg(struct dw_i3c_master *master)

 	core_period = DIV_ROUND_UP(1000000000, core_rate);

-	if (master->base.jdec_spd) {
-		/* set open-drain timing according to I2C SCL frequency */
-		if (master->base.bus.scl_rate.i2c) {
-			scl_period_h = scl_period_l =
-				DIV_ROUND_UP(1000000000,
-					     master->base.bus.scl_rate.i2c) >> 1;
-		} else {
-			/* default: I2C SCL = 400kHz (fast mode) */
-			scl_period_h = scl_period_l =
-				DIV_ROUND_UP(1000000000, 400000) >> 1;
-		}
-
-		if (scl_period_h < I3C_BUS_OP_THIGH_MIN_NS)
-			scl_period_h = I3C_BUS_OP_THIGH_MIN_NS;
-		if (scl_period_l < I3C_BUS_OP_TLOW_MIN_NS)
-			scl_period_l = I3C_BUS_OP_TLOW_MIN_NS;
-		hcnt = DIV_ROUND_UP(scl_period_h, core_period) + 1;
-		lcnt = DIV_ROUND_UP(scl_period_l, core_period) + 1;
-		scl_timing = SCL_I3C_TIMING_HCNT(hcnt) | SCL_I3C_TIMING_LCNT(lcnt);
-		writel(scl_timing, master->regs + SCL_I3C_OD_TIMING);
-		scl_timing = SCL_I2C_FM_TIMING_HCNT(hcnt) | SCL_I2C_FM_TIMING_LCNT(lcnt);
-		writel(scl_timing, master->regs + SCL_I2C_FM_TIMING);
-		scl_timing = SCL_I2C_FMP_TIMING_HCNT(hcnt) | SCL_I2C_FMP_TIMING_LCNT(lcnt);
-		writel(scl_timing, master->regs + SCL_I2C_FMP_TIMING);
-		pr_info( "dw_i3c_clk_cfg: I2C Freq %d, SCL_H %d SCL_L %d \n", master->base.bus.scl_rate.i2c, scl_period_h, scl_period_l);
-
-		if (!(readl(master->regs + DEVICE_CTRL) & DEV_CTRL_I2C_SLAVE_PRESENT))
-			writel(BUS_I3C_MST_FREE(lcnt), master->regs + BUS_FREE_TIMING);
-
-		/* set push-pull timing according to I3C SCL frequency */
-		if (master->base.bus.scl_rate.i3c) {
-			scl_period_h = scl_period_l =
-				DIV_ROUND_UP(1000000000,
-					     master->base.bus.scl_rate.i3c) >> 1;
-		} else {
-			/* default: I3C SCL = 12.5MHz */
-			scl_period_h = scl_period_l =
-				DIV_ROUND_UP(1000000000, 12500000) >> 1;
-		}
-		if (scl_period_h < I3C_BUS_PP_THIGH_MIN_NS)
-			scl_period_h = I3C_BUS_PP_THIGH_MIN_NS;
-		if (scl_period_l < I3C_BUS_PP_TLOW_MIN_NS)
-			scl_period_l = I3C_BUS_PP_TLOW_MIN_NS;
-		hcnt = DIV_ROUND_UP(scl_period_h, core_period);
-		lcnt = DIV_ROUND_UP(scl_period_l, core_period);
-		scl_timing = SCL_I3C_TIMING_HCNT(hcnt) | SCL_I3C_TIMING_LCNT(lcnt);
-		writel(scl_timing, master->regs + SCL_I3C_PP_TIMING);
-		pr_info( "dw_i3c_clk_cfg: I3C Freq %d, Hcnt %d Lcnt %d \n", master->base.bus.scl_rate.i3c, hcnt, lcnt);
-	} else {
-		hcnt = DIV_ROUND_UP(I3C_BUS_THIGH_MAX_NS, core_period) - 1;
-		if (hcnt < SCL_I3C_TIMING_CNT_MIN)
-			hcnt = SCL_I3C_TIMING_CNT_MIN;
+	hcnt = DIV_ROUND_UP(I3C_BUS_THIGH_MAX_NS, core_period) - 1;
+	if (hcnt < SCL_I3C_TIMING_CNT_MIN)
+		hcnt = SCL_I3C_TIMING_CNT_MIN;

-		lcnt = DIV_ROUND_UP(core_rate, I3C_BUS_TYP_I3C_SCL_RATE) - hcnt;
-		if (lcnt < SCL_I3C_TIMING_CNT_MIN)
-			lcnt = SCL_I3C_TIMING_CNT_MIN;
+	lcnt = DIV_ROUND_UP(core_rate, I3C_BUS_TYP_I3C_SCL_RATE) - hcnt;
+	if (lcnt < SCL_I3C_TIMING_CNT_MIN)
+		lcnt = SCL_I3C_TIMING_CNT_MIN;

-		scl_timing = SCL_I3C_TIMING_HCNT(hcnt) | SCL_I3C_TIMING_LCNT(lcnt);
-		writel(scl_timing, master->regs + SCL_I3C_PP_TIMING);
+	scl_timing = SCL_I3C_TIMING_HCNT(hcnt) | SCL_I3C_TIMING_LCNT(lcnt);
+	writel(scl_timing, master->regs + SCL_I3C_PP_TIMING);

-		if (!(readl(master->regs + DEVICE_CTRL) & DEV_CTRL_I2C_SLAVE_PRESENT))
-			writel(BUS_I3C_MST_FREE(lcnt), master->regs + BUS_FREE_TIMING);
+	if (!(readl(master->regs + DEVICE_CTRL) & DEV_CTRL_I2C_SLAVE_PRESENT))
+		writel(BUS_I3C_MST_FREE(lcnt), master->regs + BUS_FREE_TIMING);

-		lcnt = DIV_ROUND_UP(I3C_BUS_TLOW_OD_MIN_NS, core_period);
-		scl_timing = SCL_I3C_TIMING_HCNT(hcnt) | SCL_I3C_TIMING_LCNT(lcnt);
-		writel(scl_timing, master->regs + SCL_I3C_OD_TIMING);
-	}
+	lcnt = DIV_ROUND_UP(I3C_BUS_TLOW_OD_MIN_NS, core_period);
+	scl_timing = SCL_I3C_TIMING_HCNT(hcnt) | SCL_I3C_TIMING_LCNT(lcnt);
+	writel(scl_timing, master->regs + SCL_I3C_OD_TIMING);

 	lcnt = DIV_ROUND_UP(core_rate, I3C_BUS_SDR1_SCL_RATE) - hcnt;
 	scl_timing = SCL_EXT_LCNT_1(lcnt);
@@ -824,7 +603,7 @@ static int dw_i3c_master_bus_init(struct i3c_master_controller *m)
 		ret = dw_i2c_clk_cfg(master);
 		if (ret)
 			return ret;
-		/* fall through */
+		fallthrough;
 	case I3C_BUS_MODE_PURE:
 		ret = dw_i3c_clk_cfg(master);
 		if (ret)
@@ -860,20 +639,8 @@ static int dw_i3c_master_bus_init(struct i3c_master_controller *m)
 	if (ret)
 		return ret;

-#ifdef IBI_WIP
-	thld_ctrl = readl(master->regs + QUEUE_THLD_CTRL);
-	thld_ctrl &=
-		~(QUEUE_THLD_CTRL_IBI_STA_MASK | QUEUE_THLD_CTRL_IBI_DAT_MASK);
-	thld_ctrl |= QUEUE_THLD_CTRL_IBI_STA(1);
-	thld_ctrl |= QUEUE_THLD_CTRL_IBI_DAT(1);
-	writel(thld_ctrl, master->regs + QUEUE_THLD_CTRL);
-
-	writel(0, master->regs + IBI_SIR_REQ_REJECT);
-	writel(0, master->regs + IBI_MR_REQ_REJECT);
-#else
 	writel(IBI_REQ_REJECT_ALL, master->regs + IBI_SIR_REQ_REJECT);
 	writel(IBI_REQ_REJECT_ALL, master->regs + IBI_MR_REQ_REJECT);
-#endif

 	/* For now don't support Hot-Join */
 	writel(readl(master->regs + DEVICE_CTRL) | DEV_CTRL_HOT_JOIN_NACK,
@@ -899,10 +666,7 @@ static int dw_i3c_ccc_set(struct dw_i3c_master *master,
 	int ret, pos = 0;

 	if (ccc->id & I3C_CCC_DIRECT) {
-		if(master->base.set_dasa) // APML
-			pos = dw_i3c_master_get_addr_pos(master, ccc->dests[0].addr);
-		else // DIMM
-			pos = dw_i3c_master_sync_hw_dat(master, ccc->dests[0].addr);
+		pos = dw_i3c_master_get_addr_pos(master, ccc->dests[0].addr);
 		if (pos < 0)
 			return pos;
 	}
@@ -924,9 +688,6 @@ static int dw_i3c_ccc_set(struct dw_i3c_master *master,
 		      COMMAND_PORT_TOC |
 		      COMMAND_PORT_ROC;

-	dev_dbg(master->dev, "%s:cmd_hi=0x%08x cmd_lo=0x%08x tx_len=%d id=%x\n",
-		__func__, cmd->cmd_hi, cmd->cmd_lo, cmd->tx_len, ccc->id);
-
 	dw_i3c_master_enqueue_xfer(master, xfer);
 	if (!wait_for_completion_timeout(&xfer->comp, XFER_TIMEOUT))
 		dw_i3c_master_dequeue_xfer(master, xfer);
@@ -946,10 +707,7 @@ static int dw_i3c_ccc_get(struct dw_i3c_master *master, struct i3c_ccc_cmd *ccc)
 	struct dw_i3c_cmd *cmd;
 	int ret, pos;

-	if(master->base.set_dasa) // APML
-		pos = dw_i3c_master_get_addr_pos(master, ccc->dests[0].addr);
-	else // DIMM
-		pos = dw_i3c_master_sync_hw_dat(master, ccc->dests[0].addr);
+	pos = dw_i3c_master_get_addr_pos(master, ccc->dests[0].addr);
 	if (pos < 0)
 		return pos;

@@ -971,9 +729,6 @@ static int dw_i3c_ccc_get(struct dw_i3c_master *master, struct i3c_ccc_cmd *ccc)
 		      COMMAND_PORT_TOC |
 		      COMMAND_PORT_ROC;

-	dev_dbg(master->dev, "%s:cmd_hi=0x%08x cmd_lo=0x%08x rx_len=%d id=%x\n",
-		__func__, cmd->cmd_hi, cmd->cmd_lo, cmd->rx_len, ccc->id);
-
 	dw_i3c_master_enqueue_xfer(master, xfer);
 	if (!wait_for_completion_timeout(&xfer->comp, XFER_TIMEOUT))
 		dw_i3c_master_dequeue_xfer(master, xfer);
@@ -991,29 +746,14 @@ static int dw_i3c_master_send_ccc_cmd(struct i3c_master_controller *m,
 {
 	struct dw_i3c_master *master = to_dw_i3c_master(m);
 	int ret = 0;
-	u32 i3c_pp_timing, i3c_od_timing;

-	if (ccc->id == I3C_CCC_ENTDAA){
-		pr_err( "dw_i3c_master_send_ccc_cmd: Error " " ENTDAA , bus %d, cmd 0x%x\n",m->bus.id, ccc->id );
+	if (ccc->id == I3C_CCC_ENTDAA)
 		return -EINVAL;
-	}
-
-	i3c_od_timing = readl(master->regs + SCL_I3C_OD_TIMING);
-	i3c_pp_timing = readl(master->regs + SCL_I3C_PP_TIMING);
-	if ((ccc->id == I3C_CCC_SETAASA) || (ccc->id == I3C_CCC_SETHID) ||
-	    (ccc->id == I3C_CCC_DEVCTRL)) {
-		writel(i3c_od_timing, master->regs + SCL_I3C_PP_TIMING);
-	}

 	if (ccc->rnw)
 		ret = dw_i3c_ccc_get(master, ccc);
 	else
 		ret = dw_i3c_ccc_set(master, ccc);
-	if(ret != 0)
-		pr_err( "dw_i3c_master_send_ccc_cmd: Error bus %d, cmd 0x%x r/w %d ret %d\n",m->bus.id, ccc->id , ccc->rnw, ret);
-	if ((ccc->id == I3C_CCC_SETAASA) || (ccc->id == I3C_CCC_SETHID)) {
-		writel(i3c_pp_timing, master->regs + SCL_I3C_PP_TIMING);
-	}

 	return ret;
 }
@@ -1025,10 +765,9 @@ static int dw_i3c_master_daa(struct i3c_master_controller *m)
 	struct dw_i3c_cmd *cmd;
 	u32 olddevs, newdevs;
 	u8 p, last_addr = 0;
-	int ret, pos, ndevs;
+	int ret, pos;

 	olddevs = ~(master->free_pos);
-	ndevs = 0;

 	/* Prepare DAT before launching DAA. */
 	for (pos = 0; pos < master->maxdevs; pos++) {
@@ -1037,9 +776,7 @@ static int dw_i3c_master_daa(struct i3c_master_controller *m)

 		ret = i3c_master_get_free_addr(m, last_addr + 1);
 		if (ret < 0)
-			break;
-
-		ndevs++;
+			return -ENOSPC;

 		master->addrs[pos] = ret;
 		p = even_parity(ret);
@@ -1051,14 +788,15 @@ static int dw_i3c_master_daa(struct i3c_master_controller *m)
 		       DEV_ADDR_TABLE_LOC(master->datstartaddr, pos));
 	}

-	if (!ndevs)
-		return -ENOSPC;
-
 	xfer = dw_i3c_master_alloc_xfer(master, 1);
 	if (!xfer)
 		return -ENOMEM;

 	pos = dw_i3c_master_get_free_pos(master);
+	if (pos < 0) {
+		dw_i3c_master_free_xfer(xfer);
+		return pos;
+	}
 	cmd = &xfer->cmds[0];
 	cmd->cmd_hi = 0x1;
 	cmd->cmd_lo = COMMAND_PORT_DEV_COUNT(master->maxdevs - pos) |
@@ -1072,120 +810,19 @@ static int dw_i3c_master_daa(struct i3c_master_controller *m)
 	if (!wait_for_completion_timeout(&xfer->comp, XFER_TIMEOUT))
 		dw_i3c_master_dequeue_xfer(master, xfer);

-	if(m->set_dasa) { // APML
-		newdevs = GENMASK(master->maxdevs - cmd->rx_len - 1, 0);
-		newdevs &= ~olddevs;
-	}
-	else  // DIMM
-		newdevs = GENMASK(ndevs - cmd->rx_len - 1, 0) << pos;
-	for (pos = 0; pos < master->maxdevs; pos++) {
-		if (newdevs & BIT(pos)) {
-			if(m->set_dasa)  // APML
-				i3c_master_add_i3c_dev_locked(m, master->addrs[pos]);
-			else {  // DIMM
-				u32 dat = GET_DAT_FROM_POS(master, pos);
-				u32 addr = GET_DYNAMIC_ADDR_FROM_DAT(dat);
-
-				dw_i3c_master_set_group_dat(master, addr, dat);
-				i3c_master_add_i3c_dev_locked(m, addr);
-			}
-		}
+	newdevs = GENMASK(master->maxdevs - cmd->rx_len - 1, 0);
+	newdevs &= ~olddevs;

-		/* cleanup the free HW DATs */
-		if ((master->free_pos & BIT(pos)) &&
-		   (!(m->set_dasa)))
-			writel(0, master->regs +
-				DEV_ADDR_TABLE_LOC( master->datstartaddr, pos));
+	for (pos = 0; pos < master->maxdevs; pos++) {
+		if (newdevs & BIT(pos))
+			i3c_master_add_i3c_dev_locked(m, master->addrs[pos]);
 	}

 	dw_i3c_master_free_xfer(xfer);
-	if(m->set_dasa)
-		i3c_master_disec_locked(m, I3C_BROADCAST_ADDR,
-					I3C_CCC_EVENT_HJ |
-					I3C_CCC_EVENT_MR |
-					I3C_CCC_EVENT_SIR);

 	return 0;
 }
-#ifdef CCC_WORKAROUND
-/**
- * Provide an interface for sending CCC from userspace.  Especially for the
- * transfers with PEC and direct CCC.
-*/
-static int dw_i3c_master_ccc_xfers(struct i3c_dev_desc *dev,
-				    struct i3c_priv_xfer *i3c_xfers,
-				    int i3c_nxfers)
-{
-	struct dw_i3c_i2c_dev_data *data = i3c_dev_get_master_data(dev);
-	struct i3c_master_controller *m = i3c_dev_get_master(dev);
-	struct dw_i3c_master *master = to_dw_i3c_master(m);
-	struct dw_i3c_xfer *xfer;
-	int i, ret = 0;
-	struct dw_i3c_cmd *cmd_ccc;
-
-	xfer = dw_i3c_master_alloc_xfer(master, i3c_nxfers);
-	if (!xfer)
-		return -ENOMEM;
-
-	/* i3c_xfers[0] handles the CCC data */
-	cmd_ccc = &xfer->cmds[0];
-	cmd_ccc->cmd_hi = COMMAND_PORT_ARG_DATA_LEN(i3c_xfers[0].len - 1) |
-			  COMMAND_PORT_TRANSFER_ARG;
-	cmd_ccc->tx_buf = i3c_xfers[0].data.out + 1;
-	cmd_ccc->tx_len = i3c_xfers[0].len - 1;
-	cmd_ccc->cmd_lo = COMMAND_PORT_SPEED(dev->info.max_write_ds);
-	cmd_ccc->cmd_lo |= COMMAND_PORT_TID(0) |
-			   COMMAND_PORT_DEV_INDEX(master->maxdevs - 1) |
-			   COMMAND_PORT_ROC;
-	if (i3c_nxfers == 1)
-		cmd_ccc->cmd_lo |= COMMAND_PORT_TOC;
-
-	dev_dbg(master->dev,
-		"%s:cmd_ccc_hi=0x%08x cmd_ccc_lo=0x%08x tx_len=%d\n", __func__,
-		cmd_ccc->cmd_hi, cmd_ccc->cmd_lo, cmd_ccc->tx_len);
-
-	for (i = 1; i < i3c_nxfers; i++) {
-		struct dw_i3c_cmd *cmd = &xfer->cmds[i];
-
-		cmd->cmd_hi = COMMAND_PORT_ARG_DATA_LEN(i3c_xfers[i].len) |
-			COMMAND_PORT_TRANSFER_ARG;

-		if (i3c_xfers[i].rnw) {
-			cmd->rx_buf = i3c_xfers[i].data.in;
-			cmd->rx_len = i3c_xfers[i].len;
-			cmd->cmd_lo = COMMAND_PORT_READ_TRANSFER |
-				      COMMAND_PORT_SPEED(dev->info.max_read_ds);
-
-		} else {
-			cmd->tx_buf = i3c_xfers[i].data.out;
-			cmd->tx_len = i3c_xfers[i].len;
-			cmd->cmd_lo =
-				COMMAND_PORT_SPEED(dev->info.max_write_ds);
-		}
-
-		cmd->cmd_lo |= COMMAND_PORT_TID(i) |
-			       COMMAND_PORT_DEV_INDEX(data->index) |
-			       COMMAND_PORT_ROC;
-
-		if (i == (i3c_nxfers - 1))
-			cmd->cmd_lo |= COMMAND_PORT_TOC;
-
-		dev_dbg(master->dev,
-			"%s:cmd_hi=0x%08x cmd_lo=0x%08x tx_len=%d rx_len=%d\n",
-			__func__, cmd->cmd_hi, cmd->cmd_lo, cmd->tx_len,
-			cmd->rx_len);
-	}
-
-	dw_i3c_master_enqueue_xfer(master, xfer);
-	if (!wait_for_completion_timeout(&xfer->comp, XFER_TIMEOUT))
-		dw_i3c_master_dequeue_xfer(master, xfer);
-
-	ret = xfer->ret;
-	dw_i3c_master_free_xfer(xfer);
-
-	return ret;
-}
-#endif
 static int dw_i3c_master_priv_xfers(struct i3c_dev_desc *dev,
 				    struct i3c_priv_xfer *i3c_xfers,
 				    int i3c_nxfers)
@@ -1214,23 +851,10 @@ static int dw_i3c_master_priv_xfers(struct i3c_dev_desc *dev,
 	    nrxwords > master->caps.datafifodepth)
 		return -ENOTSUPP;

-#ifdef CCC_WORKAROUND
-	if (0 == i3c_xfers[0].rnw) {
-		/* write command: check if hit special address */
-		u8 tmp;
-		memcpy(&tmp, i3c_xfers[0].data.out, 1);
-		if (0xff == tmp)
-			return dw_i3c_master_ccc_xfers(dev, i3c_xfers, i3c_nxfers);
-	}
-#endif
-
 	xfer = dw_i3c_master_alloc_xfer(master, i3c_nxfers);
 	if (!xfer)
 		return -ENOMEM;

-	if(!(m->set_dasa))  // DIMM
-		data->index = dw_i3c_master_sync_hw_dat(master, dev->info.dyn_addr);
-
 	for (i = 0; i < i3c_nxfers; i++) {
 		struct dw_i3c_cmd *cmd = &xfer->cmds[i];

@@ -1256,26 +880,12 @@ static int dw_i3c_master_priv_xfers(struct i3c_dev_desc *dev,

 		if (i == (i3c_nxfers - 1))
 			cmd->cmd_lo |= COMMAND_PORT_TOC;
-
-		dev_dbg(master->dev,
-			"%s:cmd_hi=0x%08x cmd_lo=0x%08x tx_len=%d rx_len=%d\n",
-			__func__, cmd->cmd_hi, cmd->cmd_lo, cmd->tx_len,
-			cmd->rx_len);
 	}

 	dw_i3c_master_enqueue_xfer(master, xfer);
 	if (!wait_for_completion_timeout(&xfer->comp, XFER_TIMEOUT))
 		dw_i3c_master_dequeue_xfer(master, xfer);

-	if(!(m->set_dasa))  {  // DIMM
-		for (i = 0; i < i3c_nxfers; i++) {
-			struct dw_i3c_cmd *cmd = &xfer->cmds[i];
-
-			if (i3c_xfers[i].rnw)
-				i3c_xfers[i].len = cmd->rx_len;
-		}
-	}
-
 	ret = xfer->ret;
 	dw_i3c_master_free_xfer(xfer);

@@ -1288,35 +898,30 @@ static int dw_i3c_master_reattach_i3c_dev(struct i3c_dev_desc *dev,
 	struct dw_i3c_i2c_dev_data *data = i3c_dev_get_master_data(dev);
 	struct i3c_master_controller *m = i3c_dev_get_master(dev);
 	struct dw_i3c_master *master = to_dw_i3c_master(m);
+	int pos;

-	if(m->set_dasa)  // APML
-		writel(DEV_ADDR_TABLE_DYNAMIC_ADDR(dev->info.dyn_addr),master->regs +
-			DEV_ADDR_TABLE_LOC(master->datstartaddr, data->index));
-	else  // DIMM
-		dw_i3c_master_set_group_dat(
-			master, dev->info.dyn_addr,
-			DEV_ADDR_TABLE_DYNAMIC_ADDR(dev->info.dyn_addr));
+	pos = dw_i3c_master_get_free_pos(master);

-	master->addrs[data->index] = dev->info.dyn_addr;
+	if (data->index > pos && pos > 0) {
+		writel(0,
+		       master->regs +
+		       DEV_ADDR_TABLE_LOC(master->datstartaddr, data->index));

-	return 0;
-}
+		master->addrs[data->index] = 0;
+		master->free_pos |= BIT(data->index);

-static int scl_rate_to_speed_index(unsigned long scl_rate)
-{
-	switch (scl_rate) {
-	case I3C_BUS_SDR1_SCL_RATE:
-		return 1;
-	case I3C_BUS_SDR2_SCL_RATE:
-		return 2;
-	case I3C_BUS_SDR3_SCL_RATE:
-		return 3;
-	case I3C_BUS_SDR4_SCL_RATE:
-		return 4;
-	case I3C_BUS_TYP_I3C_SCL_RATE:
-	default:
-		return 0;
+		data->index = pos;
+		master->addrs[pos] = dev->info.dyn_addr;
+		master->free_pos &= ~BIT(pos);
 	}
+
+	writel(DEV_ADDR_TABLE_DYNAMIC_ADDR(dev->info.dyn_addr),
+	       master->regs +
+	       DEV_ADDR_TABLE_LOC(master->datstartaddr, data->index));
+
+	master->addrs[data->index] = dev->info.dyn_addr;
+
+	return 0;
 }

 static int dw_i3c_master_attach_i3c_dev(struct i3c_dev_desc *dev)
@@ -1325,13 +930,8 @@ static int dw_i3c_master_attach_i3c_dev(struct i3c_dev_desc *dev)
 	struct dw_i3c_master *master = to_dw_i3c_master(m);
 	struct dw_i3c_i2c_dev_data *data;
 	int pos;
-	u8 addr = dev->info.dyn_addr ? : dev->info.static_addr;

-	if (m->set_dasa)  // APML
-		pos = dw_i3c_master_get_free_pos(master);
-	else  // DIMM
-		pos = dw_i3c_master_set_group_dat(master, addr,
-                                          DEV_ADDR_TABLE_DYNAMIC_ADDR(addr));
+	pos = dw_i3c_master_get_free_pos(master);
 	if (pos < 0)
 		return pos;

@@ -1339,26 +939,15 @@ static int dw_i3c_master_attach_i3c_dev(struct i3c_dev_desc *dev)
 	if (!data)
 		return -ENOMEM;

-	if (m->set_dasa) {  // APML
-		data->index = pos;
-		master->addrs[pos] = dev->info.dyn_addr ? : dev->info.static_addr;
-		master->free_pos &= ~BIT(pos);
-		i3c_dev_set_master_data(dev, data);
+	data->index = pos;
+	master->addrs[pos] = dev->info.dyn_addr ? : dev->info.static_addr;
+	master->free_pos &= ~BIT(pos);
+	i3c_dev_set_master_data(dev, data);
+
+	writel(DEV_ADDR_TABLE_DYNAMIC_ADDR(master->addrs[pos]),
+	       master->regs +
+	       DEV_ADDR_TABLE_LOC(master->datstartaddr, data->index));

-		writel(DEV_ADDR_TABLE_DYNAMIC_ADDR(master->addrs[pos]),
-			master->regs +
-			DEV_ADDR_TABLE_LOC(master->datstartaddr, data->index));
-	}
-	else { // DIMM
-		data->index = dw_i3c_master_get_group_hw_index(master, addr);
-		master->addrs[pos] = addr;
-		i3c_dev_set_master_data(dev, data);
-
-		if (master->base.jdec_spd) {
-			dev->info.max_write_ds = dev->info.max_read_ds =
-				scl_rate_to_speed_index(m->bus.scl_rate.i3c);
-		}
-	}
 	return 0;
 }

@@ -1368,16 +957,13 @@ static void dw_i3c_master_detach_i3c_dev(struct i3c_dev_desc *dev)
 	struct i3c_master_controller *m = i3c_dev_get_master(dev);
 	struct dw_i3c_master *master = to_dw_i3c_master(m);

-	if (m->set_dasa)  // APML
-		writel(0, master->regs +
-			DEV_ADDR_TABLE_LOC(master->datstartaddr, data->index));
-	else  // DIMM
-		dw_i3c_master_set_group_dat(master, dev->info.dyn_addr, 0);
+	writel(0,
+	       master->regs +
+	       DEV_ADDR_TABLE_LOC(master->datstartaddr, data->index));

 	i3c_dev_set_master_data(dev, NULL);
 	master->addrs[data->index] = 0;
-	if (m->set_dasa)  // APML
-		master->free_pos |= BIT(data->index);
+	master->free_pos |= BIT(data->index);
 	kfree(data);
 }

@@ -1390,7 +976,7 @@ static int dw_i3c_master_i2c_xfers(struct i2c_dev_desc *dev,
 	struct dw_i3c_master *master = to_dw_i3c_master(m);
 	unsigned int nrxwords = 0, ntxwords = 0;
 	struct dw_i3c_xfer *xfer;
-	int speed, i, ret = 0;
+	int i, ret = 0;

 	if (!i2c_nxfers)
 		return 0;
@@ -1413,9 +999,6 @@ static int dw_i3c_master_i2c_xfers(struct i2c_dev_desc *dev,
 	if (!xfer)
 		return -ENOMEM;

-	data->index = dw_i3c_master_sync_hw_dat(master, dev->addr);
-	speed = (master->base.bus.scl_rate.i2c == I3C_BUS_I2C_FM_PLUS_SCL_RATE) ? 1 : 0;
-
 	for (i = 0; i < i2c_nxfers; i++) {
 		struct dw_i3c_cmd *cmd = &xfer->cmds[i];

@@ -1424,7 +1007,6 @@ static int dw_i3c_master_i2c_xfers(struct i2c_dev_desc *dev,

 		cmd->cmd_lo = COMMAND_PORT_TID(i) |
 			      COMMAND_PORT_DEV_INDEX(data->index) |
-			      COMMAND_PORT_SPEED(speed) |
 			      COMMAND_PORT_ROC;

 		if (i2c_xfers[i].flags & I2C_M_RD) {
@@ -1457,13 +1039,7 @@ static int dw_i3c_master_attach_i2c_dev(struct i2c_dev_desc *dev)
 	struct dw_i3c_i2c_dev_data *data;
 	int pos;

-	if (m->set_dasa)  // APML
-		pos = dw_i3c_master_get_free_pos(master);
-	else
-		pos = dw_i3c_master_set_group_dat(
-			master, dev->addr,
-			DEV_ADDR_TABLE_LEGACY_I2C_DEV |
-			DEV_ADDR_TABLE_STATIC_ADDR(dev->addr));
+	pos = dw_i3c_master_get_free_pos(master);
 	if (pos < 0)
 		return pos;

@@ -1471,21 +1047,15 @@ static int dw_i3c_master_attach_i2c_dev(struct i2c_dev_desc *dev)
 	if (!data)
 		return -ENOMEM;

-	if (m->set_dasa) {  // APML
-		data->index = pos;
-		master->addrs[pos] = dev->addr;
-		master->free_pos &= ~BIT(pos);
-		i2c_dev_set_master_data(dev, data);
-		writel(DEV_ADDR_TABLE_LEGACY_I2C_DEV |
-			DEV_ADDR_TABLE_STATIC_ADDR(dev->addr),
-			master->regs +
-			DEV_ADDR_TABLE_LOC(master->datstartaddr, data->index));
-	}
-	else  {  // DIMM
-		data->index = dw_i3c_master_get_group_hw_index(master, dev->addr);
-		master->addrs[data->index] = dev->addr;
-		i2c_dev_set_master_data(dev, data);
-	}
+	data->index = pos;
+	master->addrs[pos] = dev->addr;
+	master->free_pos &= ~BIT(pos);
+	i2c_dev_set_master_data(dev, data);
+
+	writel(DEV_ADDR_TABLE_LEGACY_I2C_DEV |
+	       DEV_ADDR_TABLE_STATIC_ADDR(dev->addr),
+	       master->regs +
+	       DEV_ADDR_TABLE_LOC(master->datstartaddr, data->index));

 	return 0;
 }
@@ -1496,17 +1066,13 @@ static void dw_i3c_master_detach_i2c_dev(struct i2c_dev_desc *dev)
 	struct i3c_master_controller *m = i2c_dev_get_master(dev);
 	struct dw_i3c_master *master = to_dw_i3c_master(m);

-	if (m->set_dasa)  // APML
-		writel(0,
-			master->regs +
-			DEV_ADDR_TABLE_LOC(master->datstartaddr, data->index));
-	else  // DIMM
-		dw_i3c_master_set_group_dat(master, dev->addr, 0);
+	writel(0,
+	       master->regs +
+	       DEV_ADDR_TABLE_LOC(master->datstartaddr, data->index));

 	i2c_dev_set_master_data(dev, NULL);
 	master->addrs[data->index] = 0;
-	if (m->set_dasa)  // APML
-		master->free_pos |= BIT(data->index);
+	master->free_pos |= BIT(data->index);
 	kfree(data);
 }

@@ -1550,37 +1116,27 @@ static int dw_i3c_probe(struct platform_device *pdev)
 {
 	struct dw_i3c_master *master;
 	int ret, irq;
-	u32 i3c_data, i3c_reg, i;

 	master = devm_kzalloc(&pdev->dev, sizeof(*master), GFP_KERNEL);
 	if (!master)
 		return -ENOMEM;

 	master->regs = devm_platform_ioremap_resource(pdev, 0);
-	if (IS_ERR(master->regs)) {
-		pr_err( "dw_i3c_probe: Error " "regs , dev %s, bus %d\n", dev_name(&pdev->dev), master->base.bus.id );
+	if (IS_ERR(master->regs))
 		return PTR_ERR(master->regs);
-    }

 	master->core_clk = devm_clk_get(&pdev->dev, NULL);
-	if (IS_ERR(master->core_clk)) {
-		pr_err( "dw_i3c_probe: Error " "core_clk , dev %s, bus %d\n", dev_name(&pdev->dev), master->base.bus.id );
+	if (IS_ERR(master->core_clk))
 		return PTR_ERR(master->core_clk);
-    }

 	master->core_rst = devm_reset_control_get_optional_exclusive(&pdev->dev,
 								    "core_rst");
-	if (IS_ERR(master->core_rst)) {
-		pr_err( "dw_i3c_probe: Error " "core_rst , dev %s, bus %d\n", dev_name(&pdev->dev), master->base.bus.id );
+	if (IS_ERR(master->core_rst))
 		return PTR_ERR(master->core_rst);
-    }

 	ret = clk_prepare_enable(master->core_clk);
-	if (ret) {
-		pr_err( "dw_i3c_probe: Error " "clk_prepare_enable dev %s, bus %d, ret %d\n",
-			 dev_name(&pdev->dev), master->base.bus.id, ret );
+	if (ret)
 		goto err_disable_core_clk;
-        }

 	reset_control_deassert(master->core_rst);

@@ -1592,11 +1148,8 @@ static int dw_i3c_probe(struct platform_device *pdev)
 	ret = devm_request_irq(&pdev->dev, irq,
 			       dw_i3c_master_irq_handler, 0,
 			       dev_name(&pdev->dev), master);
-	if (ret) {
-		pr_err( "dw_i3c_probe: Error " "devm_request_irq dev %s, bus %d, ret %d\n",
-			 dev_name(&pdev->dev), master->base.bus.id, ret );
+	if (ret)
 		goto err_assert_rst;
-	}

 	platform_set_drvdata(pdev, master);

@@ -1609,48 +1162,13 @@ static int dw_i3c_probe(struct platform_device *pdev)

 	ret = readl(master->regs + DEVICE_ADDR_TABLE_POINTER);
 	master->datstartaddr = ret;
-	/* Default value for maxdevs from the register is 0x8
-	 * Each SPD hub has 4 devices (EEPROM, PMIC, TS0 and TS1)
-	 * So, we need to set maxdevs to at least 24.
-	 */
-	//master->maxdevs = ret >> 16;
-	master->maxdevs = MAX_DEVS;
+	master->maxdevs = ret >> 16;
 	master->free_pos = GENMASK(master->maxdevs - 1, 0);
-	if(!(master->base.set_dasa))  // DIMM
-		dw_i3c_master_init_group_dat(master);
-#ifdef CCC_WORKAROUND
-	master->free_pos &= ~BIT(master->maxdevs - 1);
-	ret = (even_parity(I3C_BROADCAST_ADDR) << 7) | I3C_BROADCAST_ADDR;
-	master->addrs[master->maxdevs - 1] = ret;
-	writel(DEV_ADDR_TABLE_DYNAMIC_ADDR(ret),
-	       master->regs + DEV_ADDR_TABLE_LOC(master->datstartaddr, master->maxdevs - 1));
-#endif
-	master->dev = &pdev->dev;
+
 	ret = i3c_master_register(&master->base, &pdev->dev,
 				  &dw_mipi_i3c_ops, false);
-	if (ret) {
-		pr_err( "dw_i3c_probe: Error " "register dev %s, bus %d, ret %d\n",
-			 dev_name(&pdev->dev), master->base.bus.id, ret );
+	if (ret)
 		goto err_assert_rst;
-	}
-	pr_info( "dw_i3c_probe: Done " "Register dev %s, bus %d\n",
-                dev_name(&pdev->dev), master->base.bus.id );
-	// set HW Retry to 3 times for NAK
-	for(i=0; i<NUM_OF_I3C_DEVICES; i++) {
-		i3c_reg = DEV_ADDR_TABLE_LOC_OFFSET + i*4;
-		i3c_data = readl(master->regs + i3c_reg);
-		i3c_data = i3c_data | HW_RETRY_3_MASK ;
-		writel(i3c_data, master->regs + i3c_reg);
-	}
-	//set SDA TX Hold time
-	i3c_reg = SDA_DLY_TIMING_OFFSET;
-	i3c_data = readl(master->regs + i3c_reg);
-	i3c_data = i3c_data & SDA_TX_MASK;
-	if(master->base.set_dasa)  // APML
-		i3c_data = i3c_data | SDA_TX_HOLD_APML;
-	else  // DIMM
-		i3c_data = i3c_data | SDA_TX_HOLD_DIMM;
-	writel(i3c_data, master->regs + i3c_reg);

 	return 0;

diff --git a/drivers/i3c/master/i3c-master-cdns.c b/drivers/i3c/master/i3c-master-cdns.c
index 3f2226928fe0..5b37ffe5ad5b 100644
--- a/drivers/i3c/master/i3c-master-cdns.c
+++ b/drivers/i3c/master/i3c-master-cdns.c
@@ -1379,6 +1379,8 @@ static void cnds_i3c_master_demux_ibis(struct cdns_i3c_master *master)

 		case IBIR_TYPE_MR:
 			WARN_ON(IBIR_XFER_BYTES(ibir) || (ibir & IBIR_ERROR));
+			break;
+
 		default:
 			break;
 		}
diff --git a/drivers/i3c/master/mipi-i3c-hci/Makefile b/drivers/i3c/master/mipi-i3c-hci/Makefile
new file mode 100644
index 000000000000..a658e7b8262c
--- /dev/null
+++ b/drivers/i3c/master/mipi-i3c-hci/Makefile
@@ -0,0 +1,6 @@
+# SPDX-License-Identifier: BSD-3-Clause
+
+obj-$(CONFIG_MIPI_I3C_HCI)		+= mipi-i3c-hci.o
+mipi-i3c-hci-y				:= core.o ext_caps.o pio.o dma.o \
+					   cmd_v1.o cmd_v2.o \
+					   dat_v1.o dct_v1.o
diff --git a/drivers/i3c/master/mipi-i3c-hci/cmd.h b/drivers/i3c/master/mipi-i3c-hci/cmd.h
new file mode 100644
index 000000000000..1d6dd2c5d01a
--- /dev/null
+++ b/drivers/i3c/master/mipi-i3c-hci/cmd.h
@@ -0,0 +1,67 @@
+/* SPDX-License-Identifier: BSD-3-Clause */
+/*
+ * Copyright (c) 2020, MIPI Alliance, Inc.
+ *
+ * Author: Nicolas Pitre <npitre@baylibre.com>
+ *
+ * Common command/response related stuff
+ */
+
+#ifndef CMD_H
+#define CMD_H
+
+/*
+ * Those bits are common to all descriptor formats and
+ * may be manipulated by the core code.
+ */
+#define CMD_0_TOC			W0_BIT_(31)
+#define CMD_0_ROC			W0_BIT_(30)
+#define CMD_0_ATTR			W0_MASK(2, 0)
+
+/*
+ * Response Descriptor Structure
+ */
+#define RESP_STATUS(resp)		FIELD_GET(GENMASK(31, 28), resp)
+#define RESP_TID(resp)			FIELD_GET(GENMASK(27, 24), resp)
+#define RESP_DATA_LENGTH(resp)		FIELD_GET(GENMASK(21,  0), resp)
+
+#define RESP_ERR_FIELD			GENMASK(31, 28)
+
+enum hci_resp_err {
+	RESP_SUCCESS			= 0x0,
+	RESP_ERR_CRC			= 0x1,
+	RESP_ERR_PARITY			= 0x2,
+	RESP_ERR_FRAME			= 0x3,
+	RESP_ERR_ADDR_HEADER		= 0x4,
+	RESP_ERR_BCAST_NACK_7E		= 0x4,
+	RESP_ERR_NACK			= 0x5,
+	RESP_ERR_OVL			= 0x6,
+	RESP_ERR_I3C_SHORT_READ		= 0x7,
+	RESP_ERR_HC_TERMINATED		= 0x8,
+	RESP_ERR_I2C_WR_DATA_NACK	= 0x9,
+	RESP_ERR_BUS_XFER_ABORTED	= 0x9,
+	RESP_ERR_NOT_SUPPORTED		= 0xa,
+	RESP_ERR_ABORTED_WITH_CRC	= 0xb,
+	/* 0xc to 0xf are reserved for transfer specific errors */
+};
+
+/* TID generation (4 bits wide in all cases) */
+#define hci_get_tid(bits) \
+	(atomic_inc_return_relaxed(&hci->next_cmd_tid) % (1U << 4))
+
+/* This abstracts operations with our command descriptor formats */
+struct hci_cmd_ops {
+	int (*prep_ccc)(struct i3c_hci *hci, struct hci_xfer *xfer,
+			u8 ccc_addr, u8 ccc_cmd, bool raw);
+	void (*prep_i3c_xfer)(struct i3c_hci *hci, struct i3c_dev_desc *dev,
+			      struct hci_xfer *xfer);
+	void (*prep_i2c_xfer)(struct i3c_hci *hci, struct i2c_dev_desc *dev,
+			      struct hci_xfer *xfer);
+	int (*perform_daa)(struct i3c_hci *hci);
+};
+
+/* Our various instances */
+extern const struct hci_cmd_ops mipi_i3c_hci_cmd_v1;
+extern const struct hci_cmd_ops mipi_i3c_hci_cmd_v2;
+
+#endif
diff --git a/drivers/i3c/master/mipi-i3c-hci/cmd_v1.c b/drivers/i3c/master/mipi-i3c-hci/cmd_v1.c
new file mode 100644
index 000000000000..d97c3175e0e2
--- /dev/null
+++ b/drivers/i3c/master/mipi-i3c-hci/cmd_v1.c
@@ -0,0 +1,378 @@
+// SPDX-License-Identifier: BSD-3-Clause
+/*
+ * Copyright (c) 2020, MIPI Alliance, Inc.
+ *
+ * Author: Nicolas Pitre <npitre@baylibre.com>
+ *
+ * I3C HCI v1.0/v1.1 Command Descriptor Handling
+ */
+
+#include <linux/bitfield.h>
+#include <linux/i3c/master.h>
+
+#include "hci.h"
+#include "cmd.h"
+#include "dat.h"
+#include "dct.h"
+
+
+/*
+ * Address Assignment Command
+ */
+
+#define CMD_0_ATTR_A			FIELD_PREP(CMD_0_ATTR, 0x2)
+
+#define CMD_A0_TOC				   W0_BIT_(31)
+#define CMD_A0_ROC				   W0_BIT_(30)
+#define CMD_A0_DEV_COUNT(v)		FIELD_PREP(W0_MASK(29, 26), v)
+#define CMD_A0_DEV_INDEX(v)		FIELD_PREP(W0_MASK(20, 16), v)
+#define CMD_A0_CMD(v)			FIELD_PREP(W0_MASK(14,  7), v)
+#define CMD_A0_TID(v)			FIELD_PREP(W0_MASK( 6,  3), v)
+
+/*
+ * Immediate Data Transfer Command
+ */
+
+#define CMD_0_ATTR_I			FIELD_PREP(CMD_0_ATTR, 0x1)
+
+#define CMD_I1_DATA_BYTE_4(v)		FIELD_PREP(W1_MASK(63, 56), v)
+#define CMD_I1_DATA_BYTE_3(v)		FIELD_PREP(W1_MASK(55, 48), v)
+#define CMD_I1_DATA_BYTE_2(v)		FIELD_PREP(W1_MASK(47, 40), v)
+#define CMD_I1_DATA_BYTE_1(v)		FIELD_PREP(W1_MASK(39, 32), v)
+#define CMD_I1_DEF_BYTE(v)		FIELD_PREP(W1_MASK(39, 32), v)
+#define CMD_I0_TOC				   W0_BIT_(31)
+#define CMD_I0_ROC				   W0_BIT_(30)
+#define CMD_I0_RNW				   W0_BIT_(29)
+#define CMD_I0_MODE(v)			FIELD_PREP(W0_MASK(28, 26), v)
+#define CMD_I0_DTT(v)			FIELD_PREP(W0_MASK(25, 23), v)
+#define CMD_I0_DEV_INDEX(v)		FIELD_PREP(W0_MASK(20, 16), v)
+#define CMD_I0_CP				   W0_BIT_(15)
+#define CMD_I0_CMD(v)			FIELD_PREP(W0_MASK(14,  7), v)
+#define CMD_I0_TID(v)			FIELD_PREP(W0_MASK( 6,  3), v)
+
+/*
+ * Regular Data Transfer Command
+ */
+
+#define CMD_0_ATTR_R			FIELD_PREP(CMD_0_ATTR, 0x0)
+
+#define CMD_R1_DATA_LENGTH(v)		FIELD_PREP(W1_MASK(63, 48), v)
+#define CMD_R1_DEF_BYTE(v)		FIELD_PREP(W1_MASK(39, 32), v)
+#define CMD_R0_TOC				   W0_BIT_(31)
+#define CMD_R0_ROC				   W0_BIT_(30)
+#define CMD_R0_RNW				   W0_BIT_(29)
+#define CMD_R0_MODE(v)			FIELD_PREP(W0_MASK(28, 26), v)
+#define CMD_R0_DBP				   W0_BIT_(25)
+#define CMD_R0_DEV_INDEX(v)		FIELD_PREP(W0_MASK(20, 16), v)
+#define CMD_R0_CP				   W0_BIT_(15)
+#define CMD_R0_CMD(v)			FIELD_PREP(W0_MASK(14,  7), v)
+#define CMD_R0_TID(v)			FIELD_PREP(W0_MASK( 6,  3), v)
+
+/*
+ * Combo Transfer (Write + Write/Read) Command
+ */
+
+#define CMD_0_ATTR_C			FIELD_PREP(CMD_0_ATTR, 0x3)
+
+#define CMD_C1_DATA_LENGTH(v)		FIELD_PREP(W1_MASK(63, 48), v)
+#define CMD_C1_OFFSET(v)		FIELD_PREP(W1_MASK(47, 32), v)
+#define CMD_C0_TOC				   W0_BIT_(31)
+#define CMD_C0_ROC				   W0_BIT_(30)
+#define CMD_C0_RNW				   W0_BIT_(29)
+#define CMD_C0_MODE(v)			FIELD_PREP(W0_MASK(28, 26), v)
+#define CMD_C0_16_BIT_SUBOFFSET			   W0_BIT_(25)
+#define CMD_C0_FIRST_PHASE_MODE			   W0_BIT_(24)
+#define CMD_C0_DATA_LENGTH_POSITION(v)	FIELD_PREP(W0_MASK(23, 22), v)
+#define CMD_C0_DEV_INDEX(v)		FIELD_PREP(W0_MASK(20, 16), v)
+#define CMD_C0_CP				   W0_BIT_(15)
+#define CMD_C0_CMD(v)			FIELD_PREP(W0_MASK(14,  7), v)
+#define CMD_C0_TID(v)			FIELD_PREP(W0_MASK( 6,  3), v)
+
+/*
+ * Internal Control Command
+ */
+
+#define CMD_0_ATTR_M			FIELD_PREP(CMD_0_ATTR, 0x7)
+
+#define CMD_M1_VENDOR_SPECIFIC			   W1_MASK(63, 32)
+#define CMD_M0_MIPI_RESERVED			   W0_MASK(31, 12)
+#define CMD_M0_MIPI_CMD				   W0_MASK(11,  8)
+#define CMD_M0_VENDOR_INFO_PRESENT		   W0_BIT_( 7)
+#define CMD_M0_TID(v)			FIELD_PREP(W0_MASK( 6,  3), v)
+
+
+/* Data Transfer Speed and Mode */
+enum hci_cmd_mode {
+	MODE_I3C_SDR0		= 0x0,
+	MODE_I3C_SDR1		= 0x1,
+	MODE_I3C_SDR2		= 0x2,
+	MODE_I3C_SDR3		= 0x3,
+	MODE_I3C_SDR4		= 0x4,
+	MODE_I3C_HDR_TSx	= 0x5,
+	MODE_I3C_HDR_DDR	= 0x6,
+	MODE_I3C_HDR_BT		= 0x7,
+	MODE_I3C_Fm_FmP		= 0x8,
+	MODE_I2C_Fm		= 0x0,
+	MODE_I2C_FmP		= 0x1,
+	MODE_I2C_UD1		= 0x2,
+	MODE_I2C_UD2		= 0x3,
+	MODE_I2C_UD3		= 0x4,
+};
+
+static enum hci_cmd_mode get_i3c_mode(struct i3c_hci *hci)
+{
+	struct i3c_bus *bus = i3c_master_get_bus(&hci->master);
+
+	if (bus->scl_rate.i3c >= 12500000)
+		return MODE_I3C_SDR0;
+	if (bus->scl_rate.i3c > 8000000)
+		return MODE_I3C_SDR1;
+	if (bus->scl_rate.i3c > 6000000)
+		return MODE_I3C_SDR2;
+	if (bus->scl_rate.i3c > 4000000)
+		return MODE_I3C_SDR3;
+	if (bus->scl_rate.i3c > 2000000)
+		return MODE_I3C_SDR4;
+	return MODE_I3C_Fm_FmP;
+}
+
+static enum hci_cmd_mode get_i2c_mode(struct i3c_hci *hci)
+{
+	struct i3c_bus *bus = i3c_master_get_bus(&hci->master);
+
+	if (bus->scl_rate.i2c >= 1000000)
+		return MODE_I2C_FmP;
+	return MODE_I2C_Fm;
+}
+
+static void fill_data_bytes(struct hci_xfer *xfer, u8 *data,
+			    unsigned int data_len)
+{
+	xfer->cmd_desc[1] = 0;
+	switch (data_len) {
+	case 4:
+		xfer->cmd_desc[1] |= CMD_I1_DATA_BYTE_4(data[3]);
+		fallthrough;
+	case 3:
+		xfer->cmd_desc[1] |= CMD_I1_DATA_BYTE_3(data[2]);
+		fallthrough;
+	case 2:
+		xfer->cmd_desc[1] |= CMD_I1_DATA_BYTE_2(data[1]);
+		fallthrough;
+	case 1:
+		xfer->cmd_desc[1] |= CMD_I1_DATA_BYTE_1(data[0]);
+		fallthrough;
+	case 0:
+		break;
+	}
+	/* we consumed all the data with the cmd descriptor */
+	xfer->data = NULL;
+}
+
+static int hci_cmd_v1_prep_ccc(struct i3c_hci *hci,
+			       struct hci_xfer *xfer,
+			       u8 ccc_addr, u8 ccc_cmd, bool raw)
+{
+	unsigned int dat_idx = 0;
+	enum hci_cmd_mode mode = get_i3c_mode(hci);
+	u8 *data = xfer->data;
+	unsigned int data_len = xfer->data_len;
+	bool rnw = xfer->rnw;
+	int ret;
+
+	/* this should never happen */
+	if (WARN_ON(raw))
+		return -EINVAL;
+
+	if (ccc_addr != I3C_BROADCAST_ADDR) {
+		ret = mipi_i3c_hci_dat_v1.get_index(hci, ccc_addr);
+		if (ret < 0)
+			return ret;
+		dat_idx = ret;
+	}
+
+	xfer->cmd_tid = hci_get_tid();
+
+	if (!rnw && data_len <= 4) {
+		/* we use an Immediate Data Transfer Command */
+		xfer->cmd_desc[0] =
+			CMD_0_ATTR_I |
+			CMD_I0_TID(xfer->cmd_tid) |
+			CMD_I0_CMD(ccc_cmd) | CMD_I0_CP |
+			CMD_I0_DEV_INDEX(dat_idx) |
+			CMD_I0_DTT(data_len) |
+			CMD_I0_MODE(mode);
+		fill_data_bytes(xfer, data, data_len);
+	} else {
+		/* we use a Regular Data Transfer Command */
+		xfer->cmd_desc[0] =
+			CMD_0_ATTR_R |
+			CMD_R0_TID(xfer->cmd_tid) |
+			CMD_R0_CMD(ccc_cmd) | CMD_R0_CP |
+			CMD_R0_DEV_INDEX(dat_idx) |
+			CMD_R0_MODE(mode) |
+			(rnw ? CMD_R0_RNW : 0);
+		xfer->cmd_desc[1] =
+			CMD_R1_DATA_LENGTH(data_len);
+	}
+
+	return 0;
+}
+
+static void hci_cmd_v1_prep_i3c_xfer(struct i3c_hci *hci,
+				     struct i3c_dev_desc *dev,
+				     struct hci_xfer *xfer)
+{
+	struct i3c_hci_dev_data *dev_data = i3c_dev_get_master_data(dev);
+	unsigned int dat_idx = dev_data->dat_idx;
+	enum hci_cmd_mode mode = get_i3c_mode(hci);
+	u8 *data = xfer->data;
+	unsigned int data_len = xfer->data_len;
+	bool rnw = xfer->rnw;
+
+	xfer->cmd_tid = hci_get_tid();
+
+	if (!rnw && data_len <= 4) {
+		/* we use an Immediate Data Transfer Command */
+		xfer->cmd_desc[0] =
+			CMD_0_ATTR_I |
+			CMD_I0_TID(xfer->cmd_tid) |
+			CMD_I0_DEV_INDEX(dat_idx) |
+			CMD_I0_DTT(data_len) |
+			CMD_I0_MODE(mode);
+		fill_data_bytes(xfer, data, data_len);
+	} else {
+		/* we use a Regular Data Transfer Command */
+		xfer->cmd_desc[0] =
+			CMD_0_ATTR_R |
+			CMD_R0_TID(xfer->cmd_tid) |
+			CMD_R0_DEV_INDEX(dat_idx) |
+			CMD_R0_MODE(mode) |
+			(rnw ? CMD_R0_RNW : 0);
+		xfer->cmd_desc[1] =
+			CMD_R1_DATA_LENGTH(data_len);
+	}
+}
+
+static void hci_cmd_v1_prep_i2c_xfer(struct i3c_hci *hci,
+				     struct i2c_dev_desc *dev,
+				     struct hci_xfer *xfer)
+{
+	struct i3c_hci_dev_data *dev_data = i2c_dev_get_master_data(dev);
+	unsigned int dat_idx = dev_data->dat_idx;
+	enum hci_cmd_mode mode = get_i2c_mode(hci);
+	u8 *data = xfer->data;
+	unsigned int data_len = xfer->data_len;
+	bool rnw = xfer->rnw;
+
+	xfer->cmd_tid = hci_get_tid();
+
+	if (!rnw && data_len <= 4) {
+		/* we use an Immediate Data Transfer Command */
+		xfer->cmd_desc[0] =
+			CMD_0_ATTR_I |
+			CMD_I0_TID(xfer->cmd_tid) |
+			CMD_I0_DEV_INDEX(dat_idx) |
+			CMD_I0_DTT(data_len) |
+			CMD_I0_MODE(mode);
+		fill_data_bytes(xfer, data, data_len);
+	} else {
+		/* we use a Regular Data Transfer Command */
+		xfer->cmd_desc[0] =
+			CMD_0_ATTR_R |
+			CMD_R0_TID(xfer->cmd_tid) |
+			CMD_R0_DEV_INDEX(dat_idx) |
+			CMD_R0_MODE(mode) |
+			(rnw ? CMD_R0_RNW : 0);
+		xfer->cmd_desc[1] =
+			CMD_R1_DATA_LENGTH(data_len);
+	}
+}
+
+static int hci_cmd_v1_daa(struct i3c_hci *hci)
+{
+	struct hci_xfer *xfer;
+	int ret, dat_idx = -1;
+	u8 next_addr = 0;
+	u64 pid;
+	unsigned int dcr, bcr;
+	DECLARE_COMPLETION_ONSTACK(done);
+
+	xfer = hci_alloc_xfer(2);
+	if (!xfer)
+		return -ENOMEM;
+
+	/*
+	 * Simple for now: we allocate a temporary DAT entry, do a single
+	 * DAA, register the device which will allocate its own DAT entry
+	 * via the core callback, then free the temporary DAT entry.
+	 * Loop until there is no more devices to assign an address to.
+	 * Yes, there is room for improvements.
+	 */
+	for (;;) {
+		ret = mipi_i3c_hci_dat_v1.alloc_entry(hci);
+		if (ret < 0)
+			break;
+		dat_idx = ret;
+		ret = i3c_master_get_free_addr(&hci->master, next_addr);
+		if (ret < 0)
+			break;
+		next_addr = ret;
+
+		DBG("next_addr = 0x%02x, DAA using DAT %d", next_addr, dat_idx);
+		mipi_i3c_hci_dat_v1.set_dynamic_addr(hci, dat_idx, next_addr);
+		mipi_i3c_hci_dct_index_reset(hci);
+
+		xfer->cmd_tid = hci_get_tid();
+		xfer->cmd_desc[0] =
+			CMD_0_ATTR_A |
+			CMD_A0_TID(xfer->cmd_tid) |
+			CMD_A0_CMD(I3C_CCC_ENTDAA) |
+			CMD_A0_DEV_INDEX(dat_idx) |
+			CMD_A0_DEV_COUNT(1) |
+			CMD_A0_ROC | CMD_A0_TOC;
+		xfer->cmd_desc[1] = 0;
+		hci->io->queue_xfer(hci, xfer, 1);
+		if (!wait_for_completion_timeout(&done, HZ) &&
+		    hci->io->dequeue_xfer(hci, xfer, 1)) {
+			ret = -ETIME;
+			break;
+		}
+		if (RESP_STATUS(xfer[0].response) == RESP_ERR_NACK &&
+		    RESP_STATUS(xfer[0].response) == 1) {
+			ret = 0;  /* no more devices to be assigned */
+			break;
+		}
+		if (RESP_STATUS(xfer[0].response) != RESP_SUCCESS) {
+			ret = -EIO;
+			break;
+		}
+
+		i3c_hci_dct_get_val(hci, 0, &pid, &dcr, &bcr);
+		DBG("assigned address %#x to device PID=0x%llx DCR=%#x BCR=%#x",
+		    next_addr, pid, dcr, bcr);
+
+		mipi_i3c_hci_dat_v1.free_entry(hci, dat_idx);
+		dat_idx = -1;
+
+		/*
+		 * TODO: Extend the subsystem layer to allow for registering
+		 * new device and provide BCR/DCR/PID at the same time.
+		 */
+		ret = i3c_master_add_i3c_dev_locked(&hci->master, next_addr);
+		if (ret)
+			break;
+	}
+
+	if (dat_idx >= 0)
+		mipi_i3c_hci_dat_v1.free_entry(hci, dat_idx);
+	hci_free_xfer(xfer, 1);
+	return ret;
+}
+
+const struct hci_cmd_ops mipi_i3c_hci_cmd_v1 = {
+	.prep_ccc		= hci_cmd_v1_prep_ccc,
+	.prep_i3c_xfer		= hci_cmd_v1_prep_i3c_xfer,
+	.prep_i2c_xfer		= hci_cmd_v1_prep_i2c_xfer,
+	.perform_daa		= hci_cmd_v1_daa,
+};
diff --git a/drivers/i3c/master/mipi-i3c-hci/cmd_v2.c b/drivers/i3c/master/mipi-i3c-hci/cmd_v2.c
new file mode 100644
index 000000000000..4493b2b067cb
--- /dev/null
+++ b/drivers/i3c/master/mipi-i3c-hci/cmd_v2.c
@@ -0,0 +1,316 @@
+// SPDX-License-Identifier: BSD-3-Clause
+/*
+ * Copyright (c) 2020, MIPI Alliance, Inc.
+ *
+ * Author: Nicolas Pitre <npitre@baylibre.com>
+ *
+ * I3C HCI v2.0 Command Descriptor Handling
+ *
+ * Note: The I3C HCI v2.0 spec is still in flux. The code here will change.
+ */
+
+#include <linux/bitfield.h>
+#include <linux/i3c/master.h>
+
+#include "hci.h"
+#include "cmd.h"
+#include "xfer_mode_rate.h"
+
+
+/*
+ * Unified Data Transfer Command
+ */
+
+#define CMD_0_ATTR_U			FIELD_PREP(CMD_0_ATTR, 0x4)
+
+#define CMD_U3_HDR_TSP_ML_CTRL(v)	FIELD_PREP(W3_MASK(107, 104), v)
+#define CMD_U3_IDB4(v)			FIELD_PREP(W3_MASK(103,  96), v)
+#define CMD_U3_HDR_CMD(v)		FIELD_PREP(W3_MASK(103,  96), v)
+#define CMD_U2_IDB3(v)			FIELD_PREP(W2_MASK( 95,  88), v)
+#define CMD_U2_HDR_BT(v)		FIELD_PREP(W2_MASK( 95,  88), v)
+#define CMD_U2_IDB2(v)			FIELD_PREP(W2_MASK( 87,  80), v)
+#define CMD_U2_BT_CMD2(v)		FIELD_PREP(W2_MASK( 87,  80), v)
+#define CMD_U2_IDB1(v)			FIELD_PREP(W2_MASK( 79,  72), v)
+#define CMD_U2_BT_CMD1(v)		FIELD_PREP(W2_MASK( 79,  72), v)
+#define CMD_U2_IDB0(v)			FIELD_PREP(W2_MASK( 71,  64), v)
+#define CMD_U2_BT_CMD0(v)		FIELD_PREP(W2_MASK( 71,  64), v)
+#define CMD_U1_ERR_HANDLING(v)		FIELD_PREP(W1_MASK( 63,  62), v)
+#define CMD_U1_ADD_FUNC(v)		FIELD_PREP(W1_MASK( 61,  56), v)
+#define CMD_U1_COMBO_XFER			   W1_BIT_( 55)
+#define CMD_U1_DATA_LENGTH(v)		FIELD_PREP(W1_MASK( 53,  32), v)
+#define CMD_U0_TOC				   W0_BIT_( 31)
+#define CMD_U0_ROC				   W0_BIT_( 30)
+#define CMD_U0_MAY_YIELD			   W0_BIT_( 29)
+#define CMD_U0_NACK_RCNT(v)		FIELD_PREP(W0_MASK( 28,  27), v)
+#define CMD_U0_IDB_COUNT(v)		FIELD_PREP(W0_MASK( 26,  24), v)
+#define CMD_U0_MODE_INDEX(v)		FIELD_PREP(W0_MASK( 22,  18), v)
+#define CMD_U0_XFER_RATE(v)		FIELD_PREP(W0_MASK( 17,  15), v)
+#define CMD_U0_DEV_ADDRESS(v)		FIELD_PREP(W0_MASK( 14,   8), v)
+#define CMD_U0_RnW				   W0_BIT_(  7)
+#define CMD_U0_TID(v)			FIELD_PREP(W0_MASK(  6,   3), v)
+
+/*
+ * Address Assignment Command
+ */
+
+#define CMD_0_ATTR_A			FIELD_PREP(CMD_0_ATTR, 0x2)
+
+#define CMD_A1_DATA_LENGTH(v)		FIELD_PREP(W1_MASK( 53,  32), v)
+#define CMD_A0_TOC				   W0_BIT_( 31)
+#define CMD_A0_ROC				   W0_BIT_( 30)
+#define CMD_A0_XFER_RATE(v)		FIELD_PREP(W0_MASK( 17,  15), v)
+#define CMD_A0_ASSIGN_ADDRESS(v)	FIELD_PREP(W0_MASK( 14,   8), v)
+#define CMD_A0_TID(v)			FIELD_PREP(W0_MASK(  6,   3), v)
+
+
+static unsigned int get_i3c_rate_idx(struct i3c_hci *hci)
+{
+	struct i3c_bus *bus = i3c_master_get_bus(&hci->master);
+
+	if (bus->scl_rate.i3c >= 12000000)
+		return XFERRATE_I3C_SDR0;
+	if (bus->scl_rate.i3c > 8000000)
+		return XFERRATE_I3C_SDR1;
+	if (bus->scl_rate.i3c > 6000000)
+		return XFERRATE_I3C_SDR2;
+	if (bus->scl_rate.i3c > 4000000)
+		return XFERRATE_I3C_SDR3;
+	if (bus->scl_rate.i3c > 2000000)
+		return XFERRATE_I3C_SDR4;
+	return XFERRATE_I3C_SDR_FM_FMP;
+}
+
+static unsigned int get_i2c_rate_idx(struct i3c_hci *hci)
+{
+	struct i3c_bus *bus = i3c_master_get_bus(&hci->master);
+
+	if (bus->scl_rate.i2c >= 1000000)
+		return XFERRATE_I2C_FMP;
+	return XFERRATE_I2C_FM;
+}
+
+static void hci_cmd_v2_prep_private_xfer(struct i3c_hci *hci,
+					 struct hci_xfer *xfer,
+					 u8 addr, unsigned int mode,
+					 unsigned int rate)
+{
+	u8 *data = xfer->data;
+	unsigned int data_len = xfer->data_len;
+	bool rnw = xfer->rnw;
+
+	xfer->cmd_tid = hci_get_tid();
+
+	if (!rnw && data_len <= 5) {
+		xfer->cmd_desc[0] =
+			CMD_0_ATTR_U |
+			CMD_U0_TID(xfer->cmd_tid) |
+			CMD_U0_DEV_ADDRESS(addr) |
+			CMD_U0_XFER_RATE(rate) |
+			CMD_U0_MODE_INDEX(mode) |
+			CMD_U0_IDB_COUNT(data_len);
+		xfer->cmd_desc[1] =
+			CMD_U1_DATA_LENGTH(0);
+		xfer->cmd_desc[2] = 0;
+		xfer->cmd_desc[3] = 0;
+		switch (data_len) {
+		case 5:
+			xfer->cmd_desc[3] |= CMD_U3_IDB4(data[4]);
+			fallthrough;
+		case 4:
+			xfer->cmd_desc[2] |= CMD_U2_IDB3(data[3]);
+			fallthrough;
+		case 3:
+			xfer->cmd_desc[2] |= CMD_U2_IDB2(data[2]);
+			fallthrough;
+		case 2:
+			xfer->cmd_desc[2] |= CMD_U2_IDB1(data[1]);
+			fallthrough;
+		case 1:
+			xfer->cmd_desc[2] |= CMD_U2_IDB0(data[0]);
+			fallthrough;
+		case 0:
+			break;
+		}
+		/* we consumed all the data with the cmd descriptor */
+		xfer->data = NULL;
+	} else {
+		xfer->cmd_desc[0] =
+			CMD_0_ATTR_U |
+			CMD_U0_TID(xfer->cmd_tid) |
+			(rnw ? CMD_U0_RnW : 0) |
+			CMD_U0_DEV_ADDRESS(addr) |
+			CMD_U0_XFER_RATE(rate) |
+			CMD_U0_MODE_INDEX(mode);
+		xfer->cmd_desc[1] =
+			CMD_U1_DATA_LENGTH(data_len);
+		xfer->cmd_desc[2] = 0;
+		xfer->cmd_desc[3] = 0;
+	}
+}
+
+static int hci_cmd_v2_prep_ccc(struct i3c_hci *hci, struct hci_xfer *xfer,
+			       u8 ccc_addr, u8 ccc_cmd, bool raw)
+{
+	unsigned int mode = XFERMODE_IDX_I3C_SDR;
+	unsigned int rate = get_i3c_rate_idx(hci);
+	u8 *data = xfer->data;
+	unsigned int data_len = xfer->data_len;
+	bool rnw = xfer->rnw;
+
+	if (raw && ccc_addr != I3C_BROADCAST_ADDR) {
+		hci_cmd_v2_prep_private_xfer(hci, xfer, ccc_addr, mode, rate);
+		return 0;
+	}
+
+	xfer->cmd_tid = hci_get_tid();
+
+	if (!rnw && data_len <= 4) {
+		xfer->cmd_desc[0] =
+			CMD_0_ATTR_U |
+			CMD_U0_TID(xfer->cmd_tid) |
+			CMD_U0_DEV_ADDRESS(ccc_addr) |
+			CMD_U0_XFER_RATE(rate) |
+			CMD_U0_MODE_INDEX(mode) |
+			CMD_U0_IDB_COUNT(data_len + (!raw ? 0 : 1));
+		xfer->cmd_desc[1] =
+			CMD_U1_DATA_LENGTH(0);
+		xfer->cmd_desc[2] =
+			CMD_U2_IDB0(ccc_cmd);
+		xfer->cmd_desc[3] = 0;
+		switch (data_len) {
+		case 4:
+			xfer->cmd_desc[3] |= CMD_U3_IDB4(data[3]);
+			fallthrough;
+		case 3:
+			xfer->cmd_desc[2] |= CMD_U2_IDB3(data[2]);
+			fallthrough;
+		case 2:
+			xfer->cmd_desc[2] |= CMD_U2_IDB2(data[1]);
+			fallthrough;
+		case 1:
+			xfer->cmd_desc[2] |= CMD_U2_IDB1(data[0]);
+			fallthrough;
+		case 0:
+			break;
+		}
+		/* we consumed all the data with the cmd descriptor */
+		xfer->data = NULL;
+	} else {
+		xfer->cmd_desc[0] =
+			CMD_0_ATTR_U |
+			CMD_U0_TID(xfer->cmd_tid) |
+			(rnw ? CMD_U0_RnW : 0) |
+			CMD_U0_DEV_ADDRESS(ccc_addr) |
+			CMD_U0_XFER_RATE(rate) |
+			CMD_U0_MODE_INDEX(mode) |
+			CMD_U0_IDB_COUNT(!raw ? 0 : 1);
+		xfer->cmd_desc[1] =
+			CMD_U1_DATA_LENGTH(data_len);
+		xfer->cmd_desc[2] =
+			CMD_U2_IDB0(ccc_cmd);
+		xfer->cmd_desc[3] = 0;
+	}
+
+	return 0;
+}
+
+static void hci_cmd_v2_prep_i3c_xfer(struct i3c_hci *hci,
+				     struct i3c_dev_desc *dev,
+				     struct hci_xfer *xfer)
+{
+	unsigned int mode = XFERMODE_IDX_I3C_SDR;
+	unsigned int rate = get_i3c_rate_idx(hci);
+	u8 addr = dev->info.dyn_addr;
+
+	hci_cmd_v2_prep_private_xfer(hci, xfer, addr, mode, rate);
+}
+
+static void hci_cmd_v2_prep_i2c_xfer(struct i3c_hci *hci,
+				     struct i2c_dev_desc *dev,
+				     struct hci_xfer *xfer)
+{
+	unsigned int mode = XFERMODE_IDX_I2C;
+	unsigned int rate = get_i2c_rate_idx(hci);
+	u8 addr = dev->addr;
+
+	hci_cmd_v2_prep_private_xfer(hci, xfer, addr, mode, rate);
+}
+
+static int hci_cmd_v2_daa(struct i3c_hci *hci)
+{
+	struct hci_xfer *xfer;
+	int ret;
+	u8 next_addr = 0;
+	u32 device_id[2];
+	u64 pid;
+	unsigned int dcr, bcr;
+	DECLARE_COMPLETION_ONSTACK(done);
+
+	xfer = hci_alloc_xfer(2);
+	if (!xfer)
+		return -ENOMEM;
+
+	xfer[0].data = &device_id;
+	xfer[0].data_len = 8;
+	xfer[0].rnw = true;
+	xfer[0].cmd_desc[1] = CMD_A1_DATA_LENGTH(8);
+	xfer[1].completion = &done;
+
+	for (;;) {
+		ret = i3c_master_get_free_addr(&hci->master, next_addr);
+		if (ret < 0)
+			break;
+		next_addr = ret;
+		DBG("next_addr = 0x%02x", next_addr);
+		xfer[0].cmd_tid = hci_get_tid();
+		xfer[0].cmd_desc[0] =
+			CMD_0_ATTR_A |
+			CMD_A0_TID(xfer[0].cmd_tid) |
+			CMD_A0_ROC;
+		xfer[1].cmd_tid = hci_get_tid();
+		xfer[1].cmd_desc[0] =
+			CMD_0_ATTR_A |
+			CMD_A0_TID(xfer[1].cmd_tid) |
+			CMD_A0_ASSIGN_ADDRESS(next_addr) |
+			CMD_A0_ROC |
+			CMD_A0_TOC;
+		hci->io->queue_xfer(hci, xfer, 2);
+		if (!wait_for_completion_timeout(&done, HZ) &&
+		    hci->io->dequeue_xfer(hci, xfer, 2)) {
+			ret = -ETIME;
+			break;
+		}
+		if (RESP_STATUS(xfer[0].response) != RESP_SUCCESS) {
+			ret = 0;  /* no more devices to be assigned */
+			break;
+		}
+		if (RESP_STATUS(xfer[1].response) != RESP_SUCCESS) {
+			ret = -EIO;
+			break;
+		}
+
+		pid = FIELD_GET(W1_MASK(47, 32), device_id[1]);
+		pid = (pid << 32) | device_id[0];
+		bcr = FIELD_GET(W1_MASK(55, 48), device_id[1]);
+		dcr = FIELD_GET(W1_MASK(63, 56), device_id[1]);
+		DBG("assigned address %#x to device PID=0x%llx DCR=%#x BCR=%#x",
+		    next_addr, pid, dcr, bcr);
+		/*
+		 * TODO: Extend the subsystem layer to allow for registering
+		 * new device and provide BCR/DCR/PID at the same time.
+		 */
+		ret = i3c_master_add_i3c_dev_locked(&hci->master, next_addr);
+		if (ret)
+			break;
+	}
+
+	hci_free_xfer(xfer, 2);
+	return ret;
+}
+
+const struct hci_cmd_ops mipi_i3c_hci_cmd_v2 = {
+	.prep_ccc		= hci_cmd_v2_prep_ccc,
+	.prep_i3c_xfer		= hci_cmd_v2_prep_i3c_xfer,
+	.prep_i2c_xfer		= hci_cmd_v2_prep_i2c_xfer,
+	.perform_daa		= hci_cmd_v2_daa,
+};
diff --git a/drivers/i3c/master/mipi-i3c-hci/core.c b/drivers/i3c/master/mipi-i3c-hci/core.c
new file mode 100644
index 000000000000..6aef5ce43cc1
--- /dev/null
+++ b/drivers/i3c/master/mipi-i3c-hci/core.c
@@ -0,0 +1,793 @@
+// SPDX-License-Identifier: BSD-3-Clause
+/*
+ * Copyright (c) 2020, MIPI Alliance, Inc.
+ *
+ * Author: Nicolas Pitre <npitre@baylibre.com>
+ *
+ * Core driver code with main interface to the I3C subsystem.
+ */
+
+#include <linux/bitfield.h>
+#include <linux/device.h>
+#include <linux/errno.h>
+#include <linux/i3c/master.h>
+#include <linux/interrupt.h>
+#include <linux/io.h>
+#include <linux/iopoll.h>
+#include <linux/module.h>
+#include <linux/platform_device.h>
+
+#include "hci.h"
+#include "ext_caps.h"
+#include "cmd.h"
+#include "dat.h"
+
+
+/*
+ * Host Controller Capabilities and Operation Registers
+ */
+
+#define reg_read(r)		readl(hci->base_regs + (r))
+#define reg_write(r, v)		writel(v, hci->base_regs + (r))
+#define reg_set(r, v)		reg_write(r, reg_read(r) | (v))
+#define reg_clear(r, v)		reg_write(r, reg_read(r) & ~(v))
+
+#define HCI_VERSION			0x00	/* HCI Version (in BCD) */
+
+#define HC_CONTROL			0x04
+#define HC_CONTROL_BUS_ENABLE		BIT(31)
+#define HC_CONTROL_RESUME		BIT(30)
+#define HC_CONTROL_ABORT		BIT(29)
+#define HC_CONTROL_HALT_ON_CMD_TIMEOUT	BIT(12)
+#define HC_CONTROL_HOT_JOIN_CTRL	BIT(8)	/* Hot-Join ACK/NACK Control */
+#define HC_CONTROL_I2C_TARGET_PRESENT	BIT(7)
+#define HC_CONTROL_PIO_MODE		BIT(6)	/* DMA/PIO Mode Selector */
+#define HC_CONTROL_DATA_BIG_ENDIAN	BIT(4)
+#define HC_CONTROL_IBA_INCLUDE		BIT(0)	/* Include I3C Broadcast Address */
+
+#define MASTER_DEVICE_ADDR		0x08	/* Master Device Address */
+#define MASTER_DYNAMIC_ADDR_VALID	BIT(31)	/* Dynamic Address is Valid */
+#define MASTER_DYNAMIC_ADDR(v)		FIELD_PREP(GENMASK(22, 16), v)
+
+#define HC_CAPABILITIES			0x0c
+#define HC_CAP_SG_DC_EN			BIT(30)
+#define HC_CAP_SG_IBI_EN		BIT(29)
+#define HC_CAP_SG_CR_EN			BIT(28)
+#define HC_CAP_MAX_DATA_LENGTH		GENMASK(24, 22)
+#define HC_CAP_CMD_SIZE			GENMASK(21, 20)
+#define HC_CAP_DIRECT_COMMANDS_EN	BIT(18)
+#define HC_CAP_MULTI_LANE_EN		BIT(15)
+#define HC_CAP_CMD_CCC_DEFBYTE		BIT(10)
+#define HC_CAP_HDR_BT_EN		BIT(8)
+#define HC_CAP_HDR_TS_EN		BIT(7)
+#define HC_CAP_HDR_DDR_EN		BIT(6)
+#define HC_CAP_NON_CURRENT_MASTER_CAP	BIT(5)	/* master handoff capable */
+#define HC_CAP_DATA_BYTE_CFG_EN		BIT(4)	/* endian selection possible */
+#define HC_CAP_AUTO_COMMAND		BIT(3)
+#define HC_CAP_COMBO_COMMAND		BIT(2)
+
+#define RESET_CONTROL			0x10
+#define BUS_RESET			BIT(31)
+#define BUS_RESET_TYPE			GENMASK(30, 29)
+#define IBI_QUEUE_RST			BIT(5)
+#define RX_FIFO_RST			BIT(4)
+#define TX_FIFO_RST			BIT(3)
+#define RESP_QUEUE_RST			BIT(2)
+#define CMD_QUEUE_RST			BIT(1)
+#define SOFT_RST			BIT(0)	/* Core Reset */
+
+#define PRESENT_STATE			0x14
+#define STATE_CURRENT_MASTER		BIT(2)
+
+#define INTR_STATUS			0x20
+#define INTR_STATUS_ENABLE		0x24
+#define INTR_SIGNAL_ENABLE		0x28
+#define INTR_FORCE			0x2c
+#define INTR_HC_CMD_SEQ_UFLOW_STAT	BIT(12)	/* Cmd Sequence Underflow */
+#define INTR_HC_RESET_CANCEL		BIT(11)	/* HC Cancelled Reset */
+#define INTR_HC_INTERNAL_ERR		BIT(10)	/* HC Internal Error */
+#define INTR_HC_PIO			BIT(8)	/* cascaded PIO interrupt */
+#define INTR_HC_RINGS			GENMASK(7, 0)
+
+#define DAT_SECTION			0x30	/* Device Address Table */
+#define DAT_ENTRY_SIZE			GENMASK(31, 28)
+#define DAT_TABLE_SIZE			GENMASK(18, 12)
+#define DAT_TABLE_OFFSET		GENMASK(11, 0)
+
+#define DCT_SECTION			0x34	/* Device Characteristics Table */
+#define DCT_ENTRY_SIZE			GENMASK(31, 28)
+#define DCT_TABLE_INDEX			GENMASK(23, 19)
+#define DCT_TABLE_SIZE			GENMASK(18, 12)
+#define DCT_TABLE_OFFSET		GENMASK(11, 0)
+
+#define RING_HEADERS_SECTION		0x38
+#define RING_HEADERS_OFFSET		GENMASK(15, 0)
+
+#define PIO_SECTION			0x3c
+#define PIO_REGS_OFFSET			GENMASK(15, 0)	/* PIO Offset */
+
+#define EXT_CAPS_SECTION		0x40
+#define EXT_CAPS_OFFSET			GENMASK(15, 0)
+
+#define IBI_NOTIFY_CTRL			0x58	/* IBI Notify Control */
+#define IBI_NOTIFY_SIR_REJECTED		BIT(3)	/* Rejected Target Interrupt Request */
+#define IBI_NOTIFY_MR_REJECTED		BIT(1)	/* Rejected Master Request Control */
+#define IBI_NOTIFY_HJ_REJECTED		BIT(0)	/* Rejected Hot-Join Control */
+
+#define DEV_CTX_BASE_LO			0x60
+#define DEV_CTX_BASE_HI			0x64
+
+
+static inline struct i3c_hci *to_i3c_hci(struct i3c_master_controller *m)
+{
+	return container_of(m, struct i3c_hci, master);
+}
+
+static int i3c_hci_bus_init(struct i3c_master_controller *m)
+{
+	struct i3c_hci *hci = to_i3c_hci(m);
+	struct i3c_device_info info;
+	int ret;
+
+	DBG("");
+
+	if (hci->cmd == &mipi_i3c_hci_cmd_v1) {
+		ret = mipi_i3c_hci_dat_v1.init(hci);
+		if (ret)
+			return ret;
+	}
+
+	ret = i3c_master_get_free_addr(m, 0);
+	if (ret < 0)
+		return ret;
+	reg_write(MASTER_DEVICE_ADDR,
+		  MASTER_DYNAMIC_ADDR(ret) | MASTER_DYNAMIC_ADDR_VALID);
+	memset(&info, 0, sizeof(info));
+	info.dyn_addr = ret;
+	ret = i3c_master_set_info(m, &info);
+	if (ret)
+		return ret;
+
+	ret = hci->io->init(hci);
+	if (ret)
+		return ret;
+
+	reg_set(HC_CONTROL, HC_CONTROL_BUS_ENABLE);
+	DBG("HC_CONTROL = %#x", reg_read(HC_CONTROL));
+
+	return 0;
+}
+
+static void i3c_hci_bus_cleanup(struct i3c_master_controller *m)
+{
+	struct i3c_hci *hci = to_i3c_hci(m);
+
+	DBG("");
+
+	reg_clear(HC_CONTROL, HC_CONTROL_BUS_ENABLE);
+	hci->io->cleanup(hci);
+	if (hci->cmd == &mipi_i3c_hci_cmd_v1)
+		mipi_i3c_hci_dat_v1.cleanup(hci);
+}
+
+void mipi_i3c_hci_resume(struct i3c_hci *hci)
+{
+	/* the HC_CONTROL_RESUME bit is R/W1C so just read and write back */
+	reg_write(HC_CONTROL, reg_read(HC_CONTROL));
+}
+
+/* located here rather than pio.c because needed bits are in core reg space */
+void mipi_i3c_hci_pio_reset(struct i3c_hci *hci)
+{
+	reg_write(RESET_CONTROL, RX_FIFO_RST | TX_FIFO_RST | RESP_QUEUE_RST);
+}
+
+/* located here rather than dct.c because needed bits are in core reg space */
+void mipi_i3c_hci_dct_index_reset(struct i3c_hci *hci)
+{
+	reg_write(DCT_SECTION, FIELD_PREP(DCT_TABLE_INDEX, 0));
+}
+
+static int i3c_hci_send_ccc_cmd(struct i3c_master_controller *m,
+				struct i3c_ccc_cmd *ccc)
+{
+	struct i3c_hci *hci = to_i3c_hci(m);
+	struct hci_xfer *xfer;
+	bool raw = !!(hci->quirks & HCI_QUIRK_RAW_CCC);
+	bool prefixed = raw && !!(ccc->id & I3C_CCC_DIRECT);
+	unsigned int nxfers = ccc->ndests + prefixed;
+	DECLARE_COMPLETION_ONSTACK(done);
+	int i, last, ret = 0;
+
+	DBG("cmd=%#x rnw=%d ndests=%d data[0].len=%d",
+	    ccc->id, ccc->rnw, ccc->ndests, ccc->dests[0].payload.len);
+
+	xfer = hci_alloc_xfer(nxfers);
+	if (!xfer)
+		return -ENOMEM;
+
+	if (prefixed) {
+		xfer->data = NULL;
+		xfer->data_len = 0;
+		xfer->rnw = false;
+		hci->cmd->prep_ccc(hci, xfer, I3C_BROADCAST_ADDR,
+				   ccc->id, true);
+		xfer++;
+	}
+
+	for (i = 0; i < nxfers - prefixed; i++) {
+		xfer[i].data = ccc->dests[i].payload.data;
+		xfer[i].data_len = ccc->dests[i].payload.len;
+		xfer[i].rnw = ccc->rnw;
+		ret = hci->cmd->prep_ccc(hci, &xfer[i], ccc->dests[i].addr,
+					 ccc->id, raw);
+		if (ret)
+			goto out;
+		xfer[i].cmd_desc[0] |= CMD_0_ROC;
+	}
+	last = i - 1;
+	xfer[last].cmd_desc[0] |= CMD_0_TOC;
+	xfer[last].completion = &done;
+
+	if (prefixed)
+		xfer--;
+
+	ret = hci->io->queue_xfer(hci, xfer, nxfers);
+	if (ret)
+		goto out;
+	if (!wait_for_completion_timeout(&done, HZ) &&
+	    hci->io->dequeue_xfer(hci, xfer, nxfers)) {
+		ret = -ETIME;
+		goto out;
+	}
+	for (i = prefixed; i < nxfers; i++) {
+		if (ccc->rnw)
+			ccc->dests[i - prefixed].payload.len =
+				RESP_DATA_LENGTH(xfer[i].response);
+		if (RESP_STATUS(xfer[i].response) != RESP_SUCCESS) {
+			ret = -EIO;
+			goto out;
+		}
+	}
+
+	if (ccc->rnw)
+		DBG("got: %*ph",
+		    ccc->dests[0].payload.len, ccc->dests[0].payload.data);
+
+out:
+	hci_free_xfer(xfer, nxfers);
+	return ret;
+}
+
+static int i3c_hci_daa(struct i3c_master_controller *m)
+{
+	struct i3c_hci *hci = to_i3c_hci(m);
+
+	DBG("");
+
+	return hci->cmd->perform_daa(hci);
+}
+
+static int i3c_hci_priv_xfers(struct i3c_dev_desc *dev,
+			      struct i3c_priv_xfer *i3c_xfers,
+			      int nxfers)
+{
+	struct i3c_master_controller *m = i3c_dev_get_master(dev);
+	struct i3c_hci *hci = to_i3c_hci(m);
+	struct hci_xfer *xfer;
+	DECLARE_COMPLETION_ONSTACK(done);
+	unsigned int size_limit;
+	int i, last, ret = 0;
+
+	DBG("nxfers = %d", nxfers);
+
+	xfer = hci_alloc_xfer(nxfers);
+	if (!xfer)
+		return -ENOMEM;
+
+	size_limit = 1U << (16 + FIELD_GET(HC_CAP_MAX_DATA_LENGTH, hci->caps));
+
+	for (i = 0; i < nxfers; i++) {
+		xfer[i].data_len = i3c_xfers[i].len;
+		ret = -EFBIG;
+		if (xfer[i].data_len >= size_limit)
+			goto out;
+		xfer[i].rnw = i3c_xfers[i].rnw;
+		if (i3c_xfers[i].rnw) {
+			xfer[i].data = i3c_xfers[i].data.in;
+		} else {
+			/* silence the const qualifier warning with a cast */
+			xfer[i].data = (void *) i3c_xfers[i].data.out;
+		}
+		hci->cmd->prep_i3c_xfer(hci, dev, &xfer[i]);
+		xfer[i].cmd_desc[0] |= CMD_0_ROC;
+	}
+	last = i - 1;
+	xfer[last].cmd_desc[0] |= CMD_0_TOC;
+	xfer[last].completion = &done;
+
+	ret = hci->io->queue_xfer(hci, xfer, nxfers);
+	if (ret)
+		goto out;
+	if (!wait_for_completion_timeout(&done, HZ) &&
+	    hci->io->dequeue_xfer(hci, xfer, nxfers)) {
+		ret = -ETIME;
+		goto out;
+	}
+	for (i = 0; i < nxfers; i++) {
+		if (i3c_xfers[i].rnw)
+			i3c_xfers[i].len = RESP_DATA_LENGTH(xfer[i].response);
+		if (RESP_STATUS(xfer[i].response) != RESP_SUCCESS) {
+			ret = -EIO;
+			goto out;
+		}
+	}
+
+out:
+	hci_free_xfer(xfer, nxfers);
+	return ret;
+}
+
+static int i3c_hci_i2c_xfers(struct i2c_dev_desc *dev,
+			     const struct i2c_msg *i2c_xfers, int nxfers)
+{
+	struct i3c_master_controller *m = i2c_dev_get_master(dev);
+	struct i3c_hci *hci = to_i3c_hci(m);
+	struct hci_xfer *xfer;
+	DECLARE_COMPLETION_ONSTACK(done);
+	int i, last, ret = 0;
+
+	DBG("nxfers = %d", nxfers);
+
+	xfer = hci_alloc_xfer(nxfers);
+	if (!xfer)
+		return -ENOMEM;
+
+	for (i = 0; i < nxfers; i++) {
+		xfer[i].data = i2c_xfers[i].buf;
+		xfer[i].data_len = i2c_xfers[i].len;
+		xfer[i].rnw = i2c_xfers[i].flags & I2C_M_RD;
+		hci->cmd->prep_i2c_xfer(hci, dev, &xfer[i]);
+		xfer[i].cmd_desc[0] |= CMD_0_ROC;
+	}
+	last = i - 1;
+	xfer[last].cmd_desc[0] |= CMD_0_TOC;
+	xfer[last].completion = &done;
+
+	ret = hci->io->queue_xfer(hci, xfer, nxfers);
+	if (ret)
+		goto out;
+	if (!wait_for_completion_timeout(&done, HZ) &&
+	    hci->io->dequeue_xfer(hci, xfer, nxfers)) {
+		ret = -ETIME;
+		goto out;
+	}
+	for (i = 0; i < nxfers; i++) {
+		if (RESP_STATUS(xfer[i].response) != RESP_SUCCESS) {
+			ret = -EIO;
+			goto out;
+		}
+	}
+
+out:
+	hci_free_xfer(xfer, nxfers);
+	return ret;
+}
+
+static int i3c_hci_attach_i3c_dev(struct i3c_dev_desc *dev)
+{
+	struct i3c_master_controller *m = i3c_dev_get_master(dev);
+	struct i3c_hci *hci = to_i3c_hci(m);
+	struct i3c_hci_dev_data *dev_data;
+	int ret;
+
+	DBG("");
+
+	dev_data = kzalloc(sizeof(*dev_data), GFP_KERNEL);
+	if (!dev_data)
+		return -ENOMEM;
+	if (hci->cmd == &mipi_i3c_hci_cmd_v1) {
+		ret = mipi_i3c_hci_dat_v1.alloc_entry(hci);
+		if (ret < 0) {
+			kfree(dev_data);
+			return ret;
+		}
+		mipi_i3c_hci_dat_v1.set_dynamic_addr(hci, ret, dev->info.dyn_addr);
+		dev_data->dat_idx = ret;
+	}
+	i3c_dev_set_master_data(dev, dev_data);
+	return 0;
+}
+
+static int i3c_hci_reattach_i3c_dev(struct i3c_dev_desc *dev, u8 old_dyn_addr)
+{
+	struct i3c_master_controller *m = i3c_dev_get_master(dev);
+	struct i3c_hci *hci = to_i3c_hci(m);
+	struct i3c_hci_dev_data *dev_data = i3c_dev_get_master_data(dev);
+
+	DBG("");
+
+	if (hci->cmd == &mipi_i3c_hci_cmd_v1)
+		mipi_i3c_hci_dat_v1.set_dynamic_addr(hci, dev_data->dat_idx,
+					     dev->info.dyn_addr);
+	return 0;
+}
+
+static void i3c_hci_detach_i3c_dev(struct i3c_dev_desc *dev)
+{
+	struct i3c_master_controller *m = i3c_dev_get_master(dev);
+	struct i3c_hci *hci = to_i3c_hci(m);
+	struct i3c_hci_dev_data *dev_data = i3c_dev_get_master_data(dev);
+
+	DBG("");
+
+	i3c_dev_set_master_data(dev, NULL);
+	if (hci->cmd == &mipi_i3c_hci_cmd_v1)
+		mipi_i3c_hci_dat_v1.free_entry(hci, dev_data->dat_idx);
+	kfree(dev_data);
+}
+
+static int i3c_hci_attach_i2c_dev(struct i2c_dev_desc *dev)
+{
+	struct i3c_master_controller *m = i2c_dev_get_master(dev);
+	struct i3c_hci *hci = to_i3c_hci(m);
+	struct i3c_hci_dev_data *dev_data;
+	int ret;
+
+	DBG("");
+
+	if (hci->cmd != &mipi_i3c_hci_cmd_v1)
+		return 0;
+	dev_data = kzalloc(sizeof(*dev_data), GFP_KERNEL);
+	if (!dev_data)
+		return -ENOMEM;
+	ret = mipi_i3c_hci_dat_v1.alloc_entry(hci);
+	if (ret < 0) {
+		kfree(dev_data);
+		return ret;
+	}
+	mipi_i3c_hci_dat_v1.set_static_addr(hci, ret, dev->addr);
+	mipi_i3c_hci_dat_v1.set_flags(hci, ret, DAT_0_I2C_DEVICE, 0);
+	dev_data->dat_idx = ret;
+	i2c_dev_set_master_data(dev, dev_data);
+	return 0;
+}
+
+static void i3c_hci_detach_i2c_dev(struct i2c_dev_desc *dev)
+{
+	struct i3c_master_controller *m = i2c_dev_get_master(dev);
+	struct i3c_hci *hci = to_i3c_hci(m);
+	struct i3c_hci_dev_data *dev_data = i2c_dev_get_master_data(dev);
+
+	DBG("");
+
+	if (dev_data) {
+		i2c_dev_set_master_data(dev, NULL);
+		if (hci->cmd == &mipi_i3c_hci_cmd_v1)
+			mipi_i3c_hci_dat_v1.free_entry(hci, dev_data->dat_idx);
+		kfree(dev_data);
+	}
+}
+
+static int i3c_hci_request_ibi(struct i3c_dev_desc *dev,
+			       const struct i3c_ibi_setup *req)
+{
+	struct i3c_master_controller *m = i3c_dev_get_master(dev);
+	struct i3c_hci *hci = to_i3c_hci(m);
+	struct i3c_hci_dev_data *dev_data = i3c_dev_get_master_data(dev);
+	unsigned int dat_idx = dev_data->dat_idx;
+
+	if (req->max_payload_len != 0)
+		mipi_i3c_hci_dat_v1.set_flags(hci, dat_idx, DAT_0_IBI_PAYLOAD, 0);
+	else
+		mipi_i3c_hci_dat_v1.clear_flags(hci, dat_idx, DAT_0_IBI_PAYLOAD, 0);
+	return hci->io->request_ibi(hci, dev, req);
+}
+
+static void i3c_hci_free_ibi(struct i3c_dev_desc *dev)
+{
+	struct i3c_master_controller *m = i3c_dev_get_master(dev);
+	struct i3c_hci *hci = to_i3c_hci(m);
+
+	hci->io->free_ibi(hci, dev);
+}
+
+static int i3c_hci_enable_ibi(struct i3c_dev_desc *dev)
+{
+	struct i3c_master_controller *m = i3c_dev_get_master(dev);
+	struct i3c_hci *hci = to_i3c_hci(m);
+	struct i3c_hci_dev_data *dev_data = i3c_dev_get_master_data(dev);
+
+	mipi_i3c_hci_dat_v1.clear_flags(hci, dev_data->dat_idx, DAT_0_SIR_REJECT, 0);
+	return i3c_master_enec_locked(m, dev->info.dyn_addr, I3C_CCC_EVENT_SIR);
+}
+
+static int i3c_hci_disable_ibi(struct i3c_dev_desc *dev)
+{
+	struct i3c_master_controller *m = i3c_dev_get_master(dev);
+	struct i3c_hci *hci = to_i3c_hci(m);
+	struct i3c_hci_dev_data *dev_data = i3c_dev_get_master_data(dev);
+
+	mipi_i3c_hci_dat_v1.set_flags(hci, dev_data->dat_idx, DAT_0_SIR_REJECT, 0);
+	return i3c_master_disec_locked(m, dev->info.dyn_addr, I3C_CCC_EVENT_SIR);
+}
+
+static void i3c_hci_recycle_ibi_slot(struct i3c_dev_desc *dev,
+				     struct i3c_ibi_slot *slot)
+{
+	struct i3c_master_controller *m = i3c_dev_get_master(dev);
+	struct i3c_hci *hci = to_i3c_hci(m);
+
+	hci->io->recycle_ibi_slot(hci, dev, slot);
+}
+
+static const struct i3c_master_controller_ops i3c_hci_ops = {
+	.bus_init		= i3c_hci_bus_init,
+	.bus_cleanup		= i3c_hci_bus_cleanup,
+	.do_daa			= i3c_hci_daa,
+	.send_ccc_cmd		= i3c_hci_send_ccc_cmd,
+	.priv_xfers		= i3c_hci_priv_xfers,
+	.i2c_xfers		= i3c_hci_i2c_xfers,
+	.attach_i3c_dev		= i3c_hci_attach_i3c_dev,
+	.reattach_i3c_dev	= i3c_hci_reattach_i3c_dev,
+	.detach_i3c_dev		= i3c_hci_detach_i3c_dev,
+	.attach_i2c_dev		= i3c_hci_attach_i2c_dev,
+	.detach_i2c_dev		= i3c_hci_detach_i2c_dev,
+	.request_ibi		= i3c_hci_request_ibi,
+	.free_ibi		= i3c_hci_free_ibi,
+	.enable_ibi		= i3c_hci_enable_ibi,
+	.disable_ibi		= i3c_hci_disable_ibi,
+	.recycle_ibi_slot	= i3c_hci_recycle_ibi_slot,
+};
+
+static irqreturn_t i3c_hci_irq_handler(int irq, void *dev_id)
+{
+	struct i3c_hci *hci = dev_id;
+	irqreturn_t result = IRQ_NONE;
+	u32 val;
+
+	val = reg_read(INTR_STATUS);
+	DBG("INTR_STATUS = %#x", val);
+
+	if (val) {
+		reg_write(INTR_STATUS, val);
+	} else {
+		/* v1.0 does not have PIO cascaded notification bits */
+		val |= INTR_HC_PIO;
+	}
+
+	if (val & INTR_HC_RESET_CANCEL) {
+		DBG("cancelled reset");
+		val &= ~INTR_HC_RESET_CANCEL;
+	}
+	if (val & INTR_HC_INTERNAL_ERR) {
+		dev_err(&hci->master.dev, "Host Controller Internal Error\n");
+		val &= ~INTR_HC_INTERNAL_ERR;
+	}
+	if (val & INTR_HC_PIO) {
+		hci->io->irq_handler(hci, 0);
+		val &= ~INTR_HC_PIO;
+	}
+	if (val & INTR_HC_RINGS) {
+		hci->io->irq_handler(hci, val & INTR_HC_RINGS);
+		val &= ~INTR_HC_RINGS;
+	}
+	if (val)
+		dev_err(&hci->master.dev, "unexpected INTR_STATUS %#x\n", val);
+	else
+		result = IRQ_HANDLED;
+
+	return result;
+}
+
+static int i3c_hci_init(struct i3c_hci *hci)
+{
+	u32 regval, offset;
+	int ret;
+
+	/* Validate HCI hardware version */
+	regval = reg_read(HCI_VERSION);
+	hci->version_major = (regval >> 8) & 0xf;
+	hci->version_minor = (regval >> 4) & 0xf;
+	hci->revision = regval & 0xf;
+	dev_notice(&hci->master.dev, "MIPI I3C HCI v%u.%u r%02u\n",
+		   hci->version_major, hci->version_minor, hci->revision);
+	/* known versions */
+	switch (regval & ~0xf) {
+	case 0x100:	/* version 1.0 */
+	case 0x110:	/* version 1.1 */
+	case 0x200:	/* version 2.0 */
+		break;
+	default:
+		dev_err(&hci->master.dev, "unsupported HCI version\n");
+		return -EPROTONOSUPPORT;
+	}
+
+	hci->caps = reg_read(HC_CAPABILITIES);
+	DBG("caps = %#x", hci->caps);
+
+	regval = reg_read(DAT_SECTION);
+	offset = FIELD_GET(DAT_TABLE_OFFSET, regval);
+	hci->DAT_regs = offset ? hci->base_regs + offset : NULL;
+	hci->DAT_entries = FIELD_GET(DAT_TABLE_SIZE, regval);
+	hci->DAT_entry_size = FIELD_GET(DAT_ENTRY_SIZE, regval);
+	dev_info(&hci->master.dev, "DAT: %u %u-bytes entries at offset %#x\n",
+		 hci->DAT_entries, hci->DAT_entry_size * 4, offset);
+
+	regval = reg_read(DCT_SECTION);
+	offset = FIELD_GET(DCT_TABLE_OFFSET, regval);
+	hci->DCT_regs = offset ? hci->base_regs + offset : NULL;
+	hci->DCT_entries = FIELD_GET(DCT_TABLE_SIZE, regval);
+	hci->DCT_entry_size = FIELD_GET(DCT_ENTRY_SIZE, regval);
+	dev_info(&hci->master.dev, "DCT: %u %u-bytes entries at offset %#x\n",
+		 hci->DCT_entries, hci->DCT_entry_size * 4, offset);
+
+	regval = reg_read(RING_HEADERS_SECTION);
+	offset = FIELD_GET(RING_HEADERS_OFFSET, regval);
+	hci->RHS_regs = offset ? hci->base_regs + offset : NULL;
+	dev_info(&hci->master.dev, "Ring Headers at offset %#x\n", offset);
+
+	regval = reg_read(PIO_SECTION);
+	offset = FIELD_GET(PIO_REGS_OFFSET, regval);
+	hci->PIO_regs = offset ? hci->base_regs + offset : NULL;
+	dev_info(&hci->master.dev, "PIO section at offset %#x\n", offset);
+
+	regval = reg_read(EXT_CAPS_SECTION);
+	offset = FIELD_GET(EXT_CAPS_OFFSET, regval);
+	hci->EXTCAPS_regs = offset ? hci->base_regs + offset : NULL;
+	dev_info(&hci->master.dev, "Extended Caps at offset %#x\n", offset);
+
+	ret = i3c_hci_parse_ext_caps(hci);
+	if (ret)
+		return ret;
+
+	/*
+	 * Now let's reset the hardware.
+	 * SOFT_RST must be clear before we write to it.
+	 * Then we must wait until it clears again.
+	 */
+	ret = readx_poll_timeout(reg_read, RESET_CONTROL, regval,
+				 !(regval & SOFT_RST), 1, 10000);
+	if (ret)
+		return -ENXIO;
+	reg_write(RESET_CONTROL, SOFT_RST);
+	ret = readx_poll_timeout(reg_read, RESET_CONTROL, regval,
+				 !(regval & SOFT_RST), 1, 10000);
+	if (ret)
+		return -ENXIO;
+
+	/* Disable all interrupts and allow all signal updates */
+	reg_write(INTR_SIGNAL_ENABLE, 0x0);
+	reg_write(INTR_STATUS_ENABLE, 0xffffffff);
+
+	/* Make sure our data ordering fits the host's */
+	regval = reg_read(HC_CONTROL);
+	if (IS_ENABLED(CONFIG_CPU_BIG_ENDIAN)) {
+		if (!(regval & HC_CONTROL_DATA_BIG_ENDIAN)) {
+			regval |= HC_CONTROL_DATA_BIG_ENDIAN;
+			reg_write(HC_CONTROL, regval);
+			regval = reg_read(HC_CONTROL);
+			if (!(regval & HC_CONTROL_DATA_BIG_ENDIAN)) {
+				dev_err(&hci->master.dev, "cannot set BE mode\n");
+				return -EOPNOTSUPP;
+			}
+		}
+	} else {
+		if (regval & HC_CONTROL_DATA_BIG_ENDIAN) {
+			regval &= ~HC_CONTROL_DATA_BIG_ENDIAN;
+			reg_write(HC_CONTROL, regval);
+			regval = reg_read(HC_CONTROL);
+			if (regval & HC_CONTROL_DATA_BIG_ENDIAN) {
+				dev_err(&hci->master.dev, "cannot clear BE mode\n");
+				return -EOPNOTSUPP;
+			}
+		}
+	}
+
+	/* Select our command descriptor model */
+	switch (FIELD_GET(HC_CAP_CMD_SIZE, hci->caps)) {
+	case 0:
+		hci->cmd = &mipi_i3c_hci_cmd_v1;
+		break;
+	case 1:
+		hci->cmd = &mipi_i3c_hci_cmd_v2;
+		break;
+	default:
+		dev_err(&hci->master.dev, "wrong CMD_SIZE capability value\n");
+		return -EINVAL;
+	}
+
+	/* Try activating DMA operations first */
+	if (hci->RHS_regs) {
+		reg_clear(HC_CONTROL, HC_CONTROL_PIO_MODE);
+		if (reg_read(HC_CONTROL) & HC_CONTROL_PIO_MODE) {
+			dev_err(&hci->master.dev, "PIO mode is stuck\n");
+			ret = -EIO;
+		} else {
+			hci->io = &mipi_i3c_hci_dma;
+			dev_info(&hci->master.dev, "Using DMA\n");
+		}
+	}
+
+	/* If no DMA, try PIO */
+	if (!hci->io && hci->PIO_regs) {
+		reg_set(HC_CONTROL, HC_CONTROL_PIO_MODE);
+		if (!(reg_read(HC_CONTROL) & HC_CONTROL_PIO_MODE)) {
+			dev_err(&hci->master.dev, "DMA mode is stuck\n");
+			ret = -EIO;
+		} else {
+			hci->io = &mipi_i3c_hci_pio;
+			dev_info(&hci->master.dev, "Using PIO\n");
+		}
+	}
+
+	if (!hci->io) {
+		dev_err(&hci->master.dev, "neither DMA nor PIO can be used\n");
+		if (!ret)
+			ret = -EINVAL;
+		return ret;
+	}
+
+	return 0;
+}
+
+static int i3c_hci_probe(struct platform_device *pdev)
+{
+	struct i3c_hci *hci;
+	int irq, ret;
+
+	hci = devm_kzalloc(&pdev->dev, sizeof(*hci), GFP_KERNEL);
+	if (!hci)
+		return -ENOMEM;
+	hci->base_regs = devm_platform_ioremap_resource(pdev, 0);
+	if (IS_ERR(hci->base_regs))
+		return PTR_ERR(hci->base_regs);
+
+	platform_set_drvdata(pdev, hci);
+	/* temporary for dev_printk's, to be replaced in i3c_master_register */
+	hci->master.dev.init_name = dev_name(&pdev->dev);
+
+	ret = i3c_hci_init(hci);
+	if (ret)
+		return ret;
+
+	irq = platform_get_irq(pdev, 0);
+	ret = devm_request_irq(&pdev->dev, irq, i3c_hci_irq_handler,
+			       0, NULL, hci);
+	if (ret)
+		return ret;
+
+	ret = i3c_master_register(&hci->master, &pdev->dev,
+				  &i3c_hci_ops, false);
+	if (ret)
+		return ret;
+
+	return 0;
+}
+
+static int i3c_hci_remove(struct platform_device *pdev)
+{
+	struct i3c_hci *hci = platform_get_drvdata(pdev);
+
+	return i3c_master_unregister(&hci->master);
+}
+
+static const __maybe_unused struct of_device_id i3c_hci_of_match[] = {
+	{ .compatible = "mipi-i3c-hci", },
+	{},
+};
+MODULE_DEVICE_TABLE(of, i3c_hci_of_match);
+
+static struct platform_driver i3c_hci_driver = {
+	.probe = i3c_hci_probe,
+	.remove = i3c_hci_remove,
+	.driver = {
+		.name = "mipi-i3c-hci",
+		.of_match_table = of_match_ptr(i3c_hci_of_match),
+	},
+};
+module_platform_driver(i3c_hci_driver);
+
+MODULE_AUTHOR("Nicolas Pitre <npitre@baylibre.com>");
+MODULE_DESCRIPTION("MIPI I3C HCI driver");
+MODULE_LICENSE("Dual BSD/GPL");
diff --git a/drivers/i3c/master/mipi-i3c-hci/dat.h b/drivers/i3c/master/mipi-i3c-hci/dat.h
new file mode 100644
index 000000000000..1f0f345c3daf
--- /dev/null
+++ b/drivers/i3c/master/mipi-i3c-hci/dat.h
@@ -0,0 +1,32 @@
+/* SPDX-License-Identifier: BSD-3-Clause */
+/*
+ * Copyright (c) 2020, MIPI Alliance, Inc.
+ *
+ * Author: Nicolas Pitre <npitre@baylibre.com>
+ *
+ * Common DAT related stuff
+ */
+
+#ifndef DAT_H
+#define DAT_H
+
+/* Global DAT flags */
+#define DAT_0_I2C_DEVICE		W0_BIT_(31)
+#define DAT_0_SIR_REJECT		W0_BIT_(13)
+#define DAT_0_IBI_PAYLOAD		W0_BIT_(12)
+
+struct hci_dat_ops {
+	int (*init)(struct i3c_hci *hci);
+	void (*cleanup)(struct i3c_hci *hci);
+	int (*alloc_entry)(struct i3c_hci *hci);
+	void (*free_entry)(struct i3c_hci *hci, unsigned int dat_idx);
+	void (*set_dynamic_addr)(struct i3c_hci *hci, unsigned int dat_idx, u8 addr);
+	void (*set_static_addr)(struct i3c_hci *hci, unsigned int dat_idx, u8 addr);
+	void (*set_flags)(struct i3c_hci *hci, unsigned int dat_idx, u32 w0, u32 w1);
+	void (*clear_flags)(struct i3c_hci *hci, unsigned int dat_idx, u32 w0, u32 w1);
+	int (*get_index)(struct i3c_hci *hci, u8 address);
+};
+
+extern const struct hci_dat_ops mipi_i3c_hci_dat_v1;
+
+#endif
diff --git a/drivers/i3c/master/mipi-i3c-hci/dat_v1.c b/drivers/i3c/master/mipi-i3c-hci/dat_v1.c
new file mode 100644
index 000000000000..97bb49ff5b53
--- /dev/null
+++ b/drivers/i3c/master/mipi-i3c-hci/dat_v1.c
@@ -0,0 +1,182 @@
+// SPDX-License-Identifier: BSD-3-Clause
+/*
+ * Copyright (c) 2020, MIPI Alliance, Inc.
+ *
+ * Author: Nicolas Pitre <npitre@baylibre.com>
+ */
+
+#include <linux/bitfield.h>
+#include <linux/bitmap.h>
+#include <linux/device.h>
+#include <linux/errno.h>
+#include <linux/i3c/master.h>
+#include <linux/io.h>
+
+#include "hci.h"
+#include "dat.h"
+
+
+/*
+ * Device Address Table Structure
+ */
+
+#define DAT_1_AUTOCMD_HDR_CODE		W1_MASK(58, 51)
+#define DAT_1_AUTOCMD_MODE		W1_MASK(50, 48)
+#define DAT_1_AUTOCMD_VALUE		W1_MASK(47, 40)
+#define DAT_1_AUTOCMD_MASK		W1_MASK(39, 32)
+/*	DAT_0_I2C_DEVICE		W0_BIT_(31) */
+#define DAT_0_DEV_NACK_RETRY_CNT	W0_MASK(30, 29)
+#define DAT_0_RING_ID			W0_MASK(28, 26)
+#define DAT_0_DYNADDR_PARITY		W0_BIT_(23)
+#define DAT_0_DYNAMIC_ADDRESS		W0_MASK(22, 16)
+#define DAT_0_TS			W0_BIT_(15)
+#define DAT_0_MR_REJECT			W0_BIT_(14)
+/*	DAT_0_SIR_REJECT		W0_BIT_(13) */
+/*	DAT_0_IBI_PAYLOAD		W0_BIT_(12) */
+#define DAT_0_STATIC_ADDRESS		W0_MASK(6, 0)
+
+#define dat_w0_read(i)		readl(hci->DAT_regs + (i) * 8)
+#define dat_w1_read(i)		readl(hci->DAT_regs + (i) * 8 + 4)
+#define dat_w0_write(i, v)	writel(v, hci->DAT_regs + (i) * 8)
+#define dat_w1_write(i, v)	writel(v, hci->DAT_regs + (i) * 8 + 4)
+
+static inline bool dynaddr_parity(unsigned int addr)
+{
+	addr |= 1 << 7;
+	addr += addr >> 4;
+	addr += addr >> 2;
+	addr += addr >> 1;
+	return (addr & 1);
+}
+
+static int hci_dat_v1_init(struct i3c_hci *hci)
+{
+	unsigned int dat_idx;
+
+	if (!hci->DAT_regs) {
+		dev_err(&hci->master.dev,
+			"only DAT in register space is supported at the moment\n");
+		return -EOPNOTSUPP;
+	}
+	if (hci->DAT_entry_size != 8) {
+		dev_err(&hci->master.dev,
+			"only 8-bytes DAT entries are supported at the moment\n");
+		return -EOPNOTSUPP;
+	}
+
+	/* use a bitmap for faster free slot search */
+	hci->DAT_data = bitmap_zalloc(hci->DAT_entries, GFP_KERNEL);
+	if (!hci->DAT_data)
+		return -ENOMEM;
+
+	/* clear them */
+	for (dat_idx = 0; dat_idx < hci->DAT_entries; dat_idx++) {
+		dat_w0_write(dat_idx, 0);
+		dat_w1_write(dat_idx, 0);
+	}
+
+	return 0;
+}
+
+static void hci_dat_v1_cleanup(struct i3c_hci *hci)
+{
+	bitmap_free(hci->DAT_data);
+	hci->DAT_data = NULL;
+}
+
+static int hci_dat_v1_alloc_entry(struct i3c_hci *hci)
+{
+	unsigned int dat_idx;
+
+	dat_idx = find_first_zero_bit(hci->DAT_data, hci->DAT_entries);
+	if (dat_idx >= hci->DAT_entries)
+		return -ENOENT;
+	__set_bit(dat_idx, hci->DAT_data);
+
+	/* default flags */
+	dat_w0_write(dat_idx, DAT_0_SIR_REJECT | DAT_0_MR_REJECT);
+
+	return dat_idx;
+}
+
+static void hci_dat_v1_free_entry(struct i3c_hci *hci, unsigned int dat_idx)
+{
+	dat_w0_write(dat_idx, 0);
+	dat_w1_write(dat_idx, 0);
+	__clear_bit(dat_idx, hci->DAT_data);
+}
+
+static void hci_dat_v1_set_dynamic_addr(struct i3c_hci *hci,
+					unsigned int dat_idx, u8 address)
+{
+	u32 dat_w0;
+
+	dat_w0 = dat_w0_read(dat_idx);
+	dat_w0 &= ~(DAT_0_DYNAMIC_ADDRESS | DAT_0_DYNADDR_PARITY);
+	dat_w0 |= FIELD_PREP(DAT_0_DYNAMIC_ADDRESS, address) |
+		  (dynaddr_parity(address) ? DAT_0_DYNADDR_PARITY : 0);
+	dat_w0_write(dat_idx, dat_w0);
+}
+
+static void hci_dat_v1_set_static_addr(struct i3c_hci *hci,
+				       unsigned int dat_idx, u8 address)
+{
+	u32 dat_w0;
+
+	dat_w0 = dat_w0_read(dat_idx);
+	dat_w0 &= ~DAT_0_STATIC_ADDRESS;
+	dat_w0 |= FIELD_PREP(DAT_0_STATIC_ADDRESS, address);
+	dat_w0_write(dat_idx, dat_w0);
+}
+
+static void hci_dat_v1_set_flags(struct i3c_hci *hci, unsigned int dat_idx,
+				 u32 w0_flags, u32 w1_flags)
+{
+	u32 dat_w0, dat_w1;
+
+	dat_w0 = dat_w0_read(dat_idx);
+	dat_w1 = dat_w1_read(dat_idx);
+	dat_w0 |= w0_flags;
+	dat_w1 |= w1_flags;
+	dat_w0_write(dat_idx, dat_w0);
+	dat_w1_write(dat_idx, dat_w1);
+}
+
+static void hci_dat_v1_clear_flags(struct i3c_hci *hci, unsigned int dat_idx,
+				   u32 w0_flags, u32 w1_flags)
+{
+	u32 dat_w0, dat_w1;
+
+	dat_w0 = dat_w0_read(dat_idx);
+	dat_w1 = dat_w1_read(dat_idx);
+	dat_w0 &= ~w0_flags;
+	dat_w1 &= ~w1_flags;
+	dat_w0_write(dat_idx, dat_w0);
+	dat_w1_write(dat_idx, dat_w1);
+}
+
+static int hci_dat_v1_get_index(struct i3c_hci *hci, u8 dev_addr)
+{
+	unsigned int dat_idx;
+	u32 dat_w0;
+
+	for_each_set_bit(dat_idx, hci->DAT_data, hci->DAT_entries) {
+		dat_w0 = dat_w0_read(dat_idx);
+		if (FIELD_GET(DAT_0_DYNAMIC_ADDRESS, dat_w0) == dev_addr)
+			return dat_idx;
+	}
+
+	return -ENODEV;
+}
+
+const struct hci_dat_ops mipi_i3c_hci_dat_v1 = {
+	.init			= hci_dat_v1_init,
+	.cleanup		= hci_dat_v1_cleanup,
+	.alloc_entry		= hci_dat_v1_alloc_entry,
+	.free_entry		= hci_dat_v1_free_entry,
+	.set_dynamic_addr	= hci_dat_v1_set_dynamic_addr,
+	.set_static_addr	= hci_dat_v1_set_static_addr,
+	.set_flags		= hci_dat_v1_set_flags,
+	.clear_flags		= hci_dat_v1_clear_flags,
+	.get_index		= hci_dat_v1_get_index,
+};
diff --git a/drivers/i3c/master/mipi-i3c-hci/dct.h b/drivers/i3c/master/mipi-i3c-hci/dct.h
new file mode 100644
index 000000000000..1028e0b40d89
--- /dev/null
+++ b/drivers/i3c/master/mipi-i3c-hci/dct.h
@@ -0,0 +1,16 @@
+/* SPDX-License-Identifier: BSD-3-Clause */
+/*
+ * Copyright (c) 2020, MIPI Alliance, Inc.
+ *
+ * Author: Nicolas Pitre <npitre@baylibre.com>
+ *
+ * Common DCT related stuff
+ */
+
+#ifndef DCT_H
+#define DCT_H
+
+void i3c_hci_dct_get_val(struct i3c_hci *hci, unsigned int dct_idx,
+			 u64 *pid, unsigned int *dcr, unsigned int *bcr);
+
+#endif
diff --git a/drivers/i3c/master/mipi-i3c-hci/dct_v1.c b/drivers/i3c/master/mipi-i3c-hci/dct_v1.c
new file mode 100644
index 000000000000..acfd4d60f7b0
--- /dev/null
+++ b/drivers/i3c/master/mipi-i3c-hci/dct_v1.c
@@ -0,0 +1,36 @@
+// SPDX-License-Identifier: BSD-3-Clause
+/*
+ * Copyright (c) 2020, MIPI Alliance, Inc.
+ *
+ * Author: Nicolas Pitre <npitre@baylibre.com>
+ */
+
+#include <linux/device.h>
+#include <linux/bitfield.h>
+#include <linux/i3c/master.h>
+#include <linux/io.h>
+
+#include "hci.h"
+#include "dct.h"
+
+/*
+ * Device Characteristic Table
+ */
+
+void i3c_hci_dct_get_val(struct i3c_hci *hci, unsigned int dct_idx,
+			 u64 *pid, unsigned int *dcr, unsigned int *bcr)
+{
+	void __iomem *reg = hci->DCT_regs + dct_idx * 4 * 4;
+	u32 dct_entry_data[4];
+	unsigned int i;
+
+	for (i = 0; i < 4; i++) {
+		dct_entry_data[i] = readl(reg);
+		reg += 4;
+	}
+
+	*pid = ((u64)dct_entry_data[0]) << (47 - 32 + 1) |
+	       FIELD_GET(W1_MASK(47, 32), dct_entry_data[1]);
+	*dcr = FIELD_GET(W2_MASK(71, 64), dct_entry_data[2]);
+	*bcr = FIELD_GET(W2_MASK(79, 72), dct_entry_data[2]);
+}
diff --git a/drivers/i3c/master/mipi-i3c-hci/dma.c b/drivers/i3c/master/mipi-i3c-hci/dma.c
new file mode 100644
index 000000000000..2990ac9eaade
--- /dev/null
+++ b/drivers/i3c/master/mipi-i3c-hci/dma.c
@@ -0,0 +1,784 @@
+// SPDX-License-Identifier: BSD-3-Clause
+/*
+ * Copyright (c) 2020, MIPI Alliance, Inc.
+ *
+ * Author: Nicolas Pitre <npitre@baylibre.com>
+ *
+ * Note: The I3C HCI v2.0 spec is still in flux. The IBI support is based on
+ * v1.x of the spec and v2.0 will likely be split out.
+ */
+
+#include <linux/bitfield.h>
+#include <linux/device.h>
+#include <linux/dma-mapping.h>
+#include <linux/errno.h>
+#include <linux/i3c/master.h>
+#include <linux/io.h>
+
+#include "hci.h"
+#include "cmd.h"
+#include "ibi.h"
+
+
+/*
+ * Software Parameter Values (somewhat arb itrary for now).
+ * Some of them could be determined at run time eventually.
+ */
+
+#define XFER_RINGS			1	/* max: 8 */
+#define XFER_RING_ENTRIES		16	/* max: 255 */
+
+#define IBI_RINGS			1	/* max: 8 */
+#define IBI_STATUS_RING_ENTRIES		32	/* max: 255 */
+#define IBI_CHUNK_CACHELINES		1	/* max: 256 bytes equivalent */
+#define IBI_CHUNK_POOL_SIZE		128	/* max: 1023 */
+
+/*
+ * Ring Header Preamble
+ */
+
+#define rhs_reg_read(r)		readl(hci->RHS_regs + (RHS_##r))
+#define rhs_reg_write(r, v)	writel(v, hci->RHS_regs + (RHS_##r))
+
+#define RHS_CONTROL			0x00
+#define PREAMBLE_SIZE			GENMASK(31, 24)	/* Preamble Section Size */
+#define HEADER_SIZE			GENMASK(23, 16)	/* Ring Header Size */
+#define MAX_HEADER_COUNT_CAP		GENMASK(7, 4) /* HC Max Header Count */
+#define MAX_HEADER_COUNT		GENMASK(3, 0) /* Driver Max Header Count */
+
+#define RHS_RHn_OFFSET(n)		(0x04 + (n)*4)
+
+/*
+ * Ring Header (Per-Ring Bundle)
+ */
+
+#define rh_reg_read(r)		readl(rh->regs + (RH_##r))
+#define rh_reg_write(r, v)	writel(v, rh->regs + (RH_##r))
+
+#define RH_CR_SETUP			0x00	/* Command/Response Ring */
+#define CR_XFER_STRUCT_SIZE		GENMASK(31, 24)
+#define CR_RESP_STRUCT_SIZE		GENMASK(23, 16)
+#define CR_RING_SIZE			GENMASK(8, 0)
+
+#define RH_IBI_SETUP			0x04
+#define IBI_STATUS_STRUCT_SIZE		GENMASK(31, 24)
+#define IBI_STATUS_RING_SIZE		GENMASK(23, 16)
+#define IBI_DATA_CHUNK_SIZE		GENMASK(12, 10)
+#define IBI_DATA_CHUNK_COUNT		GENMASK(9, 0)
+
+#define RH_CHUNK_CONTROL			0x08
+
+#define RH_INTR_STATUS			0x10
+#define RH_INTR_STATUS_ENABLE		0x14
+#define RH_INTR_SIGNAL_ENABLE		0x18
+#define RH_INTR_FORCE			0x1c
+#define INTR_IBI_READY			BIT(12)
+#define INTR_TRANSFER_COMPLETION	BIT(11)
+#define INTR_RING_OP			BIT(10)
+#define INTR_TRANSFER_ERR		BIT(9)
+#define INTR_WARN_INS_STOP_MODE		BIT(7)
+#define INTR_IBI_RING_FULL		BIT(6)
+#define INTR_TRANSFER_ABORT		BIT(5)
+
+#define RH_RING_STATUS			0x20
+#define RING_STATUS_LOCKED		BIT(3)
+#define RING_STATUS_ABORTED		BIT(2)
+#define RING_STATUS_RUNNING		BIT(1)
+#define RING_STATUS_ENABLED		BIT(0)
+
+#define RH_RING_CONTROL			0x24
+#define RING_CTRL_ABORT			BIT(2)
+#define RING_CTRL_RUN_STOP		BIT(1)
+#define RING_CTRL_ENABLE		BIT(0)
+
+#define RH_RING_OPERATION1		0x28
+#define RING_OP1_IBI_DEQ_PTR		GENMASK(23, 16)
+#define RING_OP1_CR_SW_DEQ_PTR		GENMASK(15, 8)
+#define RING_OP1_CR_ENQ_PTR		GENMASK(7, 0)
+
+#define RH_RING_OPERATION2		0x2c
+#define RING_OP2_IBI_ENQ_PTR		GENMASK(23, 16)
+#define RING_OP2_CR_DEQ_PTR		GENMASK(7, 0)
+
+#define RH_CMD_RING_BASE_LO		0x30
+#define RH_CMD_RING_BASE_HI		0x34
+#define RH_RESP_RING_BASE_LO		0x38
+#define RH_RESP_RING_BASE_HI		0x3c
+#define RH_IBI_STATUS_RING_BASE_LO	0x40
+#define RH_IBI_STATUS_RING_BASE_HI	0x44
+#define RH_IBI_DATA_RING_BASE_LO	0x48
+#define RH_IBI_DATA_RING_BASE_HI	0x4c
+
+#define RH_CMD_RING_SG			0x50	/* Ring Scatter Gather Support */
+#define RH_RESP_RING_SG			0x54
+#define RH_IBI_STATUS_RING_SG		0x58
+#define RH_IBI_DATA_RING_SG		0x5c
+#define RING_SG_BLP			BIT(31)	/* Buffer Vs. List Pointer */
+#define RING_SG_LIST_SIZE		GENMASK(15, 0)
+
+/*
+ * Data Buffer Descriptor (in memory)
+ */
+
+#define DATA_BUF_BLP			BIT(31)	/* Buffer Vs. List Pointer */
+#define DATA_BUF_IOC			BIT(30)	/* Interrupt on Completion */
+#define DATA_BUF_BLOCK_SIZE		GENMASK(15, 0)
+
+
+struct hci_rh_data {
+	void __iomem *regs;
+	void *xfer, *resp, *ibi_status, *ibi_data;
+	dma_addr_t xfer_dma, resp_dma, ibi_status_dma, ibi_data_dma;
+	unsigned int xfer_entries, ibi_status_entries, ibi_chunks_total;
+	unsigned int xfer_struct_sz, resp_struct_sz, ibi_status_sz, ibi_chunk_sz;
+	unsigned int done_ptr, ibi_chunk_ptr;
+	struct hci_xfer **src_xfers;
+	spinlock_t lock;
+	struct completion op_done;
+};
+
+struct hci_rings_data {
+	unsigned int total;
+	struct hci_rh_data headers[];
+};
+
+struct hci_dma_dev_ibi_data {
+	struct i3c_generic_ibi_pool *pool;
+	unsigned int max_len;
+};
+
+static inline u32 lo32(dma_addr_t physaddr)
+{
+	return physaddr;
+}
+
+static inline u32 hi32(dma_addr_t physaddr)
+{
+	/* trickery to avoid compiler warnings on 32-bit build targets */
+	if (sizeof(dma_addr_t) > 4) {
+		u64 hi = physaddr;
+		return hi >> 32;
+	}
+	return 0;
+}
+
+static void hci_dma_cleanup(struct i3c_hci *hci)
+{
+	struct hci_rings_data *rings = hci->io_data;
+	struct hci_rh_data *rh;
+	unsigned int i;
+
+	if (!rings)
+		return;
+
+	for (i = 0; i < rings->total; i++) {
+		rh = &rings->headers[i];
+
+		rh_reg_write(RING_CONTROL, 0);
+		rh_reg_write(CR_SETUP, 0);
+		rh_reg_write(IBI_SETUP, 0);
+		rh_reg_write(INTR_SIGNAL_ENABLE, 0);
+
+		if (rh->xfer)
+			dma_free_coherent(&hci->master.dev,
+					  rh->xfer_struct_sz * rh->xfer_entries,
+					  rh->xfer, rh->xfer_dma);
+		if (rh->resp)
+			dma_free_coherent(&hci->master.dev,
+					  rh->resp_struct_sz * rh->xfer_entries,
+					  rh->resp, rh->resp_dma);
+		kfree(rh->src_xfers);
+		if (rh->ibi_status)
+			dma_free_coherent(&hci->master.dev,
+					  rh->ibi_status_sz * rh->ibi_status_entries,
+					  rh->ibi_status, rh->ibi_status_dma);
+		if (rh->ibi_data_dma)
+			dma_unmap_single(&hci->master.dev, rh->ibi_data_dma,
+					 rh->ibi_chunk_sz * rh->ibi_chunks_total,
+					 DMA_FROM_DEVICE);
+		kfree(rh->ibi_data);
+	}
+
+	rhs_reg_write(CONTROL, 0);
+
+	kfree(rings);
+	hci->io_data = NULL;
+}
+
+static int hci_dma_init(struct i3c_hci *hci)
+{
+	struct hci_rings_data *rings;
+	struct hci_rh_data *rh;
+	u32 regval;
+	unsigned int i, nr_rings, xfers_sz, resps_sz;
+	unsigned int ibi_status_ring_sz, ibi_data_ring_sz;
+	int ret;
+
+	regval = rhs_reg_read(CONTROL);
+	nr_rings = FIELD_GET(MAX_HEADER_COUNT_CAP, regval);
+	dev_info(&hci->master.dev, "%d DMA rings available\n", nr_rings);
+	if (unlikely(nr_rings > 8)) {
+		dev_err(&hci->master.dev, "number of rings should be <= 8\n");
+		nr_rings = 8;
+	}
+	if (nr_rings > XFER_RINGS)
+		nr_rings = XFER_RINGS;
+	rings = kzalloc(struct_size(rings, headers, nr_rings), GFP_KERNEL);
+	if (!rings)
+		return -ENOMEM;
+	hci->io_data = rings;
+	rings->total = nr_rings;
+
+	for (i = 0; i < rings->total; i++) {
+		u32 offset = rhs_reg_read(RHn_OFFSET(i));
+
+		dev_info(&hci->master.dev, "Ring %d at offset %#x\n", i, offset);
+		ret = -EINVAL;
+		if (!offset)
+			goto err_out;
+		rh = &rings->headers[i];
+		rh->regs = hci->base_regs + offset;
+		spin_lock_init(&rh->lock);
+		init_completion(&rh->op_done);
+
+		rh->xfer_entries = XFER_RING_ENTRIES;
+
+		regval = rh_reg_read(CR_SETUP);
+		rh->xfer_struct_sz = FIELD_GET(CR_XFER_STRUCT_SIZE, regval);
+		rh->resp_struct_sz = FIELD_GET(CR_RESP_STRUCT_SIZE, regval);
+		DBG("xfer_struct_sz = %d, resp_struct_sz = %d",
+		    rh->xfer_struct_sz, rh->resp_struct_sz);
+		xfers_sz = rh->xfer_struct_sz * rh->xfer_entries;
+		resps_sz = rh->resp_struct_sz * rh->xfer_entries;
+
+		rh->xfer = dma_alloc_coherent(&hci->master.dev, xfers_sz,
+					      &rh->xfer_dma, GFP_KERNEL);
+		rh->resp = dma_alloc_coherent(&hci->master.dev, resps_sz,
+					      &rh->resp_dma, GFP_KERNEL);
+		rh->src_xfers =
+			kmalloc_array(rh->xfer_entries, sizeof(*rh->src_xfers),
+				      GFP_KERNEL);
+		ret = -ENOMEM;
+		if (!rh->xfer || !rh->resp || !rh->src_xfers)
+			goto err_out;
+
+		rh_reg_write(CMD_RING_BASE_LO, lo32(rh->xfer_dma));
+		rh_reg_write(CMD_RING_BASE_HI, hi32(rh->xfer_dma));
+		rh_reg_write(RESP_RING_BASE_LO, lo32(rh->resp_dma));
+		rh_reg_write(RESP_RING_BASE_HI, hi32(rh->resp_dma));
+
+		regval = FIELD_PREP(CR_RING_SIZE, rh->xfer_entries);
+		rh_reg_write(CR_SETUP, regval);
+
+		rh_reg_write(INTR_STATUS_ENABLE, 0xffffffff);
+		rh_reg_write(INTR_SIGNAL_ENABLE, INTR_IBI_READY |
+						 INTR_TRANSFER_COMPLETION |
+						 INTR_RING_OP |
+						 INTR_TRANSFER_ERR |
+						 INTR_WARN_INS_STOP_MODE |
+						 INTR_IBI_RING_FULL |
+						 INTR_TRANSFER_ABORT);
+
+		/* IBIs */
+
+		if (i >= IBI_RINGS)
+			goto ring_ready;
+
+		regval = rh_reg_read(IBI_SETUP);
+		rh->ibi_status_sz = FIELD_GET(IBI_STATUS_STRUCT_SIZE, regval);
+		rh->ibi_status_entries = IBI_STATUS_RING_ENTRIES;
+		rh->ibi_chunks_total = IBI_CHUNK_POOL_SIZE;
+
+		rh->ibi_chunk_sz = dma_get_cache_alignment();
+		rh->ibi_chunk_sz *= IBI_CHUNK_CACHELINES;
+		BUG_ON(rh->ibi_chunk_sz > 256);
+
+		ibi_status_ring_sz = rh->ibi_status_sz * rh->ibi_status_entries;
+		ibi_data_ring_sz = rh->ibi_chunk_sz * rh->ibi_chunks_total;
+
+		rh->ibi_status =
+			dma_alloc_coherent(&hci->master.dev, ibi_status_ring_sz,
+					   &rh->ibi_status_dma, GFP_KERNEL);
+		rh->ibi_data = kmalloc(ibi_data_ring_sz, GFP_KERNEL);
+		ret = -ENOMEM;
+		if (!rh->ibi_status || !rh->ibi_data)
+			goto err_out;
+		rh->ibi_data_dma =
+			dma_map_single(&hci->master.dev, rh->ibi_data,
+				       ibi_data_ring_sz, DMA_FROM_DEVICE);
+		if (dma_mapping_error(&hci->master.dev, rh->ibi_data_dma)) {
+			rh->ibi_data_dma = 0;
+			ret = -ENOMEM;
+			goto err_out;
+		}
+
+		regval = FIELD_PREP(IBI_STATUS_RING_SIZE,
+				    rh->ibi_status_entries) |
+			 FIELD_PREP(IBI_DATA_CHUNK_SIZE,
+				    ilog2(rh->ibi_chunk_sz) - 2) |
+			 FIELD_PREP(IBI_DATA_CHUNK_COUNT,
+				    rh->ibi_chunks_total);
+		rh_reg_write(IBI_SETUP, regval);
+
+		regval = rh_reg_read(INTR_SIGNAL_ENABLE);
+		regval |= INTR_IBI_READY;
+		rh_reg_write(INTR_SIGNAL_ENABLE, regval);
+
+ring_ready:
+		rh_reg_write(RING_CONTROL, RING_CTRL_ENABLE);
+	}
+
+	regval = FIELD_PREP(MAX_HEADER_COUNT, rings->total);
+	rhs_reg_write(CONTROL, regval);
+	return 0;
+
+err_out:
+	hci_dma_cleanup(hci);
+	return ret;
+}
+
+static void hci_dma_unmap_xfer(struct i3c_hci *hci,
+			       struct hci_xfer *xfer_list, unsigned int n)
+{
+	struct hci_xfer *xfer;
+	unsigned int i;
+
+	for (i = 0; i < n; i++) {
+		xfer = xfer_list + i;
+		dma_unmap_single(&hci->master.dev,
+				 xfer->data_dma, xfer->data_len,
+				 xfer->rnw ? DMA_FROM_DEVICE : DMA_TO_DEVICE);
+	}
+}
+
+static int hci_dma_queue_xfer(struct i3c_hci *hci,
+			      struct hci_xfer *xfer_list, int n)
+{
+	struct hci_rings_data *rings = hci->io_data;
+	struct hci_rh_data *rh;
+	unsigned int i, ring, enqueue_ptr;
+	u32 op1_val, op2_val;
+
+	/* For now we only use ring 0 */
+	ring = 0;
+	rh = &rings->headers[ring];
+
+	op1_val = rh_reg_read(RING_OPERATION1);
+	enqueue_ptr = FIELD_GET(RING_OP1_CR_ENQ_PTR, op1_val);
+	for (i = 0; i < n; i++) {
+		struct hci_xfer *xfer = xfer_list + i;
+		u32 *ring_data = rh->xfer + rh->xfer_struct_sz * enqueue_ptr;
+
+		/* store cmd descriptor */
+		*ring_data++ = xfer->cmd_desc[0];
+		*ring_data++ = xfer->cmd_desc[1];
+		if (hci->cmd == &mipi_i3c_hci_cmd_v2) {
+			*ring_data++ = xfer->cmd_desc[2];
+			*ring_data++ = xfer->cmd_desc[3];
+		}
+
+		/* first word of Data Buffer Descriptor Structure */
+		if (!xfer->data)
+			xfer->data_len = 0;
+		*ring_data++ =
+			FIELD_PREP(DATA_BUF_BLOCK_SIZE, xfer->data_len) |
+			((i == n - 1) ? DATA_BUF_IOC : 0);
+
+		/* 2nd and 3rd words of Data Buffer Descriptor Structure */
+		if (xfer->data) {
+			xfer->data_dma =
+				dma_map_single(&hci->master.dev,
+					       xfer->data,
+					       xfer->data_len,
+					       xfer->rnw ?
+						  DMA_FROM_DEVICE :
+						  DMA_TO_DEVICE);
+			if (dma_mapping_error(&hci->master.dev,
+					      xfer->data_dma)) {
+				hci_dma_unmap_xfer(hci, xfer_list, i);
+				return -ENOMEM;
+			}
+			*ring_data++ = lo32(xfer->data_dma);
+			*ring_data++ = hi32(xfer->data_dma);
+		} else {
+			*ring_data++ = 0;
+			*ring_data++ = 0;
+		}
+
+		/* remember corresponding xfer struct */
+		rh->src_xfers[enqueue_ptr] = xfer;
+		/* remember corresponding ring/entry for this xfer structure */
+		xfer->ring_number = ring;
+		xfer->ring_entry = enqueue_ptr;
+
+		enqueue_ptr = (enqueue_ptr + 1) % rh->xfer_entries;
+
+		/*
+		 * We may update the hardware view of the enqueue pointer
+		 * only if we didn't reach its dequeue pointer.
+		 */
+		op2_val = rh_reg_read(RING_OPERATION2);
+		if (enqueue_ptr == FIELD_GET(RING_OP2_CR_DEQ_PTR, op2_val)) {
+			/* the ring is full */
+			hci_dma_unmap_xfer(hci, xfer_list, i + 1);
+			return -EBUSY;
+		}
+	}
+
+	/* take care to update the hardware enqueue pointer atomically */
+	spin_lock_irq(&rh->lock);
+	op1_val = rh_reg_read(RING_OPERATION1);
+	op1_val &= ~RING_OP1_CR_ENQ_PTR;
+	op1_val |= FIELD_PREP(RING_OP1_CR_ENQ_PTR, enqueue_ptr);
+	rh_reg_write(RING_OPERATION1, op1_val);
+	spin_unlock_irq(&rh->lock);
+
+	return 0;
+}
+
+static bool hci_dma_dequeue_xfer(struct i3c_hci *hci,
+				 struct hci_xfer *xfer_list, int n)
+{
+	struct hci_rings_data *rings = hci->io_data;
+	struct hci_rh_data *rh = &rings->headers[xfer_list[0].ring_number];
+	unsigned int i;
+	bool did_unqueue = false;
+
+	/* stop the ring */
+	rh_reg_write(RING_CONTROL, RING_CTRL_ABORT);
+	if (wait_for_completion_timeout(&rh->op_done, HZ) == 0) {
+		/*
+		 * We're deep in it if ever this condition is ever met.
+		 * Hardware might still be writing to memory, etc.
+		 * Better suspend the world than risking silent corruption.
+		 */
+		dev_crit(&hci->master.dev, "unable to abort the ring\n");
+		BUG();
+	}
+
+	for (i = 0; i < n; i++) {
+		struct hci_xfer *xfer = xfer_list + i;
+		int idx = xfer->ring_entry;
+
+		/*
+		 * At the time the abort happened, the xfer might have
+		 * completed already. If not then replace corresponding
+		 * descriptor entries with a no-op.
+		 */
+		if (idx >= 0) {
+			u32 *ring_data = rh->xfer + rh->xfer_struct_sz * idx;
+
+			/* store no-op cmd descriptor */
+			*ring_data++ = FIELD_PREP(CMD_0_ATTR, 0x7);
+			*ring_data++ = 0;
+			if (hci->cmd == &mipi_i3c_hci_cmd_v2) {
+				*ring_data++ = 0;
+				*ring_data++ = 0;
+			}
+
+			/* disassociate this xfer struct */
+			rh->src_xfers[idx] = NULL;
+
+			/* and unmap it */
+			hci_dma_unmap_xfer(hci, xfer, 1);
+
+			did_unqueue = true;
+		}
+	}
+
+	/* restart the ring */
+	rh_reg_write(RING_CONTROL, RING_CTRL_ENABLE);
+
+	return did_unqueue;
+}
+
+static void hci_dma_xfer_done(struct i3c_hci *hci, struct hci_rh_data *rh)
+{
+	u32 op1_val, op2_val, resp, *ring_resp;
+	unsigned int tid, done_ptr = rh->done_ptr;
+	struct hci_xfer *xfer;
+
+	for (;;) {
+		op2_val = rh_reg_read(RING_OPERATION2);
+		if (done_ptr == FIELD_GET(RING_OP2_CR_DEQ_PTR, op2_val))
+			break;
+
+		ring_resp = rh->resp + rh->resp_struct_sz * done_ptr;
+		resp = *ring_resp;
+		tid = RESP_TID(resp);
+		DBG("resp = 0x%08x", resp);
+
+		xfer = rh->src_xfers[done_ptr];
+		if (!xfer) {
+			DBG("orphaned ring entry");
+		} else {
+			hci_dma_unmap_xfer(hci, xfer, 1);
+			xfer->ring_entry = -1;
+			xfer->response = resp;
+			if (tid != xfer->cmd_tid) {
+				dev_err(&hci->master.dev,
+					"response tid=%d when expecting %d\n",
+					tid, xfer->cmd_tid);
+				/* TODO: do something about it? */
+			}
+			if (xfer->completion)
+				complete(xfer->completion);
+		}
+
+		done_ptr = (done_ptr + 1) % rh->xfer_entries;
+		rh->done_ptr = done_ptr;
+	}
+
+	/* take care to update the software dequeue pointer atomically */
+	spin_lock(&rh->lock);
+	op1_val = rh_reg_read(RING_OPERATION1);
+	op1_val &= ~RING_OP1_CR_SW_DEQ_PTR;
+	op1_val |= FIELD_PREP(RING_OP1_CR_SW_DEQ_PTR, done_ptr);
+	rh_reg_write(RING_OPERATION1, op1_val);
+	spin_unlock(&rh->lock);
+}
+
+static int hci_dma_request_ibi(struct i3c_hci *hci, struct i3c_dev_desc *dev,
+			       const struct i3c_ibi_setup *req)
+{
+	struct i3c_hci_dev_data *dev_data = i3c_dev_get_master_data(dev);
+	struct i3c_generic_ibi_pool *pool;
+	struct hci_dma_dev_ibi_data *dev_ibi;
+
+	dev_ibi = kmalloc(sizeof(*dev_ibi), GFP_KERNEL);
+	if (!dev_ibi)
+		return -ENOMEM;
+	pool = i3c_generic_ibi_alloc_pool(dev, req);
+	if (IS_ERR(pool)) {
+		kfree(dev_ibi);
+		return PTR_ERR(pool);
+	}
+	dev_ibi->pool = pool;
+	dev_ibi->max_len = req->max_payload_len;
+	dev_data->ibi_data = dev_ibi;
+	return 0;
+}
+
+static void hci_dma_free_ibi(struct i3c_hci *hci, struct i3c_dev_desc *dev)
+{
+	struct i3c_hci_dev_data *dev_data = i3c_dev_get_master_data(dev);
+	struct hci_dma_dev_ibi_data *dev_ibi = dev_data->ibi_data;
+
+	dev_data->ibi_data = NULL;
+	i3c_generic_ibi_free_pool(dev_ibi->pool);
+	kfree(dev_ibi);
+}
+
+static void hci_dma_recycle_ibi_slot(struct i3c_hci *hci,
+				     struct i3c_dev_desc *dev,
+				     struct i3c_ibi_slot *slot)
+{
+	struct i3c_hci_dev_data *dev_data = i3c_dev_get_master_data(dev);
+	struct hci_dma_dev_ibi_data *dev_ibi = dev_data->ibi_data;
+
+	i3c_generic_ibi_recycle_slot(dev_ibi->pool, slot);
+}
+
+static void hci_dma_process_ibi(struct i3c_hci *hci, struct hci_rh_data *rh)
+{
+	struct i3c_dev_desc *dev;
+	struct i3c_hci_dev_data *dev_data;
+	struct hci_dma_dev_ibi_data *dev_ibi;
+	struct i3c_ibi_slot *slot;
+	u32 op1_val, op2_val, ibi_status_error;
+	unsigned int ptr, enq_ptr, deq_ptr;
+	unsigned int ibi_size, ibi_chunks, ibi_data_offset, first_part;
+	int ibi_addr, last_ptr;
+	void *ring_ibi_data;
+	dma_addr_t ring_ibi_data_dma;
+
+	op1_val = rh_reg_read(RING_OPERATION1);
+	deq_ptr = FIELD_GET(RING_OP1_IBI_DEQ_PTR, op1_val);
+
+	op2_val = rh_reg_read(RING_OPERATION2);
+	enq_ptr = FIELD_GET(RING_OP2_IBI_ENQ_PTR, op2_val);
+
+	ibi_status_error = 0;
+	ibi_addr = -1;
+	ibi_chunks = 0;
+	ibi_size = 0;
+	last_ptr = -1;
+
+	/* let's find all we can about this IBI */
+	for (ptr = deq_ptr; ptr != enq_ptr;
+	     ptr = (ptr + 1) % rh->ibi_status_entries) {
+		u32 ibi_status, *ring_ibi_status;
+		unsigned int chunks;
+
+		ring_ibi_status = rh->ibi_status + rh->ibi_status_sz * ptr;
+		ibi_status = *ring_ibi_status;
+		DBG("status = %#x", ibi_status);
+
+		if (ibi_status_error) {
+			/* we no longer care */
+		} else if (ibi_status & IBI_ERROR) {
+			ibi_status_error = ibi_status;
+		} else if (ibi_addr ==  -1) {
+			ibi_addr = FIELD_GET(IBI_TARGET_ADDR, ibi_status);
+		} else if (ibi_addr != FIELD_GET(IBI_TARGET_ADDR, ibi_status)) {
+			/* the address changed unexpectedly */
+			ibi_status_error = ibi_status;
+		}
+
+		chunks = FIELD_GET(IBI_CHUNKS, ibi_status);
+		ibi_chunks += chunks;
+		if (!(ibi_status & IBI_LAST_STATUS)) {
+			ibi_size += chunks * rh->ibi_chunk_sz;
+		} else {
+			ibi_size += FIELD_GET(IBI_DATA_LENGTH, ibi_status);
+			last_ptr = ptr;
+			break;
+		}
+	}
+
+	/* validate what we've got */
+
+	if (last_ptr == -1) {
+		/* this IBI sequence is not yet complete */
+		DBG("no LAST_STATUS available (e=%d d=%d)", enq_ptr, deq_ptr);
+		return;
+	}
+	deq_ptr = last_ptr + 1;
+	deq_ptr %= rh->ibi_status_entries;
+
+	if (ibi_status_error) {
+		dev_err(&hci->master.dev, "IBI error from %#x\n", ibi_addr);
+		goto done;
+	}
+
+	/* determine who this is for */
+	dev = i3c_hci_addr_to_dev(hci, ibi_addr);
+	if (!dev) {
+		dev_err(&hci->master.dev,
+			"IBI for unknown device %#x\n", ibi_addr);
+		goto done;
+	}
+
+	dev_data = i3c_dev_get_master_data(dev);
+	dev_ibi = dev_data->ibi_data;
+	if (ibi_size > dev_ibi->max_len) {
+		dev_err(&hci->master.dev, "IBI payload too big (%d > %d)\n",
+			ibi_size, dev_ibi->max_len);
+		goto done;
+	}
+
+	/*
+	 * This ring model is not suitable for zero-copy processing of IBIs.
+	 * We have the data chunk ring wrap-around to deal with, meaning
+	 * that the payload might span multiple chunks beginning at the
+	 * end of the ring and wrap to the start of the ring. Furthermore
+	 * there is no guarantee that those chunks will be released in order
+	 * and in a timely manner by the upper driver. So let's just copy
+	 * them to a discrete buffer. In practice they're supposed to be
+	 * small anyway.
+	 */
+	slot = i3c_generic_ibi_get_free_slot(dev_ibi->pool);
+	if (!slot) {
+		dev_err(&hci->master.dev, "no free slot for IBI\n");
+		goto done;
+	}
+
+	/* copy first part of the payload */
+	ibi_data_offset = rh->ibi_chunk_sz * rh->ibi_chunk_ptr;
+	ring_ibi_data = rh->ibi_data + ibi_data_offset;
+	ring_ibi_data_dma = rh->ibi_data_dma + ibi_data_offset;
+	first_part = (rh->ibi_chunks_total - rh->ibi_chunk_ptr)
+			* rh->ibi_chunk_sz;
+	if (first_part > ibi_size)
+		first_part = ibi_size;
+	dma_sync_single_for_cpu(&hci->master.dev, ring_ibi_data_dma,
+				first_part, DMA_FROM_DEVICE);
+	memcpy(slot->data, ring_ibi_data, first_part);
+
+	/* copy second part if any */
+	if (ibi_size > first_part) {
+		/* we wrap back to the start and copy remaining data */
+		ring_ibi_data = rh->ibi_data;
+		ring_ibi_data_dma = rh->ibi_data_dma;
+		dma_sync_single_for_cpu(&hci->master.dev, ring_ibi_data_dma,
+					ibi_size - first_part, DMA_FROM_DEVICE);
+		memcpy(slot->data + first_part, ring_ibi_data,
+		       ibi_size - first_part);
+	}
+
+	/* submit it */
+	slot->dev = dev;
+	slot->len = ibi_size;
+	i3c_master_queue_ibi(dev, slot);
+
+done:
+	/* take care to update the ibi dequeue pointer atomically */
+	spin_lock(&rh->lock);
+	op1_val = rh_reg_read(RING_OPERATION1);
+	op1_val &= ~RING_OP1_IBI_DEQ_PTR;
+	op1_val |= FIELD_PREP(RING_OP1_IBI_DEQ_PTR, deq_ptr);
+	rh_reg_write(RING_OPERATION1, op1_val);
+	spin_unlock(&rh->lock);
+
+	/* update the chunk pointer */
+	rh->ibi_chunk_ptr += ibi_chunks;
+	rh->ibi_chunk_ptr %= rh->ibi_chunks_total;
+
+	/* and tell the hardware about freed chunks */
+	rh_reg_write(CHUNK_CONTROL, rh_reg_read(CHUNK_CONTROL) + ibi_chunks);
+}
+
+static bool hci_dma_irq_handler(struct i3c_hci *hci, unsigned int mask)
+{
+	struct hci_rings_data *rings = hci->io_data;
+	unsigned int i;
+	bool handled = false;
+
+	for (i = 0; mask && i < 8; i++) {
+		struct hci_rh_data *rh;
+		u32 status;
+
+		if (!(mask & BIT(i)))
+			continue;
+		mask &= ~BIT(i);
+
+		rh = &rings->headers[i];
+		status = rh_reg_read(INTR_STATUS);
+		DBG("rh%d status: %#x", i, status);
+		if (!status)
+			continue;
+		rh_reg_write(INTR_STATUS, status);
+
+		if (status & INTR_IBI_READY)
+			hci_dma_process_ibi(hci, rh);
+		if (status & (INTR_TRANSFER_COMPLETION | INTR_TRANSFER_ERR))
+			hci_dma_xfer_done(hci, rh);
+		if (status & INTR_RING_OP)
+			complete(&rh->op_done);
+
+		if (status & INTR_TRANSFER_ABORT)
+			dev_notice_ratelimited(&hci->master.dev,
+				"ring %d: Transfer Aborted\n", i);
+		if (status & INTR_WARN_INS_STOP_MODE)
+			dev_warn_ratelimited(&hci->master.dev,
+				"ring %d: Inserted Stop on Mode Change\n", i);
+		if (status & INTR_IBI_RING_FULL)
+			dev_err_ratelimited(&hci->master.dev,
+				"ring %d: IBI Ring Full Condition\n", i);
+
+		handled = true;
+	}
+
+	return handled;
+}
+
+const struct hci_io_ops mipi_i3c_hci_dma = {
+	.init			= hci_dma_init,
+	.cleanup		= hci_dma_cleanup,
+	.queue_xfer		= hci_dma_queue_xfer,
+	.dequeue_xfer		= hci_dma_dequeue_xfer,
+	.irq_handler		= hci_dma_irq_handler,
+	.request_ibi		= hci_dma_request_ibi,
+	.free_ibi		= hci_dma_free_ibi,
+	.recycle_ibi_slot	= hci_dma_recycle_ibi_slot,
+};
diff --git a/drivers/i3c/master/mipi-i3c-hci/ext_caps.c b/drivers/i3c/master/mipi-i3c-hci/ext_caps.c
new file mode 100644
index 000000000000..2e9b23efdc45
--- /dev/null
+++ b/drivers/i3c/master/mipi-i3c-hci/ext_caps.c
@@ -0,0 +1,308 @@
+// SPDX-License-Identifier: BSD-3-Clause
+/*
+ * Copyright (c) 2020, MIPI Alliance, Inc.
+ *
+ * Author: Nicolas Pitre <npitre@baylibre.com>
+ */
+
+#include <linux/bitfield.h>
+#include <linux/device.h>
+#include <linux/errno.h>
+#include <linux/i3c/master.h>
+#include <linux/kernel.h>
+#include <linux/io.h>
+
+#include "hci.h"
+#include "ext_caps.h"
+#include "xfer_mode_rate.h"
+
+
+/* Extended Capability Header */
+#define CAP_HEADER_LENGTH		GENMASK(23, 8)
+#define CAP_HEADER_ID			GENMASK(7, 0)
+
+static int hci_extcap_hardware_id(struct i3c_hci *hci, void __iomem *base)
+{
+	hci->vendor_mipi_id	= readl(base + 0x04);
+	hci->vendor_version_id	= readl(base + 0x08);
+	hci->vendor_product_id	= readl(base + 0x0c);
+
+	dev_info(&hci->master.dev, "vendor MIPI ID: %#x\n", hci->vendor_mipi_id);
+	dev_info(&hci->master.dev, "vendor version ID: %#x\n", hci->vendor_version_id);
+	dev_info(&hci->master.dev, "vendor product ID: %#x\n", hci->vendor_product_id);
+
+	/* ought to go in a table if this grows too much */
+	switch (hci->vendor_mipi_id) {
+	case MIPI_VENDOR_NXP:
+		hci->quirks |= HCI_QUIRK_RAW_CCC;
+		DBG("raw CCC quirks set");
+		break;
+	}
+
+	return 0;
+}
+
+static int hci_extcap_master_config(struct i3c_hci *hci, void __iomem *base)
+{
+	u32 master_config = readl(base + 0x04);
+	unsigned int operation_mode = FIELD_GET(GENMASK(5, 4), master_config);
+	static const char * const functionality[] = {
+		"(unknown)", "master only", "target only",
+		"primary/secondary master" };
+	dev_info(&hci->master.dev, "operation mode: %s\n", functionality[operation_mode]);
+	if (operation_mode & 0x1)
+		return 0;
+	dev_err(&hci->master.dev, "only master mode is currently supported\n");
+	return -EOPNOTSUPP;
+}
+
+static int hci_extcap_multi_bus(struct i3c_hci *hci, void __iomem *base)
+{
+	u32 bus_instance = readl(base + 0x04);
+	unsigned int count = FIELD_GET(GENMASK(3, 0), bus_instance);
+
+	dev_info(&hci->master.dev, "%d bus instances\n", count);
+	return 0;
+}
+
+static int hci_extcap_xfer_modes(struct i3c_hci *hci, void __iomem *base)
+{
+	u32 header = readl(base);
+	u32 entries = FIELD_GET(CAP_HEADER_LENGTH, header) - 1;
+	unsigned int index;
+
+	dev_info(&hci->master.dev, "transfer mode table has %d entries\n",
+		 entries);
+	base += 4;  /* skip header */
+	for (index = 0; index < entries; index++) {
+		u32 mode_entry = readl(base);
+
+		DBG("mode %d: 0x%08x", index, mode_entry);
+		/* TODO: will be needed when I3C core does more than SDR */
+		base += 4;
+	}
+
+	return 0;
+}
+
+static int hci_extcap_xfer_rates(struct i3c_hci *hci, void __iomem *base)
+{
+	u32 header = readl(base);
+	u32 entries = FIELD_GET(CAP_HEADER_LENGTH, header) - 1;
+	u32 rate_entry;
+	unsigned int index, rate, rate_id, mode_id;
+
+	base += 4;  /* skip header */
+
+	dev_info(&hci->master.dev, "available data rates:\n");
+	for (index = 0; index < entries; index++) {
+		rate_entry = readl(base);
+		DBG("entry %d: 0x%08x", index, rate_entry);
+		rate = FIELD_GET(XFERRATE_ACTUAL_RATE_KHZ, rate_entry);
+		rate_id = FIELD_GET(XFERRATE_RATE_ID, rate_entry);
+		mode_id = FIELD_GET(XFERRATE_MODE_ID, rate_entry);
+		dev_info(&hci->master.dev, "rate %d for %s = %d kHz\n",
+			 rate_id,
+			 mode_id == XFERRATE_MODE_I3C ? "I3C" :
+			 mode_id == XFERRATE_MODE_I2C ? "I2C" :
+			 "unknown mode",
+			 rate);
+		base += 4;
+	}
+
+	return 0;
+}
+
+static int hci_extcap_auto_command(struct i3c_hci *hci, void __iomem *base)
+{
+	u32 autocmd_ext_caps = readl(base + 0x04);
+	unsigned int max_count = FIELD_GET(GENMASK(3, 0), autocmd_ext_caps);
+	u32 autocmd_ext_config = readl(base + 0x08);
+	unsigned int count = FIELD_GET(GENMASK(3, 0), autocmd_ext_config);
+
+	dev_info(&hci->master.dev, "%d/%d active auto-command entries\n",
+		 count, max_count);
+	/* remember auto-command register location for later use */
+	hci->AUTOCMD_regs = base;
+	return 0;
+}
+
+static int hci_extcap_debug(struct i3c_hci *hci, void __iomem *base)
+{
+	dev_info(&hci->master.dev, "debug registers present\n");
+	hci->DEBUG_regs = base;
+	return 0;
+}
+
+static int hci_extcap_scheduled_cmd(struct i3c_hci *hci, void __iomem *base)
+{
+	dev_info(&hci->master.dev, "scheduled commands available\n");
+	/* hci->schedcmd_regs = base; */
+	return 0;
+}
+
+static int hci_extcap_non_curr_master(struct i3c_hci *hci, void __iomem *base)
+{
+	dev_info(&hci->master.dev, "Non-Current Master support available\n");
+	/* hci->NCM_regs = base; */
+	return 0;
+}
+
+static int hci_extcap_ccc_resp_conf(struct i3c_hci *hci, void __iomem *base)
+{
+	dev_info(&hci->master.dev, "CCC Response Configuration available\n");
+	return 0;
+}
+
+static int hci_extcap_global_DAT(struct i3c_hci *hci, void __iomem *base)
+{
+	dev_info(&hci->master.dev, "Global DAT available\n");
+	return 0;
+}
+
+static int hci_extcap_multilane(struct i3c_hci *hci, void __iomem *base)
+{
+	dev_info(&hci->master.dev, "Master Multi-Lane support available\n");
+	return 0;
+}
+
+static int hci_extcap_ncm_multilane(struct i3c_hci *hci, void __iomem *base)
+{
+	dev_info(&hci->master.dev, "NCM Multi-Lane support available\n");
+	return 0;
+}
+
+struct hci_ext_caps {
+	u8  id;
+	u16 min_length;
+	int (*parser)(struct i3c_hci *hci, void __iomem *base);
+};
+
+#define EXT_CAP(_id, _highest_mandatory_reg_offset, _parser) \
+	{ .id = (_id), .parser = (_parser), \
+	  .min_length = (_highest_mandatory_reg_offset)/4 + 1 }
+
+static const struct hci_ext_caps ext_capabilities[] = {
+	EXT_CAP(0x01, 0x0c, hci_extcap_hardware_id),
+	EXT_CAP(0x02, 0x04, hci_extcap_master_config),
+	EXT_CAP(0x03, 0x04, hci_extcap_multi_bus),
+	EXT_CAP(0x04, 0x24, hci_extcap_xfer_modes),
+	EXT_CAP(0x05, 0x08, hci_extcap_auto_command),
+	EXT_CAP(0x08, 0x40, hci_extcap_xfer_rates),
+	EXT_CAP(0x0c, 0x10, hci_extcap_debug),
+	EXT_CAP(0x0d, 0x0c, hci_extcap_scheduled_cmd),
+	EXT_CAP(0x0e, 0x80, hci_extcap_non_curr_master), /* TODO confirm size */
+	EXT_CAP(0x0f, 0x04, hci_extcap_ccc_resp_conf),
+	EXT_CAP(0x10, 0x08, hci_extcap_global_DAT),
+	EXT_CAP(0x9d, 0x04,	hci_extcap_multilane),
+	EXT_CAP(0x9e, 0x04, hci_extcap_ncm_multilane),
+};
+
+static int hci_extcap_vendor_NXP(struct i3c_hci *hci, void __iomem *base)
+{
+	hci->vendor_data = (__force void *)base;
+	dev_info(&hci->master.dev, "Build Date Info = %#x\n", readl(base + 1*4));
+	/* reset the FPGA */
+	writel(0xdeadbeef, base + 1*4);
+	return 0;
+}
+
+struct hci_ext_cap_vendor_specific {
+	u32 vendor;
+	u8  cap;
+	u16 min_length;
+	int (*parser)(struct i3c_hci *hci, void __iomem *base);
+};
+
+#define EXT_CAP_VENDOR(_vendor, _cap, _highest_mandatory_reg_offset) \
+	{ .vendor = (MIPI_VENDOR_##_vendor), .cap = (_cap), \
+	  .parser = (hci_extcap_vendor_##_vendor), \
+	  .min_length = (_highest_mandatory_reg_offset)/4 + 1 }
+
+static const struct hci_ext_cap_vendor_specific vendor_ext_caps[] = {
+	EXT_CAP_VENDOR(NXP, 0xc0, 0x20),
+};
+
+static int hci_extcap_vendor_specific(struct i3c_hci *hci, void __iomem *base,
+				      u32 cap_id, u32 cap_length)
+{
+	const struct hci_ext_cap_vendor_specific *vendor_cap_entry;
+	int i;
+
+	vendor_cap_entry = NULL;
+	for (i = 0; i < ARRAY_SIZE(vendor_ext_caps); i++) {
+		if (vendor_ext_caps[i].vendor == hci->vendor_mipi_id &&
+		    vendor_ext_caps[i].cap == cap_id) {
+			vendor_cap_entry = &vendor_ext_caps[i];
+			break;
+		}
+	}
+
+	if (!vendor_cap_entry) {
+		dev_notice(&hci->master.dev,
+			   "unknown ext_cap 0x%02x for vendor 0x%02x\n",
+			   cap_id, hci->vendor_mipi_id);
+		return 0;
+	}
+	if (cap_length < vendor_cap_entry->min_length) {
+		dev_err(&hci->master.dev,
+			"ext_cap 0x%02x has size %d (expecting >= %d)\n",
+			cap_id, cap_length, vendor_cap_entry->min_length);
+		return -EINVAL;
+	}
+	return vendor_cap_entry->parser(hci, base);
+}
+
+int i3c_hci_parse_ext_caps(struct i3c_hci *hci)
+{
+	void __iomem *curr_cap = hci->EXTCAPS_regs;
+	void __iomem *end = curr_cap + 0x1000; /* some arbitrary limit */
+	u32 cap_header, cap_id, cap_length;
+	const struct hci_ext_caps *cap_entry;
+	int i, err = 0;
+
+	if (!curr_cap)
+		return 0;
+
+	for (; !err && curr_cap < end; curr_cap += cap_length * 4) {
+		cap_header = readl(curr_cap);
+		cap_id = FIELD_GET(CAP_HEADER_ID, cap_header);
+		cap_length = FIELD_GET(CAP_HEADER_LENGTH, cap_header);
+		DBG("id=0x%02x length=%d", cap_id, cap_length);
+		if (!cap_length)
+			break;
+		if (curr_cap + cap_length * 4 >= end) {
+			dev_err(&hci->master.dev,
+				"ext_cap 0x%02x has size %d (too big)\n",
+				cap_id, cap_length);
+			err = -EINVAL;
+			break;
+		}
+
+		if (cap_id >= 0xc0 && cap_id <= 0xcf) {
+			err = hci_extcap_vendor_specific(hci, curr_cap,
+							 cap_id, cap_length);
+			continue;
+		}
+
+		cap_entry = NULL;
+		for (i = 0; i < ARRAY_SIZE(ext_capabilities); i++) {
+			if (ext_capabilities[i].id == cap_id) {
+				cap_entry = &ext_capabilities[i];
+				break;
+			}
+		}
+		if (!cap_entry) {
+			dev_notice(&hci->master.dev,
+				   "unknown ext_cap 0x%02x\n", cap_id);
+		} else if (cap_length < cap_entry->min_length) {
+			dev_err(&hci->master.dev,
+				"ext_cap 0x%02x has size %d (expecting >= %d)\n",
+				cap_id, cap_length, cap_entry->min_length);
+			err = -EINVAL;
+		} else {
+			err = cap_entry->parser(hci, curr_cap);
+		}
+	}
+	return err;
+}
diff --git a/drivers/i3c/master/mipi-i3c-hci/ext_caps.h b/drivers/i3c/master/mipi-i3c-hci/ext_caps.h
new file mode 100644
index 000000000000..9df17822fdb4
--- /dev/null
+++ b/drivers/i3c/master/mipi-i3c-hci/ext_caps.h
@@ -0,0 +1,19 @@
+/* SPDX-License-Identifier: BSD-3-Clause */
+/*
+ * Copyright (c) 2020, MIPI Alliance, Inc.
+ *
+ * Author: Nicolas Pitre <npitre@baylibre.com>
+ *
+ * Extended Capability Definitions
+ */
+
+#ifndef EXTCAPS_H
+#define EXTCAPS_H
+
+/* MIPI vendor IDs */
+#define MIPI_VENDOR_NXP			0x11b
+
+
+int i3c_hci_parse_ext_caps(struct i3c_hci *hci);
+
+#endif
diff --git a/drivers/i3c/master/mipi-i3c-hci/hci.h b/drivers/i3c/master/mipi-i3c-hci/hci.h
new file mode 100644
index 000000000000..f109923f6c3f
--- /dev/null
+++ b/drivers/i3c/master/mipi-i3c-hci/hci.h
@@ -0,0 +1,144 @@
+/* SPDX-License-Identifier: BSD-3-Clause */
+/*
+ * Copyright (c) 2020, MIPI Alliance, Inc.
+ *
+ * Author: Nicolas Pitre <npitre@baylibre.com>
+ *
+ * Common HCI stuff
+ */
+
+#ifndef HCI_H
+#define HCI_H
+
+
+/* Handy logging macro to save on line length */
+#define DBG(x, ...) pr_devel("%s: " x "\n", __func__, ##__VA_ARGS__)
+
+/* 32-bit word aware bit and mask macros */
+#define W0_MASK(h, l)  GENMASK((h) - 0,  (l) - 0)
+#define W1_MASK(h, l)  GENMASK((h) - 32, (l) - 32)
+#define W2_MASK(h, l)  GENMASK((h) - 64, (l) - 64)
+#define W3_MASK(h, l)  GENMASK((h) - 96, (l) - 96)
+
+/* Same for single bit macros (trailing _ to align with W*_MASK width) */
+#define W0_BIT_(x)  BIT((x) - 0)
+#define W1_BIT_(x)  BIT((x) - 32)
+#define W2_BIT_(x)  BIT((x) - 64)
+#define W3_BIT_(x)  BIT((x) - 96)
+
+
+struct hci_cmd_ops;
+
+/* Our main structure */
+struct i3c_hci {
+	struct i3c_master_controller master;
+	void __iomem *base_regs;
+	void __iomem *DAT_regs;
+	void __iomem *DCT_regs;
+	void __iomem *RHS_regs;
+	void __iomem *PIO_regs;
+	void __iomem *EXTCAPS_regs;
+	void __iomem *AUTOCMD_regs;
+	void __iomem *DEBUG_regs;
+	const struct hci_io_ops *io;
+	void *io_data;
+	const struct hci_cmd_ops *cmd;
+	atomic_t next_cmd_tid;
+	u32 caps;
+	unsigned int quirks;
+	unsigned int DAT_entries;
+	unsigned int DAT_entry_size;
+	void *DAT_data;
+	unsigned int DCT_entries;
+	unsigned int DCT_entry_size;
+	u8 version_major;
+	u8 version_minor;
+	u8 revision;
+	u32 vendor_mipi_id;
+	u32 vendor_version_id;
+	u32 vendor_product_id;
+	void *vendor_data;
+};
+
+
+/*
+ * Structure to represent a master initiated transfer.
+ * The rnw, data and data_len fields must be initialized before calling any
+ * hci->cmd->*() method. The cmd method will initialize cmd_desc[] and
+ * possibly modify (clear) the data field. Then xfer->cmd_desc[0] can
+ * be augmented with CMD_0_ROC and/or CMD_0_TOC.
+ * The completion field needs to be initialized before queueing with
+ * hci->io->queue_xfer(), and requires CMD_0_ROC to be set.
+ */
+struct hci_xfer {
+	u32 cmd_desc[4];
+	u32 response;
+	bool rnw;
+	void *data;
+	unsigned int data_len;
+	unsigned int cmd_tid;
+	struct completion *completion;
+	union {
+		struct {
+			/* PIO specific */
+			struct hci_xfer *next_xfer;
+			struct hci_xfer *next_data;
+			struct hci_xfer *next_resp;
+			unsigned int data_left;
+			u32 data_word_before_partial;
+		};
+		struct {
+			/* DMA specific */
+			dma_addr_t data_dma;
+			int ring_number;
+			int ring_entry;
+		};
+	};
+};
+
+static inline struct hci_xfer *hci_alloc_xfer(unsigned int n)
+{
+	return kcalloc(n, sizeof(struct hci_xfer), GFP_KERNEL);
+}
+
+static inline void hci_free_xfer(struct hci_xfer *xfer, unsigned int n)
+{
+	kfree(xfer);
+}
+
+
+/* This abstracts PIO vs DMA operations */
+struct hci_io_ops {
+	bool (*irq_handler)(struct i3c_hci *hci, unsigned int mask);
+	int (*queue_xfer)(struct i3c_hci *hci, struct hci_xfer *xfer, int n);
+	bool (*dequeue_xfer)(struct i3c_hci *hci, struct hci_xfer *xfer, int n);
+	int (*request_ibi)(struct i3c_hci *hci, struct i3c_dev_desc *dev,
+			   const struct i3c_ibi_setup *req);
+	void (*free_ibi)(struct i3c_hci *hci, struct i3c_dev_desc *dev);
+	void (*recycle_ibi_slot)(struct i3c_hci *hci, struct i3c_dev_desc *dev,
+				struct i3c_ibi_slot *slot);
+	int (*init)(struct i3c_hci *hci);
+	void (*cleanup)(struct i3c_hci *hci);
+};
+
+extern const struct hci_io_ops mipi_i3c_hci_pio;
+extern const struct hci_io_ops mipi_i3c_hci_dma;
+
+
+/* Our per device master private data */
+struct i3c_hci_dev_data {
+	int dat_idx;
+	void *ibi_data;
+};
+
+
+/* list of quirks */
+#define HCI_QUIRK_RAW_CCC	BIT(1)	/* CCC framing must be explicit */
+
+
+/* global functions */
+void mipi_i3c_hci_resume(struct i3c_hci *hci);
+void mipi_i3c_hci_pio_reset(struct i3c_hci *hci);
+void mipi_i3c_hci_dct_index_reset(struct i3c_hci *hci);
+
+#endif
diff --git a/drivers/i3c/master/mipi-i3c-hci/ibi.h b/drivers/i3c/master/mipi-i3c-hci/ibi.h
new file mode 100644
index 000000000000..e1f98e264da0
--- /dev/null
+++ b/drivers/i3c/master/mipi-i3c-hci/ibi.h
@@ -0,0 +1,42 @@
+/* SPDX-License-Identifier: BSD-3-Clause */
+/*
+ * Copyright (c) 2020, MIPI Alliance, Inc.
+ *
+ * Author: Nicolas Pitre <npitre@baylibre.com>
+ *
+ * Common IBI related stuff
+ */
+
+#ifndef IBI_H
+#define IBI_H
+
+/*
+ * IBI Status Descriptor bits
+ */
+#define IBI_STS				BIT(31)
+#define IBI_ERROR			BIT(30)
+#define IBI_STATUS_TYPE			BIT(29)
+#define IBI_HW_CONTEXT			GENMASK(28, 26)
+#define IBI_TS				BIT(25)
+#define IBI_LAST_STATUS			BIT(24)
+#define IBI_CHUNKS			GENMASK(23, 16)
+#define IBI_ID				GENMASK(15, 8)
+#define IBI_TARGET_ADDR			GENMASK(15, 9)
+#define IBI_TARGET_RNW			BIT(8)
+#define IBI_DATA_LENGTH			GENMASK(7, 0)
+
+/*  handy helpers */
+static inline struct i3c_dev_desc *
+i3c_hci_addr_to_dev(struct i3c_hci *hci, unsigned int addr)
+{
+	struct i3c_bus *bus = i3c_master_get_bus(&hci->master);
+	struct i3c_dev_desc *dev;
+
+	i3c_bus_for_each_i3cdev(bus, dev) {
+		if (dev->info.dyn_addr == addr)
+			return dev;
+	}
+	return NULL;
+}
+
+#endif
diff --git a/drivers/i3c/master/mipi-i3c-hci/pio.c b/drivers/i3c/master/mipi-i3c-hci/pio.c
new file mode 100644
index 000000000000..d0272aa93599
--- /dev/null
+++ b/drivers/i3c/master/mipi-i3c-hci/pio.c
@@ -0,0 +1,1041 @@
+// SPDX-License-Identifier: BSD-3-Clause
+/*
+ * Copyright (c) 2020, MIPI Alliance, Inc.
+ *
+ * Author: Nicolas Pitre <npitre@baylibre.com>
+ */
+
+#include <linux/bitfield.h>
+#include <linux/device.h>
+#include <linux/errno.h>
+#include <linux/i3c/master.h>
+#include <linux/io.h>
+
+#include "hci.h"
+#include "cmd.h"
+#include "ibi.h"
+
+
+/*
+ * PIO Access Area
+ */
+
+#define pio_reg_read(r)		readl(hci->PIO_regs + (PIO_##r))
+#define pio_reg_write(r, v)	writel(v, hci->PIO_regs + (PIO_##r))
+
+#define PIO_COMMAND_QUEUE_PORT		0x00
+#define PIO_RESPONSE_QUEUE_PORT		0x04
+#define PIO_XFER_DATA_PORT		0x08
+#define PIO_IBI_PORT			0x0c
+
+#define PIO_QUEUE_THLD_CTRL		0x10
+#define QUEUE_IBI_STATUS_THLD		GENMASK(31, 24)
+#define QUEUE_IBI_DATA_THLD		GENMASK(23, 16)
+#define QUEUE_RESP_BUF_THLD		GENMASK(15, 8)
+#define QUEUE_CMD_EMPTY_BUF_THLD	GENMASK(7, 0)
+
+#define PIO_DATA_BUFFER_THLD_CTRL	0x14
+#define DATA_RX_START_THLD		GENMASK(26, 24)
+#define DATA_TX_START_THLD		GENMASK(18, 16)
+#define DATA_RX_BUF_THLD		GENMASK(10, 8)
+#define DATA_TX_BUF_THLD		GENMASK(2, 0)
+
+#define PIO_QUEUE_SIZE			0x18
+#define TX_DATA_BUFFER_SIZE		GENMASK(31, 24)
+#define RX_DATA_BUFFER_SIZE		GENMASK(23, 16)
+#define IBI_STATUS_SIZE			GENMASK(15, 8)
+#define CR_QUEUE_SIZE			GENMASK(7, 0)
+
+#define PIO_INTR_STATUS			0x20
+#define PIO_INTR_STATUS_ENABLE		0x24
+#define PIO_INTR_SIGNAL_ENABLE		0x28
+#define PIO_INTR_FORCE			0x2c
+#define STAT_TRANSFER_BLOCKED		BIT(25)
+#define STAT_PERR_RESP_UFLOW		BIT(24)
+#define STAT_PERR_CMD_OFLOW		BIT(23)
+#define STAT_PERR_IBI_UFLOW		BIT(22)
+#define STAT_PERR_RX_UFLOW		BIT(21)
+#define STAT_PERR_TX_OFLOW		BIT(20)
+#define STAT_ERR_RESP_QUEUE_FULL	BIT(19)
+#define STAT_WARN_RESP_QUEUE_FULL	BIT(18)
+#define STAT_ERR_IBI_QUEUE_FULL		BIT(17)
+#define STAT_WARN_IBI_QUEUE_FULL	BIT(16)
+#define STAT_ERR_RX_DATA_FULL		BIT(15)
+#define STAT_WARN_RX_DATA_FULL		BIT(14)
+#define STAT_ERR_TX_DATA_EMPTY		BIT(13)
+#define STAT_WARN_TX_DATA_EMPTY		BIT(12)
+#define STAT_TRANSFER_ERR		BIT(9)
+#define STAT_WARN_INS_STOP_MODE		BIT(7)
+#define STAT_TRANSFER_ABORT		BIT(5)
+#define STAT_RESP_READY			BIT(4)
+#define STAT_CMD_QUEUE_READY		BIT(3)
+#define STAT_IBI_STATUS_THLD		BIT(2)
+#define STAT_RX_THLD			BIT(1)
+#define STAT_TX_THLD			BIT(0)
+
+#define PIO_QUEUE_CUR_STATUS		0x38
+#define CUR_IBI_Q_LEVEL			GENMASK(28, 20)
+#define CUR_RESP_Q_LEVEL		GENMASK(18, 10)
+#define CUR_CMD_Q_EMPTY_LEVEL		GENMASK(8, 0)
+
+#define PIO_DATA_BUFFER_CUR_STATUS	0x3c
+#define CUR_RX_BUF_LVL			GENMASK(26, 16)
+#define CUR_TX_BUF_LVL			GENMASK(10, 0)
+
+/*
+ * Handy status bit combinations
+ */
+
+#define STAT_LATENCY_WARNINGS		(STAT_WARN_RESP_QUEUE_FULL | \
+					 STAT_WARN_IBI_QUEUE_FULL | \
+					 STAT_WARN_RX_DATA_FULL | \
+					 STAT_WARN_TX_DATA_EMPTY | \
+					 STAT_WARN_INS_STOP_MODE)
+
+#define STAT_LATENCY_ERRORS		(STAT_ERR_RESP_QUEUE_FULL | \
+					 STAT_ERR_IBI_QUEUE_FULL | \
+					 STAT_ERR_RX_DATA_FULL | \
+					 STAT_ERR_TX_DATA_EMPTY)
+
+#define STAT_PROG_ERRORS		(STAT_TRANSFER_BLOCKED | \
+					 STAT_PERR_RESP_UFLOW | \
+					 STAT_PERR_CMD_OFLOW | \
+					 STAT_PERR_IBI_UFLOW | \
+					 STAT_PERR_RX_UFLOW | \
+					 STAT_PERR_TX_OFLOW)
+
+#define STAT_ALL_ERRORS			(STAT_TRANSFER_ABORT | \
+					 STAT_TRANSFER_ERR | \
+					 STAT_LATENCY_ERRORS | \
+					 STAT_PROG_ERRORS)
+
+struct hci_pio_dev_ibi_data {
+	struct i3c_generic_ibi_pool *pool;
+	unsigned int max_len;
+};
+
+struct hci_pio_ibi_data {
+	struct i3c_ibi_slot *slot;
+	void *data_ptr;
+	unsigned int addr;
+	unsigned int seg_len, seg_cnt;
+	unsigned int max_len;
+	bool last_seg;
+};
+
+struct hci_pio_data {
+	spinlock_t lock;
+	struct hci_xfer *curr_xfer, *xfer_queue;
+	struct hci_xfer *curr_rx, *rx_queue;
+	struct hci_xfer *curr_tx, *tx_queue;
+	struct hci_xfer *curr_resp, *resp_queue;
+	struct hci_pio_ibi_data ibi;
+	unsigned int rx_thresh_size, tx_thresh_size;
+	unsigned int max_ibi_thresh;
+	u32 reg_queue_thresh;
+	u32 enabled_irqs;
+};
+
+static int hci_pio_init(struct i3c_hci *hci)
+{
+	struct hci_pio_data *pio;
+	u32 val, size_val, rx_thresh, tx_thresh, ibi_val;
+
+	pio = kzalloc(sizeof(*pio), GFP_KERNEL);
+	if (!pio)
+		return -ENOMEM;
+
+	hci->io_data = pio;
+	spin_lock_init(&pio->lock);
+
+	size_val = pio_reg_read(QUEUE_SIZE);
+	dev_info(&hci->master.dev, "CMD/RESP FIFO = %ld entries\n",
+		 FIELD_GET(CR_QUEUE_SIZE, size_val));
+	dev_info(&hci->master.dev, "IBI FIFO = %ld bytes\n",
+		 4 * FIELD_GET(IBI_STATUS_SIZE, size_val));
+	dev_info(&hci->master.dev, "RX data FIFO = %d bytes\n",
+		 4 * (2 << FIELD_GET(RX_DATA_BUFFER_SIZE, size_val)));
+	dev_info(&hci->master.dev, "TX data FIFO = %d bytes\n",
+		 4 * (2 << FIELD_GET(TX_DATA_BUFFER_SIZE, size_val)));
+
+	/*
+	 * Let's initialize data thresholds to half of the actual FIFO size.
+	 * The start thresholds aren't used (set to 0) as the FIFO is always
+	 * serviced before the corresponding command is queued.
+	 */
+	rx_thresh = FIELD_GET(RX_DATA_BUFFER_SIZE, size_val);
+	tx_thresh = FIELD_GET(TX_DATA_BUFFER_SIZE, size_val);
+	if (hci->version_major == 1) {
+		/* those are expressed as 2^[n+1), so just sub 1 if not 0 */
+		if (rx_thresh)
+			rx_thresh -= 1;
+		if (tx_thresh)
+			tx_thresh -= 1;
+		pio->rx_thresh_size = 2 << rx_thresh;
+		pio->tx_thresh_size = 2 << tx_thresh;
+	} else {
+		/* size is 2^(n+1) and threshold is 2^n i.e. already halved */
+		pio->rx_thresh_size = 1 << rx_thresh;
+		pio->tx_thresh_size = 1 << tx_thresh;
+	}
+	val = FIELD_PREP(DATA_RX_BUF_THLD,   rx_thresh) |
+	      FIELD_PREP(DATA_TX_BUF_THLD,   tx_thresh);
+	pio_reg_write(DATA_BUFFER_THLD_CTRL, val);
+
+	/*
+	 * Let's raise an interrupt as soon as there is one free cmd slot
+	 * or one available response or IBI. For IBI data let's use half the
+	 * IBI queue size within allowed bounds.
+	 */
+	ibi_val = FIELD_GET(IBI_STATUS_SIZE, size_val);
+	pio->max_ibi_thresh = clamp_val(ibi_val/2, 1, 63);
+	val = FIELD_PREP(QUEUE_IBI_STATUS_THLD, 1) |
+	      FIELD_PREP(QUEUE_IBI_DATA_THLD, pio->max_ibi_thresh) |
+	      FIELD_PREP(QUEUE_RESP_BUF_THLD, 1) |
+	      FIELD_PREP(QUEUE_CMD_EMPTY_BUF_THLD, 1);
+	pio_reg_write(QUEUE_THLD_CTRL, val);
+	pio->reg_queue_thresh = val;
+
+	/* Disable all IRQs but allow all status bits */
+	pio_reg_write(INTR_SIGNAL_ENABLE, 0x0);
+	pio_reg_write(INTR_STATUS_ENABLE, 0xffffffff);
+
+	/* Always accept error interrupts (will be activated on first xfer) */
+	pio->enabled_irqs = STAT_ALL_ERRORS;
+
+	return 0;
+}
+
+static void hci_pio_cleanup(struct i3c_hci *hci)
+{
+	struct hci_pio_data *pio = hci->io_data;
+
+	pio_reg_write(INTR_SIGNAL_ENABLE, 0x0);
+
+	if (pio) {
+		DBG("status = %#x/%#x",
+		    pio_reg_read(INTR_STATUS), pio_reg_read(INTR_SIGNAL_ENABLE));
+		BUG_ON(pio->curr_xfer);
+		BUG_ON(pio->curr_rx);
+		BUG_ON(pio->curr_tx);
+		BUG_ON(pio->curr_resp);
+		kfree(pio);
+		hci->io_data = NULL;
+	}
+}
+
+static void hci_pio_write_cmd(struct i3c_hci *hci, struct hci_xfer *xfer)
+{
+	DBG("cmd_desc[%d] = 0x%08x", 0, xfer->cmd_desc[0]);
+	DBG("cmd_desc[%d] = 0x%08x", 1, xfer->cmd_desc[1]);
+	pio_reg_write(COMMAND_QUEUE_PORT, xfer->cmd_desc[0]);
+	pio_reg_write(COMMAND_QUEUE_PORT, xfer->cmd_desc[1]);
+	if (hci->cmd == &mipi_i3c_hci_cmd_v2) {
+		DBG("cmd_desc[%d] = 0x%08x", 2, xfer->cmd_desc[2]);
+		DBG("cmd_desc[%d] = 0x%08x", 3, xfer->cmd_desc[3]);
+		pio_reg_write(COMMAND_QUEUE_PORT, xfer->cmd_desc[2]);
+		pio_reg_write(COMMAND_QUEUE_PORT, xfer->cmd_desc[3]);
+	}
+}
+
+static bool hci_pio_do_rx(struct i3c_hci *hci, struct hci_pio_data *pio)
+{
+	struct hci_xfer *xfer = pio->curr_rx;
+	unsigned int nr_words;
+	u32 *p;
+
+	p = xfer->data;
+	p += (xfer->data_len - xfer->data_left) / 4;
+
+	while (xfer->data_left >= 4) {
+		/* bail out if FIFO hasn't reached the threshold value yet */
+		if (!(pio_reg_read(INTR_STATUS) & STAT_RX_THLD))
+			return false;
+		nr_words = min(xfer->data_left / 4, pio->rx_thresh_size);
+		/* extract data from FIFO */
+		xfer->data_left -= nr_words * 4;
+		DBG("now %d left %d", nr_words * 4, xfer->data_left);
+		while (nr_words--)
+			*p++ = pio_reg_read(XFER_DATA_PORT);
+	}
+
+	/* trailing data is retrieved upon response reception */
+	return !xfer->data_left;
+}
+
+static void hci_pio_do_trailing_rx(struct i3c_hci *hci,
+				   struct hci_pio_data *pio, unsigned int count)
+{
+	struct hci_xfer *xfer = pio->curr_rx;
+	u32 *p;
+
+	DBG("%d remaining", count);
+
+	p = xfer->data;
+	p += (xfer->data_len - xfer->data_left) / 4;
+
+	if (count >= 4) {
+		unsigned int nr_words = count / 4;
+		/* extract data from FIFO */
+		xfer->data_left -= nr_words * 4;
+		DBG("now %d left %d", nr_words * 4, xfer->data_left);
+		while (nr_words--)
+			*p++ = pio_reg_read(XFER_DATA_PORT);
+	}
+
+	count &= 3;
+	if (count) {
+		/*
+		 * There are trailing bytes in the last word.
+		 * Fetch it and extract bytes in an endian independent way.
+		 * Unlike the TX case, we must not write memory past the
+		 * end of the destination buffer.
+		 */
+		u8 *p_byte = (u8 *)p;
+		u32 data = pio_reg_read(XFER_DATA_PORT);
+
+		xfer->data_word_before_partial = data;
+		xfer->data_left -= count;
+		data = (__force u32) cpu_to_le32(data);
+		while (count--) {
+			*p_byte++ = data;
+			data >>= 8;
+		}
+	}
+}
+
+static bool hci_pio_do_tx(struct i3c_hci *hci, struct hci_pio_data *pio)
+{
+	struct hci_xfer *xfer = pio->curr_tx;
+	unsigned int nr_words;
+	u32 *p;
+
+	p = xfer->data;
+	p += (xfer->data_len - xfer->data_left) / 4;
+
+	while (xfer->data_left >= 4) {
+		/* bail out if FIFO free space is below set threshold */
+		if (!(pio_reg_read(INTR_STATUS) & STAT_TX_THLD))
+			return false;
+		/* we can fill up to that TX threshold */
+		nr_words = min(xfer->data_left / 4, pio->tx_thresh_size);
+		/* push data into the FIFO */
+		xfer->data_left -= nr_words * 4;
+		DBG("now %d left %d", nr_words * 4, xfer->data_left);
+		while (nr_words--)
+			pio_reg_write(XFER_DATA_PORT, *p++);
+	}
+
+	if (xfer->data_left) {
+		/*
+		 * There are trailing bytes to send. We can simply load
+		 * them from memory as a word which will keep those bytes
+		 * in their proper place even on a BE system. This will
+		 * also get some bytes past the actual buffer but no one
+		 * should care as they won't be sent out.
+		 */
+		if (!(pio_reg_read(INTR_STATUS) & STAT_TX_THLD))
+			return false;
+		DBG("trailing %d", xfer->data_left);
+		pio_reg_write(XFER_DATA_PORT, *p);
+		xfer->data_left = 0;
+	}
+
+	return true;
+}
+
+static bool hci_pio_process_rx(struct i3c_hci *hci, struct hci_pio_data *pio)
+{
+	while (pio->curr_rx && hci_pio_do_rx(hci, pio))
+		pio->curr_rx = pio->curr_rx->next_data;
+	return !pio->curr_rx;
+}
+
+static bool hci_pio_process_tx(struct i3c_hci *hci, struct hci_pio_data *pio)
+{
+	while (pio->curr_tx && hci_pio_do_tx(hci, pio))
+		pio->curr_tx = pio->curr_tx->next_data;
+	return !pio->curr_tx;
+}
+
+static void hci_pio_queue_data(struct i3c_hci *hci, struct hci_pio_data *pio)
+{
+	struct hci_xfer *xfer = pio->curr_xfer;
+	struct hci_xfer *prev_queue_tail;
+
+	if (!xfer->data) {
+		xfer->data_len = xfer->data_left = 0;
+		return;
+	}
+
+	if (xfer->rnw) {
+		prev_queue_tail = pio->rx_queue;
+		pio->rx_queue = xfer;
+		if (pio->curr_rx) {
+			prev_queue_tail->next_data = xfer;
+		} else {
+			pio->curr_rx = xfer;
+			if (!hci_pio_process_rx(hci, pio))
+				pio->enabled_irqs |= STAT_RX_THLD;
+		}
+	} else {
+		prev_queue_tail = pio->tx_queue;
+		pio->tx_queue = xfer;
+		if (pio->curr_tx) {
+			prev_queue_tail->next_data = xfer;
+		} else {
+			pio->curr_tx = xfer;
+			if (!hci_pio_process_tx(hci, pio))
+				pio->enabled_irqs |= STAT_TX_THLD;
+		}
+	}
+}
+
+static void hci_pio_push_to_next_rx(struct i3c_hci *hci, struct hci_xfer *xfer,
+				    unsigned int words_to_keep)
+{
+	u32 *from = xfer->data;
+	u32 from_last;
+	unsigned int received, count;
+
+	received = (xfer->data_len - xfer->data_left) / 4;
+	if ((xfer->data_len - xfer->data_left) & 3) {
+		from_last = xfer->data_word_before_partial;
+		received += 1;
+	} else {
+		from_last = from[received];
+	}
+	from += words_to_keep;
+	count = received - words_to_keep;
+
+	while (count) {
+		unsigned int room, left, chunk, bytes_to_move;
+		u32 last_word;
+
+		xfer = xfer->next_data;
+		if (!xfer) {
+			dev_err(&hci->master.dev, "pushing RX data to unexistent xfer\n");
+			return;
+		}
+
+		room = DIV_ROUND_UP(xfer->data_len, 4);
+		left = DIV_ROUND_UP(xfer->data_left, 4);
+		chunk = min(count, room);
+		if (chunk > left) {
+			hci_pio_push_to_next_rx(hci, xfer, chunk - left);
+			left = chunk;
+			xfer->data_left = left * 4;
+		}
+
+		bytes_to_move = xfer->data_len - xfer->data_left;
+		if (bytes_to_move & 3) {
+			/* preserve word  to become partial */
+			u32 *p = xfer->data;
+
+			xfer->data_word_before_partial = p[bytes_to_move / 4];
+		}
+		memmove(xfer->data + chunk, xfer->data, bytes_to_move);
+
+		/* treat last word specially because of partial word issues */
+		chunk -= 1;
+
+		memcpy(xfer->data, from, chunk * 4);
+		xfer->data_left -= chunk * 4;
+		from += chunk;
+		count -= chunk;
+
+		last_word = (count == 1) ? from_last : *from++;
+		if (xfer->data_left < 4) {
+			/*
+			 * Like in hci_pio_do_trailing_rx(), preserve original
+			 * word to be stored partially then store bytes it
+			 * in an endian independent way.
+			 */
+			u8 *p_byte = xfer->data;
+
+			p_byte += chunk * 4;
+			xfer->data_word_before_partial = last_word;
+			last_word = (__force u32) cpu_to_le32(last_word);
+			while (xfer->data_left--) {
+				*p_byte++ = last_word;
+				last_word >>= 8;
+			}
+		} else {
+			u32 *p = xfer->data;
+
+			p[chunk] = last_word;
+			xfer->data_left -= 4;
+		}
+		count--;
+	}
+}
+
+static void hci_pio_err(struct i3c_hci *hci, struct hci_pio_data *pio,
+			u32 status);
+
+static bool hci_pio_process_resp(struct i3c_hci *hci, struct hci_pio_data *pio)
+{
+	while (pio->curr_resp &&
+	       (pio_reg_read(INTR_STATUS) & STAT_RESP_READY)) {
+		struct hci_xfer *xfer = pio->curr_resp;
+		u32 resp = pio_reg_read(RESPONSE_QUEUE_PORT);
+		unsigned int tid = RESP_TID(resp);
+
+		DBG("resp = 0x%08x", resp);
+		if (tid != xfer->cmd_tid) {
+			dev_err(&hci->master.dev,
+				"response tid=%d when expecting %d\n",
+				tid, xfer->cmd_tid);
+			/* let's pretend it is a prog error... any of them  */
+			hci_pio_err(hci, pio, STAT_PROG_ERRORS);
+			return false;
+		}
+		xfer->response = resp;
+
+		if (pio->curr_rx == xfer) {
+			/*
+			 * Response availability implies RX completion.
+			 * Retrieve trailing RX data if any.
+			 * Note that short reads are possible.
+			 */
+			unsigned int received, expected, to_keep;
+
+			received = xfer->data_len - xfer->data_left;
+			expected = RESP_DATA_LENGTH(xfer->response);
+			if (expected > received) {
+				hci_pio_do_trailing_rx(hci, pio,
+						       expected - received);
+			} else if (received > expected) {
+				/* we consumed data meant for next xfer */
+				to_keep = DIV_ROUND_UP(expected, 4);
+				hci_pio_push_to_next_rx(hci, xfer, to_keep);
+			}
+
+			/* then process the RX list pointer */
+			if (hci_pio_process_rx(hci, pio))
+				pio->enabled_irqs &= ~STAT_RX_THLD;
+		}
+
+		/*
+		 * We're about to give back ownership of the xfer structure
+		 * to the waiting instance. Make sure no reference to it
+		 * still exists.
+		 */
+		if (pio->curr_rx == xfer) {
+			DBG("short RX ?");
+			pio->curr_rx = pio->curr_rx->next_data;
+		} else if (pio->curr_tx == xfer) {
+			DBG("short TX ?");
+			pio->curr_tx = pio->curr_tx->next_data;
+		} else if (xfer->data_left) {
+			DBG("PIO xfer count = %d after response",
+			    xfer->data_left);
+		}
+
+		pio->curr_resp = xfer->next_resp;
+		if (xfer->completion)
+			complete(xfer->completion);
+	}
+	return !pio->curr_resp;
+}
+
+static void hci_pio_queue_resp(struct i3c_hci *hci, struct hci_pio_data *pio)
+{
+	struct hci_xfer *xfer = pio->curr_xfer;
+	struct hci_xfer *prev_queue_tail;
+
+	if (!(xfer->cmd_desc[0] & CMD_0_ROC))
+		return;
+
+	prev_queue_tail = pio->resp_queue;
+	pio->resp_queue = xfer;
+	if (pio->curr_resp) {
+		prev_queue_tail->next_resp = xfer;
+	} else {
+		pio->curr_resp = xfer;
+		if (!hci_pio_process_resp(hci, pio))
+			pio->enabled_irqs |= STAT_RESP_READY;
+	}
+}
+
+static bool hci_pio_process_cmd(struct i3c_hci *hci, struct hci_pio_data *pio)
+{
+	while (pio->curr_xfer &&
+	       (pio_reg_read(INTR_STATUS) & STAT_CMD_QUEUE_READY)) {
+		/*
+		 * Always process the data FIFO before sending the command
+		 * so needed TX data or RX space is available upfront.
+		 */
+		hci_pio_queue_data(hci, pio);
+		/*
+		 * Then queue our response request. This will also process
+		 * the response FIFO in case it got suddenly filled up
+		 * with results from previous commands.
+		 */
+		hci_pio_queue_resp(hci, pio);
+		/*
+		 * Finally send the command.
+		 */
+		hci_pio_write_cmd(hci, pio->curr_xfer);
+		/*
+		 * And move on.
+		 */
+		pio->curr_xfer = pio->curr_xfer->next_xfer;
+	}
+	return !pio->curr_xfer;
+}
+
+static int hci_pio_queue_xfer(struct i3c_hci *hci, struct hci_xfer *xfer, int n)
+{
+	struct hci_pio_data *pio = hci->io_data;
+	struct hci_xfer *prev_queue_tail;
+	int i;
+
+	DBG("n = %d", n);
+
+	/* link xfer instances together and initialize data count */
+	for (i = 0; i < n; i++) {
+		xfer[i].next_xfer = (i + 1 < n) ? &xfer[i + 1] : NULL;
+		xfer[i].next_data = NULL;
+		xfer[i].next_resp = NULL;
+		xfer[i].data_left = xfer[i].data_len;
+	}
+
+	spin_lock_irq(&pio->lock);
+	prev_queue_tail = pio->xfer_queue;
+	pio->xfer_queue = &xfer[n - 1];
+	if (pio->curr_xfer) {
+		prev_queue_tail->next_xfer = xfer;
+	} else {
+		pio->curr_xfer = xfer;
+		if (!hci_pio_process_cmd(hci, pio))
+			pio->enabled_irqs |= STAT_CMD_QUEUE_READY;
+		pio_reg_write(INTR_SIGNAL_ENABLE, pio->enabled_irqs);
+		DBG("status = %#x/%#x",
+		    pio_reg_read(INTR_STATUS), pio_reg_read(INTR_SIGNAL_ENABLE));
+	}
+	spin_unlock_irq(&pio->lock);
+	return 0;
+}
+
+static bool hci_pio_dequeue_xfer_common(struct i3c_hci *hci,
+					struct hci_pio_data *pio,
+					struct hci_xfer *xfer, int n)
+{
+	struct hci_xfer *p, **p_prev_next;
+	int i;
+
+	/*
+	 * To safely dequeue a transfer request, it must be either entirely
+	 * processed, or not yet processed at all. If our request tail is
+	 * reachable from either the data or resp list that means the command
+	 * was submitted and not yet completed.
+	 */
+	for (p = pio->curr_resp; p; p = p->next_resp)
+		for (i = 0; i < n; i++)
+			if (p == &xfer[i])
+				goto pio_screwed;
+	for (p = pio->curr_rx; p; p = p->next_data)
+		for (i = 0; i < n; i++)
+			if (p == &xfer[i])
+				goto pio_screwed;
+	for (p = pio->curr_tx; p; p = p->next_data)
+		for (i = 0; i < n; i++)
+			if (p == &xfer[i])
+				goto pio_screwed;
+
+	/*
+	 * The command was completed, or wasn't yet submitted.
+	 * Unlink it from the que if the later.
+	 */
+	p_prev_next = &pio->curr_xfer;
+	for (p = pio->curr_xfer; p; p = p->next_xfer) {
+		if (p == &xfer[0]) {
+			*p_prev_next = xfer[n - 1].next_xfer;
+			break;
+		}
+		p_prev_next = &p->next_xfer;
+	}
+
+	/* return true if we actually unqueued something */
+	return !!p;
+
+pio_screwed:
+	/*
+	 * Life is tough. We must invalidate the hardware state and
+	 * discard everything that is still queued.
+	 */
+	for (p = pio->curr_resp; p; p = p->next_resp) {
+		p->response = FIELD_PREP(RESP_ERR_FIELD, RESP_ERR_HC_TERMINATED);
+		if (p->completion)
+			complete(p->completion);
+	}
+	for (p = pio->curr_xfer; p; p = p->next_xfer) {
+		p->response = FIELD_PREP(RESP_ERR_FIELD, RESP_ERR_HC_TERMINATED);
+		if (p->completion)
+			complete(p->completion);
+	}
+	pio->curr_xfer = pio->curr_rx = pio->curr_tx = pio->curr_resp = NULL;
+
+	return true;
+}
+
+static bool hci_pio_dequeue_xfer(struct i3c_hci *hci, struct hci_xfer *xfer, int n)
+{
+	struct hci_pio_data *pio = hci->io_data;
+	int ret;
+
+	spin_lock_irq(&pio->lock);
+	DBG("n=%d status=%#x/%#x", n,
+	    pio_reg_read(INTR_STATUS), pio_reg_read(INTR_SIGNAL_ENABLE));
+	DBG("main_status = %#x/%#x",
+	    readl(hci->base_regs + 0x20), readl(hci->base_regs + 0x28));
+
+	ret = hci_pio_dequeue_xfer_common(hci, pio, xfer, n);
+	spin_unlock_irq(&pio->lock);
+	return ret;
+}
+
+static void hci_pio_err(struct i3c_hci *hci, struct hci_pio_data *pio,
+			u32 status)
+{
+	/* TODO: this ought to be more sophisticated eventually */
+
+	if (pio_reg_read(INTR_STATUS) & STAT_RESP_READY) {
+		/* this may happen when an error is signaled with ROC unset */
+		u32 resp = pio_reg_read(RESPONSE_QUEUE_PORT);
+
+		dev_err(&hci->master.dev,
+			"orphan response (%#x) on error\n", resp);
+	}
+
+	/* dump states on programming errors */
+	if (status & STAT_PROG_ERRORS) {
+		u32 queue = pio_reg_read(QUEUE_CUR_STATUS);
+		u32 data = pio_reg_read(DATA_BUFFER_CUR_STATUS);
+
+		dev_err(&hci->master.dev,
+			"prog error %#lx (C/R/I = %ld/%ld/%ld, TX/RX = %ld/%ld)\n",
+			status & STAT_PROG_ERRORS,
+			FIELD_GET(CUR_CMD_Q_EMPTY_LEVEL, queue),
+			FIELD_GET(CUR_RESP_Q_LEVEL, queue),
+			FIELD_GET(CUR_IBI_Q_LEVEL, queue),
+			FIELD_GET(CUR_TX_BUF_LVL, data),
+			FIELD_GET(CUR_RX_BUF_LVL, data));
+	}
+
+	/* just bust out everything with pending responses for now */
+	hci_pio_dequeue_xfer_common(hci, pio, pio->curr_resp, 1);
+	/* ... and half-way TX transfers if any */
+	if (pio->curr_tx && pio->curr_tx->data_left != pio->curr_tx->data_len)
+		hci_pio_dequeue_xfer_common(hci, pio, pio->curr_tx, 1);
+	/* then reset the hardware */
+	mipi_i3c_hci_pio_reset(hci);
+	mipi_i3c_hci_resume(hci);
+
+	DBG("status=%#x/%#x",
+	    pio_reg_read(INTR_STATUS), pio_reg_read(INTR_SIGNAL_ENABLE));
+}
+
+static void hci_pio_set_ibi_thresh(struct i3c_hci *hci,
+				   struct hci_pio_data *pio,
+				   unsigned int thresh_val)
+{
+	u32 regval = pio->reg_queue_thresh;
+
+	regval &= ~QUEUE_IBI_STATUS_THLD;
+	regval |= FIELD_PREP(QUEUE_IBI_STATUS_THLD, thresh_val);
+	/* write the threshold reg only if it changes */
+	if (regval != pio->reg_queue_thresh) {
+		pio_reg_write(QUEUE_THLD_CTRL, regval);
+		pio->reg_queue_thresh = regval;
+		DBG("%d", thresh_val);
+	}
+}
+
+static bool hci_pio_get_ibi_segment(struct i3c_hci *hci,
+				    struct hci_pio_data *pio)
+{
+	struct hci_pio_ibi_data *ibi = &pio->ibi;
+	unsigned int nr_words, thresh_val;
+	u32 *p;
+
+	p = ibi->data_ptr;
+	p += (ibi->seg_len - ibi->seg_cnt) / 4;
+
+	while ((nr_words = ibi->seg_cnt/4)) {
+		/* determine our IBI queue threshold value */
+		thresh_val = min(nr_words, pio->max_ibi_thresh);
+		hci_pio_set_ibi_thresh(hci, pio, thresh_val);
+		/* bail out if we don't have that amount of data ready */
+		if (!(pio_reg_read(INTR_STATUS) & STAT_IBI_STATUS_THLD))
+			return false;
+		/* extract the data from the IBI port */
+		nr_words = thresh_val;
+		ibi->seg_cnt -= nr_words * 4;
+		DBG("now %d left %d", nr_words * 4, ibi->seg_cnt);
+		while (nr_words--)
+			*p++ = pio_reg_read(IBI_PORT);
+	}
+
+	if (ibi->seg_cnt) {
+		/*
+		 * There are trailing bytes in the last word.
+		 * Fetch it and extract bytes in an endian independent way.
+		 * Unlike the TX case, we must not write past the end of
+		 * the destination buffer.
+		 */
+		u32 data;
+		u8 *p_byte = (u8 *)p;
+
+		hci_pio_set_ibi_thresh(hci, pio, 1);
+		if (!(pio_reg_read(INTR_STATUS) & STAT_IBI_STATUS_THLD))
+			return false;
+		DBG("trailing %d", ibi->seg_cnt);
+		data = pio_reg_read(IBI_PORT);
+		data = (__force u32) cpu_to_le32(data);
+		while (ibi->seg_cnt--) {
+			*p_byte++ = data;
+			data >>= 8;
+		}
+	}
+
+	return true;
+}
+
+static bool hci_pio_prep_new_ibi(struct i3c_hci *hci, struct hci_pio_data *pio)
+{
+	struct hci_pio_ibi_data *ibi = &pio->ibi;
+	struct i3c_dev_desc *dev;
+	struct i3c_hci_dev_data *dev_data;
+	struct hci_pio_dev_ibi_data *dev_ibi;
+	u32 ibi_status;
+
+	/*
+	 * We have a new IBI. Try to set up its payload retrieval.
+	 * When returning true, the IBI data has to be consumed whether
+	 * or not we are set up to capture it. If we return true with
+	 * ibi->slot == NULL that means the data payload has to be
+	 * drained out of the IBI port and dropped.
+	 */
+
+	ibi_status = pio_reg_read(IBI_PORT);
+	DBG("status = %#x", ibi_status);
+	ibi->addr = FIELD_GET(IBI_TARGET_ADDR, ibi_status);
+	if (ibi_status & IBI_ERROR) {
+		dev_err(&hci->master.dev, "IBI error from %#x\n", ibi->addr);
+		return false;
+	}
+
+	ibi->last_seg = ibi_status & IBI_LAST_STATUS;
+	ibi->seg_len = FIELD_GET(IBI_DATA_LENGTH, ibi_status);
+	ibi->seg_cnt = ibi->seg_len;
+
+	dev = i3c_hci_addr_to_dev(hci, ibi->addr);
+	if (!dev) {
+		dev_err(&hci->master.dev,
+			"IBI for unknown device %#x\n", ibi->addr);
+		return true;
+	}
+
+	dev_data = i3c_dev_get_master_data(dev);
+	dev_ibi = dev_data->ibi_data;
+	ibi->max_len = dev_ibi->max_len;
+
+	if (ibi->seg_len > ibi->max_len) {
+		dev_err(&hci->master.dev, "IBI payload too big (%d > %d)\n",
+			ibi->seg_len, ibi->max_len);
+		return true;
+	}
+
+	ibi->slot = i3c_generic_ibi_get_free_slot(dev_ibi->pool);
+	if (!ibi->slot) {
+		dev_err(&hci->master.dev, "no free slot for IBI\n");
+	} else {
+		ibi->slot->len = 0;
+		ibi->data_ptr = ibi->slot->data;
+	}
+	return true;
+}
+
+static void hci_pio_free_ibi_slot(struct i3c_hci *hci, struct hci_pio_data *pio)
+{
+	struct hci_pio_ibi_data *ibi = &pio->ibi;
+	struct hci_pio_dev_ibi_data *dev_ibi;
+
+	if (ibi->slot) {
+		dev_ibi = ibi->slot->dev->common.master_priv;
+		i3c_generic_ibi_recycle_slot(dev_ibi->pool, ibi->slot);
+		ibi->slot = NULL;
+	}
+}
+
+static bool hci_pio_process_ibi(struct i3c_hci *hci, struct hci_pio_data *pio)
+{
+	struct hci_pio_ibi_data *ibi = &pio->ibi;
+
+	if (!ibi->slot && !ibi->seg_cnt && ibi->last_seg)
+		if (!hci_pio_prep_new_ibi(hci, pio))
+			return false;
+
+	for (;;) {
+		u32 ibi_status;
+		unsigned int ibi_addr;
+
+		if (ibi->slot) {
+			if (!hci_pio_get_ibi_segment(hci, pio))
+				return false;
+			ibi->slot->len += ibi->seg_len;
+			ibi->data_ptr += ibi->seg_len;
+			if (ibi->last_seg) {
+				/* was the last segment: submit it and leave */
+				i3c_master_queue_ibi(ibi->slot->dev, ibi->slot);
+				ibi->slot = NULL;
+				hci_pio_set_ibi_thresh(hci, pio, 1);
+				return true;
+			}
+		} else if (ibi->seg_cnt) {
+			/*
+			 * No slot but a non-zero count. This is the result
+			 * of some error and the payload must be drained.
+			 * This normally does not happen therefore no need
+			 * to be extra optimized here.
+			 */
+			hci_pio_set_ibi_thresh(hci, pio, 1);
+			do {
+				if (!(pio_reg_read(INTR_STATUS) & STAT_IBI_STATUS_THLD))
+					return false;
+				pio_reg_read(IBI_PORT);
+			} while (--ibi->seg_cnt);
+			if (ibi->last_seg)
+				return true;
+		}
+
+		/* try to move to the next segment right away */
+		hci_pio_set_ibi_thresh(hci, pio, 1);
+		if (!(pio_reg_read(INTR_STATUS) & STAT_IBI_STATUS_THLD))
+			return false;
+		ibi_status = pio_reg_read(IBI_PORT);
+		ibi_addr = FIELD_GET(IBI_TARGET_ADDR, ibi_status);
+		if (ibi->addr != ibi_addr) {
+			/* target address changed before last segment */
+			dev_err(&hci->master.dev,
+				"unexp IBI address changed from %d to %d\n",
+				ibi->addr, ibi_addr);
+			hci_pio_free_ibi_slot(hci, pio);
+		}
+		ibi->last_seg = ibi_status & IBI_LAST_STATUS;
+		ibi->seg_len = FIELD_GET(IBI_DATA_LENGTH, ibi_status);
+		ibi->seg_cnt = ibi->seg_len;
+		if (ibi->slot && ibi->slot->len + ibi->seg_len > ibi->max_len) {
+			dev_err(&hci->master.dev,
+				"IBI payload too big (%d > %d)\n",
+				ibi->slot->len + ibi->seg_len, ibi->max_len);
+			hci_pio_free_ibi_slot(hci, pio);
+		}
+	}
+
+	return false;
+}
+
+static int hci_pio_request_ibi(struct i3c_hci *hci, struct i3c_dev_desc *dev,
+			       const struct i3c_ibi_setup *req)
+{
+	struct i3c_hci_dev_data *dev_data = i3c_dev_get_master_data(dev);
+	struct i3c_generic_ibi_pool *pool;
+	struct hci_pio_dev_ibi_data *dev_ibi;
+
+	dev_ibi = kmalloc(sizeof(*dev_ibi), GFP_KERNEL);
+	if (!dev_ibi)
+		return -ENOMEM;
+	pool = i3c_generic_ibi_alloc_pool(dev, req);
+	if (IS_ERR(pool)) {
+		kfree(dev_ibi);
+		return PTR_ERR(pool);
+	}
+	dev_ibi->pool = pool;
+	dev_ibi->max_len = req->max_payload_len;
+	dev_data->ibi_data = dev_ibi;
+	return 0;
+}
+
+static void hci_pio_free_ibi(struct i3c_hci *hci, struct i3c_dev_desc *dev)
+{
+	struct i3c_hci_dev_data *dev_data = i3c_dev_get_master_data(dev);
+	struct hci_pio_dev_ibi_data *dev_ibi = dev_data->ibi_data;
+
+	dev_data->ibi_data = NULL;
+	i3c_generic_ibi_free_pool(dev_ibi->pool);
+	kfree(dev_ibi);
+}
+
+static void hci_pio_recycle_ibi_slot(struct i3c_hci *hci,
+				    struct i3c_dev_desc *dev,
+				    struct i3c_ibi_slot *slot)
+{
+	struct i3c_hci_dev_data *dev_data = i3c_dev_get_master_data(dev);
+	struct hci_pio_dev_ibi_data *dev_ibi = dev_data->ibi_data;
+
+	i3c_generic_ibi_recycle_slot(dev_ibi->pool, slot);
+}
+
+static bool hci_pio_irq_handler(struct i3c_hci *hci, unsigned int unused)
+{
+	struct hci_pio_data *pio = hci->io_data;
+	u32 status;
+
+	spin_lock(&pio->lock);
+	status = pio_reg_read(INTR_STATUS);
+	DBG("(in) status: %#x/%#x", status, pio->enabled_irqs);
+	status &= pio->enabled_irqs | STAT_LATENCY_WARNINGS;
+	if (!status) {
+		spin_unlock(&pio->lock);
+		return false;
+	}
+
+	if (status & STAT_IBI_STATUS_THLD)
+		hci_pio_process_ibi(hci, pio);
+
+	if (status & STAT_RX_THLD)
+		if (hci_pio_process_rx(hci, pio))
+			pio->enabled_irqs &= ~STAT_RX_THLD;
+	if (status & STAT_TX_THLD)
+		if (hci_pio_process_tx(hci, pio))
+			pio->enabled_irqs &= ~STAT_TX_THLD;
+	if (status & STAT_RESP_READY)
+		if (hci_pio_process_resp(hci, pio))
+			pio->enabled_irqs &= ~STAT_RESP_READY;
+
+	if (unlikely(status & STAT_LATENCY_WARNINGS)) {
+		pio_reg_write(INTR_STATUS, status & STAT_LATENCY_WARNINGS);
+		dev_warn_ratelimited(&hci->master.dev,
+				     "encountered warning condition %#lx\n",
+				     status & STAT_LATENCY_WARNINGS);
+	}
+
+	if (unlikely(status & STAT_ALL_ERRORS)) {
+		pio_reg_write(INTR_STATUS, status & STAT_ALL_ERRORS);
+		hci_pio_err(hci, pio, status & STAT_ALL_ERRORS);
+	}
+
+	if (status & STAT_CMD_QUEUE_READY)
+		if (hci_pio_process_cmd(hci, pio))
+			pio->enabled_irqs &= ~STAT_CMD_QUEUE_READY;
+
+	pio_reg_write(INTR_SIGNAL_ENABLE, pio->enabled_irqs);
+	DBG("(out) status: %#x/%#x",
+	    pio_reg_read(INTR_STATUS), pio_reg_read(INTR_SIGNAL_ENABLE));
+	spin_unlock(&pio->lock);
+	return true;
+}
+
+const struct hci_io_ops mipi_i3c_hci_pio = {
+	.init			= hci_pio_init,
+	.cleanup		= hci_pio_cleanup,
+	.queue_xfer		= hci_pio_queue_xfer,
+	.dequeue_xfer		= hci_pio_dequeue_xfer,
+	.irq_handler		= hci_pio_irq_handler,
+	.request_ibi		= hci_pio_request_ibi,
+	.free_ibi		= hci_pio_free_ibi,
+	.recycle_ibi_slot	= hci_pio_recycle_ibi_slot,
+};
diff --git a/drivers/i3c/master/mipi-i3c-hci/xfer_mode_rate.h b/drivers/i3c/master/mipi-i3c-hci/xfer_mode_rate.h
new file mode 100644
index 000000000000..1e36b75afb16
--- /dev/null
+++ b/drivers/i3c/master/mipi-i3c-hci/xfer_mode_rate.h
@@ -0,0 +1,79 @@
+/* SPDX-License-Identifier: BSD-3-Clause */
+/*
+ * Copyright (c) 2020, MIPI Alliance, Inc.
+ *
+ * Author: Nicolas Pitre <npitre@baylibre.com>
+ *
+ * Transfer Mode/Rate Table definitions as found in extended capability
+ * sections 0x04 and 0x08.
+ * This applies starting from I3C HCI v2.0.
+ */
+
+#ifndef XFER_MODE_RATE_H
+#define XFER_MODE_RATE_H
+
+/*
+ * Master Transfer Mode Table Fixed Indexes.
+ *
+ * Indexes 0x0 and 0x8 are mandatory. Availability for the rest must be
+ * obtained from the mode table in the extended capability area.
+ * Presence and definitions for indexes beyond these ones may vary.
+ */
+#define XFERMODE_IDX_I3C_SDR		0x00	/* I3C SDR Mode */
+#define XFERMODE_IDX_I3C_HDR_DDR	0x01	/* I3C HDR-DDR Mode */
+#define XFERMODE_IDX_I3C_HDR_T		0x02	/* I3C HDR-Ternary Mode */
+#define XFERMODE_IDX_I3C_HDR_BT		0x03	/* I3C HDR-BT Mode */
+#define XFERMODE_IDX_I2C		0x08	/* Legacy I2C Mode */
+
+/*
+ * Transfer Mode Table Entry Bits Definitions
+ */
+#define XFERMODE_VALID_XFER_ADD_FUNC	GENMASK(21, 16)
+#define XFERMODE_ML_DATA_XFER_CODING	GENMASK(15, 11)
+#define XFERMODE_ML_ADDL_LANES		GENMASK(10, 8)
+#define XFERMODE_SUPPORTED		BIT(7)
+#define XFERMODE_MODE			GENMASK(3, 0)
+
+/*
+ * Master Data Transfer Rate Selector Values.
+ *
+ * These are the values to be used in the command descriptor XFER_RATE field
+ * and found in the RATE_ID field below.
+ * The I3C_SDR0, I3C_SDR1, I3C_SDR2, I3C_SDR3, I3C_SDR4 and I2C_FM rates
+ * are required, everything else is optional and discoverable in the
+ * Data Transfer Rate Table. Indicated are typical rates. The actual
+ * rates may vary slightly and are also specified in the Data Transfer
+ * Rate Table.
+ */
+#define XFERRATE_I3C_SDR0		0x00	/* 12.5 MHz */
+#define XFERRATE_I3C_SDR1		0x01	/* 8 MHz */
+#define XFERRATE_I3C_SDR2		0x02	/* 6 MHz */
+#define XFERRATE_I3C_SDR3		0x03	/* 4 MHz */
+#define XFERRATE_I3C_SDR4		0x04	/* 2 MHz */
+#define XFERRATE_I3C_SDR_FM_FMP		0x05	/* 400 KHz / 1 MHz */
+#define XFERRATE_I3C_SDR_USER6		0x06	/* User Defined */
+#define XFERRATE_I3C_SDR_USER7		0x07	/* User Defined */
+
+#define XFERRATE_I2C_FM			0x00	/* 400 KHz */
+#define XFERRATE_I2C_FMP		0x01	/* 1 MHz */
+#define XFERRATE_I2C_USER2		0x02	/* User Defined */
+#define XFERRATE_I2C_USER3		0x03	/* User Defined */
+#define XFERRATE_I2C_USER4		0x04	/* User Defined */
+#define XFERRATE_I2C_USER5		0x05	/* User Defined */
+#define XFERRATE_I2C_USER6		0x06	/* User Defined */
+#define XFERRATE_I2C_USER7		0x07	/* User Defined */
+
+/*
+ * Master Data Transfer Rate Table Mode ID values.
+ */
+#define XFERRATE_MODE_I3C		0x00
+#define XFERRATE_MODE_I2C		0x08
+
+/*
+ * Master Data Transfer Rate Table Entry Bits Definitions
+ */
+#define XFERRATE_MODE_ID		GENMASK(31, 28)
+#define XFERRATE_RATE_ID		GENMASK(22, 20)
+#define XFERRATE_ACTUAL_RATE_KHZ	GENMASK(19, 0)
+
+#endif
diff --git a/drivers/i3c/master/svc-i3c-master.c b/drivers/i3c/master/svc-i3c-master.c
new file mode 100644
index 000000000000..879e5a64acaf
--- /dev/null
+++ b/drivers/i3c/master/svc-i3c-master.c
@@ -0,0 +1,1476 @@
+// SPDX-License-Identifier: GPL-2.0
+/*
+ * Silvaco dual-role I3C master driver
+ *
+ * Copyright (C) 2020 Silvaco
+ * Author: Miquel RAYNAL <miquel.raynal@bootlin.com>
+ * Based on a work from: Conor Culhane <conor.culhane@silvaco.com>
+ */
+
+#include <linux/bitfield.h>
+#include <linux/clk.h>
+#include <linux/completion.h>
+#include <linux/errno.h>
+#include <linux/i3c/master.h>
+#include <linux/interrupt.h>
+#include <linux/iopoll.h>
+#include <linux/list.h>
+#include <linux/module.h>
+#include <linux/of.h>
+#include <linux/platform_device.h>
+
+/* Master Mode Registers */
+#define SVC_I3C_MCONFIG      0x000
+#define   SVC_I3C_MCONFIG_MASTER_EN BIT(0)
+#define   SVC_I3C_MCONFIG_DISTO(x) FIELD_PREP(BIT(3), (x))
+#define   SVC_I3C_MCONFIG_HKEEP(x) FIELD_PREP(GENMASK(5, 4), (x))
+#define   SVC_I3C_MCONFIG_ODSTOP(x) FIELD_PREP(BIT(6), (x))
+#define   SVC_I3C_MCONFIG_PPBAUD(x) FIELD_PREP(GENMASK(11, 8), (x))
+#define   SVC_I3C_MCONFIG_PPLOW(x) FIELD_PREP(GENMASK(15, 12), (x))
+#define   SVC_I3C_MCONFIG_ODBAUD(x) FIELD_PREP(GENMASK(23, 16), (x))
+#define   SVC_I3C_MCONFIG_ODHPP(x) FIELD_PREP(BIT(24), (x))
+#define   SVC_I3C_MCONFIG_SKEW(x) FIELD_PREP(GENMASK(27, 25), (x))
+#define   SVC_I3C_MCONFIG_I2CBAUD(x) FIELD_PREP(GENMASK(31, 28), (x))
+
+#define SVC_I3C_MCTRL        0x084
+#define   SVC_I3C_MCTRL_REQUEST_MASK GENMASK(2, 0)
+#define   SVC_I3C_MCTRL_REQUEST_NONE 0
+#define   SVC_I3C_MCTRL_REQUEST_START_ADDR 1
+#define   SVC_I3C_MCTRL_REQUEST_STOP 2
+#define   SVC_I3C_MCTRL_REQUEST_IBI_ACKNACK 3
+#define   SVC_I3C_MCTRL_REQUEST_PROC_DAA 4
+#define   SVC_I3C_MCTRL_REQUEST_AUTO_IBI 7
+#define   SVC_I3C_MCTRL_TYPE_I3C 0
+#define   SVC_I3C_MCTRL_TYPE_I2C BIT(4)
+#define   SVC_I3C_MCTRL_IBIRESP_AUTO 0
+#define   SVC_I3C_MCTRL_IBIRESP_ACK_WITHOUT_BYTE 0
+#define   SVC_I3C_MCTRL_IBIRESP_ACK_WITH_BYTE BIT(7)
+#define   SVC_I3C_MCTRL_IBIRESP_NACK BIT(6)
+#define   SVC_I3C_MCTRL_IBIRESP_MANUAL GENMASK(7, 6)
+#define   SVC_I3C_MCTRL_DIR(x) FIELD_PREP(BIT(8), (x))
+#define   SVC_I3C_MCTRL_DIR_WRITE 0
+#define   SVC_I3C_MCTRL_DIR_READ 1
+#define   SVC_I3C_MCTRL_ADDR(x) FIELD_PREP(GENMASK(15, 9), (x))
+#define   SVC_I3C_MCTRL_RDTERM(x) FIELD_PREP(GENMASK(23, 16), (x))
+
+#define SVC_I3C_MSTATUS      0x088
+#define   SVC_I3C_MSTATUS_STATE(x) FIELD_GET(GENMASK(2, 0), (x))
+#define   SVC_I3C_MSTATUS_STATE_DAA(x) (SVC_I3C_MSTATUS_STATE(x) == 5)
+#define   SVC_I3C_MSTATUS_STATE_IDLE(x) (SVC_I3C_MSTATUS_STATE(x) == 0)
+#define   SVC_I3C_MSTATUS_BETWEEN(x) FIELD_GET(BIT(4), (x))
+#define   SVC_I3C_MSTATUS_NACKED(x) FIELD_GET(BIT(5), (x))
+#define   SVC_I3C_MSTATUS_IBITYPE(x) FIELD_GET(GENMASK(7, 6), (x))
+#define   SVC_I3C_MSTATUS_IBITYPE_IBI 1
+#define   SVC_I3C_MSTATUS_IBITYPE_MASTER_REQUEST 2
+#define   SVC_I3C_MSTATUS_IBITYPE_HOT_JOIN 3
+#define   SVC_I3C_MINT_SLVSTART BIT(8)
+#define   SVC_I3C_MINT_MCTRLDONE BIT(9)
+#define   SVC_I3C_MINT_COMPLETE BIT(10)
+#define   SVC_I3C_MINT_RXPEND BIT(11)
+#define   SVC_I3C_MINT_TXNOTFULL BIT(12)
+#define   SVC_I3C_MINT_IBIWON BIT(13)
+#define   SVC_I3C_MINT_ERRWARN BIT(15)
+#define   SVC_I3C_MSTATUS_SLVSTART(x) FIELD_GET(SVC_I3C_MINT_SLVSTART, (x))
+#define   SVC_I3C_MSTATUS_MCTRLDONE(x) FIELD_GET(SVC_I3C_MINT_MCTRLDONE, (x))
+#define   SVC_I3C_MSTATUS_COMPLETE(x) FIELD_GET(SVC_I3C_MINT_COMPLETE, (x))
+#define   SVC_I3C_MSTATUS_RXPEND(x) FIELD_GET(SVC_I3C_MINT_RXPEND, (x))
+#define   SVC_I3C_MSTATUS_TXNOTFULL(x) FIELD_GET(SVC_I3C_MINT_TXNOTFULL, (x))
+#define   SVC_I3C_MSTATUS_IBIWON(x) FIELD_GET(SVC_I3C_MINT_IBIWON, (x))
+#define   SVC_I3C_MSTATUS_ERRWARN(x) FIELD_GET(SVC_I3C_MINT_ERRWARN, (x))
+#define   SVC_I3C_MSTATUS_IBIADDR(x) FIELD_GET(GENMASK(30, 24), (x))
+
+#define SVC_I3C_IBIRULES     0x08C
+#define   SVC_I3C_IBIRULES_ADDR(slot, addr) FIELD_PREP(GENMASK(29, 0), \
+						       ((addr) & 0x3F) << ((slot) * 6))
+#define   SVC_I3C_IBIRULES_ADDRS 5
+#define   SVC_I3C_IBIRULES_MSB0 BIT(30)
+#define   SVC_I3C_IBIRULES_NOBYTE BIT(31)
+#define   SVC_I3C_IBIRULES_MANDBYTE 0
+#define SVC_I3C_MINTSET      0x090
+#define SVC_I3C_MINTCLR      0x094
+#define SVC_I3C_MINTMASKED   0x098
+#define SVC_I3C_MERRWARN     0x09C
+#define SVC_I3C_MDMACTRL     0x0A0
+#define SVC_I3C_MDATACTRL    0x0AC
+#define   SVC_I3C_MDATACTRL_FLUSHTB BIT(0)
+#define   SVC_I3C_MDATACTRL_FLUSHRB BIT(1)
+#define   SVC_I3C_MDATACTRL_UNLOCK_TRIG BIT(3)
+#define   SVC_I3C_MDATACTRL_TXTRIG_FIFO_NOT_FULL GENMASK(5, 4)
+#define   SVC_I3C_MDATACTRL_RXTRIG_FIFO_NOT_EMPTY 0
+#define   SVC_I3C_MDATACTRL_RXCOUNT(x) FIELD_GET(GENMASK(28, 24), (x))
+#define   SVC_I3C_MDATACTRL_TXFULL BIT(30)
+#define   SVC_I3C_MDATACTRL_RXEMPTY BIT(31)
+
+#define SVC_I3C_MWDATAB      0x0B0
+#define   SVC_I3C_MWDATAB_END BIT(8)
+
+#define SVC_I3C_MWDATABE     0x0B4
+#define SVC_I3C_MWDATAH      0x0B8
+#define SVC_I3C_MWDATAHE     0x0BC
+#define SVC_I3C_MRDATAB      0x0C0
+#define SVC_I3C_MRDATAH      0x0C8
+#define SVC_I3C_MWMSG_SDR    0x0D0
+#define SVC_I3C_MRMSG_SDR    0x0D4
+#define SVC_I3C_MWMSG_DDR    0x0D8
+#define SVC_I3C_MRMSG_DDR    0x0DC
+
+#define SVC_I3C_MDYNADDR     0x0E4
+#define   SVC_MDYNADDR_VALID BIT(0)
+#define   SVC_MDYNADDR_ADDR(x) FIELD_PREP(GENMASK(7, 1), (x))
+
+#define SVC_I3C_MAX_DEVS 32
+
+/* This parameter depends on the implementation and may be tuned */
+#define SVC_I3C_FIFO_SIZE 16
+
+struct svc_i3c_cmd {
+	u8 addr;
+	bool rnw;
+	u8 *in;
+	const void *out;
+	unsigned int len;
+	unsigned int read_len;
+	bool continued;
+};
+
+struct svc_i3c_xfer {
+	struct list_head node;
+	struct completion comp;
+	int ret;
+	unsigned int type;
+	unsigned int ncmds;
+	struct svc_i3c_cmd cmds[];
+};
+
+/**
+ * struct svc_i3c_master - Silvaco I3C Master structure
+ * @base: I3C master controller
+ * @dev: Corresponding device
+ * @regs: Memory mapping
+ * @free_slots: Bit array of available slots
+ * @addrs: Array containing the dynamic addresses of each attached device
+ * @descs: Array of descriptors, one per attached device
+ * @hj_work: Hot-join work
+ * @ibi_work: IBI work
+ * @irq: Main interrupt
+ * @pclk: System clock
+ * @fclk: Fast clock (bus)
+ * @sclk: Slow clock (other events)
+ * @xferqueue: Transfer queue structure
+ * @xferqueue.list: List member
+ * @xferqueue.cur: Current ongoing transfer
+ * @xferqueue.lock: Queue lock
+ * @ibi: IBI structure
+ * @ibi.num_slots: Number of slots available in @ibi.slots
+ * @ibi.slots: Available IBI slots
+ * @ibi.tbq_slot: To be queued IBI slot
+ * @ibi.lock: IBI lock
+ */
+struct svc_i3c_master {
+	struct i3c_master_controller base;
+	struct device *dev;
+	void __iomem *regs;
+	u32 free_slots;
+	u8 addrs[SVC_I3C_MAX_DEVS];
+	struct i3c_dev_desc *descs[SVC_I3C_MAX_DEVS];
+	struct work_struct hj_work;
+	struct work_struct ibi_work;
+	int irq;
+	struct clk *pclk;
+	struct clk *fclk;
+	struct clk *sclk;
+	struct {
+		struct list_head list;
+		struct svc_i3c_xfer *cur;
+		/* Prevent races between transfers */
+		spinlock_t lock;
+	} xferqueue;
+	struct {
+		unsigned int num_slots;
+		struct i3c_dev_desc **slots;
+		struct i3c_ibi_slot *tbq_slot;
+		/* Prevent races within IBI handlers */
+		spinlock_t lock;
+	} ibi;
+};
+
+/**
+ * struct svc_i3c_i2c_dev_data - Device specific data
+ * @index: Index in the master tables corresponding to this device
+ * @ibi: IBI slot index in the master structure
+ * @ibi_pool: IBI pool associated to this device
+ */
+struct svc_i3c_i2c_dev_data {
+	u8 index;
+	int ibi;
+	struct i3c_generic_ibi_pool *ibi_pool;
+};
+
+static bool svc_i3c_master_error(struct svc_i3c_master *master)
+{
+	u32 mstatus, merrwarn;
+
+	mstatus = readl(master->regs + SVC_I3C_MSTATUS);
+	if (SVC_I3C_MSTATUS_ERRWARN(mstatus)) {
+		merrwarn = readl(master->regs + SVC_I3C_MERRWARN);
+		writel(merrwarn, master->regs + SVC_I3C_MERRWARN);
+		dev_err(master->dev,
+			"Error condition: MSTATUS 0x%08x, MERRWARN 0x%08x\n",
+			mstatus, merrwarn);
+
+		return true;
+	}
+
+	return false;
+}
+
+static void svc_i3c_master_enable_interrupts(struct svc_i3c_master *master, u32 mask)
+{
+	writel(mask, master->regs + SVC_I3C_MINTSET);
+}
+
+static void svc_i3c_master_disable_interrupts(struct svc_i3c_master *master)
+{
+	u32 mask = readl(master->regs + SVC_I3C_MINTSET);
+
+	writel(mask, master->regs + SVC_I3C_MINTCLR);
+}
+
+static inline struct svc_i3c_master *
+to_svc_i3c_master(struct i3c_master_controller *master)
+{
+	return container_of(master, struct svc_i3c_master, base);
+}
+
+static void svc_i3c_master_hj_work(struct work_struct *work)
+{
+	struct svc_i3c_master *master;
+
+	master = container_of(work, struct svc_i3c_master, hj_work);
+	i3c_master_do_daa(&master->base);
+}
+
+static struct i3c_dev_desc *
+svc_i3c_master_dev_from_addr(struct svc_i3c_master *master,
+			     unsigned int ibiaddr)
+{
+	int i;
+
+	for (i = 0; i < SVC_I3C_MAX_DEVS; i++)
+		if (master->addrs[i] == ibiaddr)
+			break;
+
+	if (i == SVC_I3C_MAX_DEVS)
+		return NULL;
+
+	return master->descs[i];
+}
+
+static void svc_i3c_master_emit_stop(struct svc_i3c_master *master)
+{
+	writel(SVC_I3C_MCTRL_REQUEST_STOP, master->regs + SVC_I3C_MCTRL);
+
+	/*
+	 * This delay is necessary after the emission of a stop, otherwise eg.
+	 * repeating IBIs do not get detected. There is a note in the manual
+	 * about it, stating that the stop condition might not be settled
+	 * correctly if a start condition follows too rapidly.
+	 */
+	udelay(1);
+}
+
+static void svc_i3c_master_clear_merrwarn(struct svc_i3c_master *master)
+{
+	writel(readl(master->regs + SVC_I3C_MERRWARN),
+	       master->regs + SVC_I3C_MERRWARN);
+}
+
+static int svc_i3c_master_handle_ibi(struct svc_i3c_master *master,
+				     struct i3c_dev_desc *dev)
+{
+	struct svc_i3c_i2c_dev_data *data = i3c_dev_get_master_data(dev);
+	struct i3c_ibi_slot *slot;
+	unsigned int count;
+	u32 mdatactrl;
+	u8 *buf;
+
+	slot = i3c_generic_ibi_get_free_slot(data->ibi_pool);
+	if (!slot)
+		return -ENOSPC;
+
+	slot->len = 0;
+	buf = slot->data;
+
+	while (SVC_I3C_MSTATUS_RXPEND(readl(master->regs + SVC_I3C_MSTATUS))  &&
+	       slot->len < SVC_I3C_FIFO_SIZE) {
+		mdatactrl = readl(master->regs + SVC_I3C_MDATACTRL);
+		count = SVC_I3C_MDATACTRL_RXCOUNT(mdatactrl);
+		readsl(master->regs + SVC_I3C_MRDATAB, buf, count);
+		slot->len += count;
+		buf += count;
+	}
+
+	master->ibi.tbq_slot = slot;
+
+	return 0;
+}
+
+static void svc_i3c_master_ack_ibi(struct svc_i3c_master *master,
+				   bool mandatory_byte)
+{
+	unsigned int ibi_ack_nack;
+
+	ibi_ack_nack = SVC_I3C_MCTRL_REQUEST_IBI_ACKNACK;
+	if (mandatory_byte)
+		ibi_ack_nack |= SVC_I3C_MCTRL_IBIRESP_ACK_WITH_BYTE;
+	else
+		ibi_ack_nack |= SVC_I3C_MCTRL_IBIRESP_ACK_WITHOUT_BYTE;
+
+	writel(ibi_ack_nack, master->regs + SVC_I3C_MCTRL);
+}
+
+static void svc_i3c_master_nack_ibi(struct svc_i3c_master *master)
+{
+	writel(SVC_I3C_MCTRL_REQUEST_IBI_ACKNACK |
+	       SVC_I3C_MCTRL_IBIRESP_NACK,
+	       master->regs + SVC_I3C_MCTRL);
+}
+
+static void svc_i3c_master_ibi_work(struct work_struct *work)
+{
+	struct svc_i3c_master *master = container_of(work, struct svc_i3c_master, ibi_work);
+	struct svc_i3c_i2c_dev_data *data;
+	unsigned int ibitype, ibiaddr;
+	struct i3c_dev_desc *dev;
+	u32 status, val;
+	int ret;
+
+	/* Acknowledge the incoming interrupt with the AUTOIBI mechanism */
+	writel(SVC_I3C_MCTRL_REQUEST_AUTO_IBI |
+	       SVC_I3C_MCTRL_IBIRESP_AUTO,
+	       master->regs + SVC_I3C_MCTRL);
+
+	/* Wait for IBIWON, should take approximately 100us */
+	ret = readl_relaxed_poll_timeout(master->regs + SVC_I3C_MSTATUS, val,
+					 SVC_I3C_MSTATUS_IBIWON(val), 0, 1000);
+	if (ret) {
+		dev_err(master->dev, "Timeout when polling for IBIWON\n");
+		goto reenable_ibis;
+	}
+
+	/* Clear the interrupt status */
+	writel(SVC_I3C_MINT_IBIWON, master->regs + SVC_I3C_MSTATUS);
+
+	status = readl(master->regs + SVC_I3C_MSTATUS);
+	ibitype = SVC_I3C_MSTATUS_IBITYPE(status);
+	ibiaddr = SVC_I3C_MSTATUS_IBIADDR(status);
+
+	/* Handle the critical responses to IBI's */
+	switch (ibitype) {
+	case SVC_I3C_MSTATUS_IBITYPE_IBI:
+		dev = svc_i3c_master_dev_from_addr(master, ibiaddr);
+		if (!dev)
+			svc_i3c_master_nack_ibi(master);
+		else
+			svc_i3c_master_handle_ibi(master, dev);
+		break;
+	case SVC_I3C_MSTATUS_IBITYPE_HOT_JOIN:
+		svc_i3c_master_ack_ibi(master, false);
+		break;
+	case SVC_I3C_MSTATUS_IBITYPE_MASTER_REQUEST:
+		svc_i3c_master_nack_ibi(master);
+		break;
+	default:
+		break;
+	}
+
+	/*
+	 * If an error happened, we probably got interrupted and the exchange
+	 * timedout. In this case we just drop everything, emit a stop and wait
+	 * for the slave to interrupt again.
+	 */
+	if (svc_i3c_master_error(master)) {
+		if (master->ibi.tbq_slot) {
+			data = i3c_dev_get_master_data(dev);
+			i3c_generic_ibi_recycle_slot(data->ibi_pool,
+						     master->ibi.tbq_slot);
+			master->ibi.tbq_slot = NULL;
+		}
+
+		svc_i3c_master_emit_stop(master);
+
+		goto reenable_ibis;
+	}
+
+	/* Handle the non critical tasks */
+	switch (ibitype) {
+	case SVC_I3C_MSTATUS_IBITYPE_IBI:
+		if (dev) {
+			i3c_master_queue_ibi(dev, master->ibi.tbq_slot);
+			master->ibi.tbq_slot = NULL;
+		}
+		svc_i3c_master_emit_stop(master);
+		break;
+	case SVC_I3C_MSTATUS_IBITYPE_HOT_JOIN:
+		queue_work(master->base.wq, &master->hj_work);
+		break;
+	case SVC_I3C_MSTATUS_IBITYPE_MASTER_REQUEST:
+	default:
+		break;
+	}
+
+reenable_ibis:
+	svc_i3c_master_enable_interrupts(master, SVC_I3C_MINT_SLVSTART);
+}
+
+static irqreturn_t svc_i3c_master_irq_handler(int irq, void *dev_id)
+{
+	struct svc_i3c_master *master = (struct svc_i3c_master *)dev_id;
+	u32 active = readl(master->regs + SVC_I3C_MINTMASKED);
+
+	if (!SVC_I3C_MSTATUS_SLVSTART(active))
+		return IRQ_NONE;
+
+	/* Clear the interrupt status */
+	writel(SVC_I3C_MINT_SLVSTART, master->regs + SVC_I3C_MSTATUS);
+
+	svc_i3c_master_disable_interrupts(master);
+
+	/* Handle the interrupt in a non atomic context */
+	queue_work(master->base.wq, &master->ibi_work);
+
+	return IRQ_HANDLED;
+}
+
+static int svc_i3c_master_bus_init(struct i3c_master_controller *m)
+{
+	struct svc_i3c_master *master = to_svc_i3c_master(m);
+	struct i3c_bus *bus = i3c_master_get_bus(m);
+	struct i3c_device_info info = {};
+	unsigned long fclk_rate, fclk_period_ns;
+	unsigned int high_period_ns, od_low_period_ns;
+	u32 ppbaud, pplow, odhpp, odbaud, i2cbaud, reg;
+	int ret;
+
+	/* Timings derivation */
+	fclk_rate = clk_get_rate(master->fclk);
+	if (!fclk_rate)
+		return -EINVAL;
+
+	fclk_period_ns = DIV_ROUND_UP(1000000000, fclk_rate);
+
+	/*
+	 * Using I3C Push-Pull mode, target is 12.5MHz/80ns period.
+	 * Simplest configuration is using a 50% duty-cycle of 40ns.
+	 */
+	ppbaud = DIV_ROUND_UP(40, fclk_period_ns) - 1;
+	pplow = 0;
+
+	/*
+	 * Using I3C Open-Drain mode, target is 4.17MHz/240ns with a
+	 * duty-cycle tuned so that high levels are filetered out by
+	 * the 50ns filter (target being 40ns).
+	 */
+	odhpp = 1;
+	high_period_ns = (ppbaud + 1) * fclk_period_ns;
+	odbaud = DIV_ROUND_UP(240 - high_period_ns, high_period_ns) - 1;
+	od_low_period_ns = (odbaud + 1) * high_period_ns;
+
+	switch (bus->mode) {
+	case I3C_BUS_MODE_PURE:
+		i2cbaud = 0;
+		break;
+	case I3C_BUS_MODE_MIXED_FAST:
+	case I3C_BUS_MODE_MIXED_LIMITED:
+		/*
+		 * Using I2C Fm+ mode, target is 1MHz/1000ns, the difference
+		 * between the high and low period does not really matter.
+		 */
+		i2cbaud = DIV_ROUND_UP(1000, od_low_period_ns) - 2;
+		break;
+	case I3C_BUS_MODE_MIXED_SLOW:
+		/*
+		 * Using I2C Fm mode, target is 0.4MHz/2500ns, with the same
+		 * constraints as the FM+ mode.
+		 */
+		i2cbaud = DIV_ROUND_UP(2500, od_low_period_ns) - 2;
+		break;
+	default:
+		return -EINVAL;
+	}
+
+	reg = SVC_I3C_MCONFIG_MASTER_EN |
+	      SVC_I3C_MCONFIG_DISTO(0) |
+	      SVC_I3C_MCONFIG_HKEEP(0) |
+	      SVC_I3C_MCONFIG_ODSTOP(0) |
+	      SVC_I3C_MCONFIG_PPBAUD(ppbaud) |
+	      SVC_I3C_MCONFIG_PPLOW(pplow) |
+	      SVC_I3C_MCONFIG_ODBAUD(odbaud) |
+	      SVC_I3C_MCONFIG_ODHPP(odhpp) |
+	      SVC_I3C_MCONFIG_SKEW(0) |
+	      SVC_I3C_MCONFIG_I2CBAUD(i2cbaud);
+	writel(reg, master->regs + SVC_I3C_MCONFIG);
+
+	/* Master core's registration */
+	ret = i3c_master_get_free_addr(m, 0);
+	if (ret < 0)
+		return ret;
+
+	info.dyn_addr = ret;
+
+	writel(SVC_MDYNADDR_VALID | SVC_MDYNADDR_ADDR(info.dyn_addr),
+	       master->regs + SVC_I3C_MDYNADDR);
+
+	ret = i3c_master_set_info(&master->base, &info);
+	if (ret)
+		return ret;
+
+	svc_i3c_master_enable_interrupts(master, SVC_I3C_MINT_SLVSTART);
+
+	return 0;
+}
+
+static void svc_i3c_master_bus_cleanup(struct i3c_master_controller *m)
+{
+	struct svc_i3c_master *master = to_svc_i3c_master(m);
+
+	svc_i3c_master_disable_interrupts(master);
+
+	/* Disable master */
+	writel(0, master->regs + SVC_I3C_MCONFIG);
+}
+
+static int svc_i3c_master_reserve_slot(struct svc_i3c_master *master)
+{
+	unsigned int slot;
+
+	if (!(master->free_slots & GENMASK(SVC_I3C_MAX_DEVS - 1, 0)))
+		return -ENOSPC;
+
+	slot = ffs(master->free_slots) - 1;
+
+	master->free_slots &= ~BIT(slot);
+
+	return slot;
+}
+
+static void svc_i3c_master_release_slot(struct svc_i3c_master *master,
+					unsigned int slot)
+{
+	master->free_slots |= BIT(slot);
+}
+
+static int svc_i3c_master_attach_i3c_dev(struct i3c_dev_desc *dev)
+{
+	struct i3c_master_controller *m = i3c_dev_get_master(dev);
+	struct svc_i3c_master *master = to_svc_i3c_master(m);
+	struct svc_i3c_i2c_dev_data *data;
+	int slot;
+
+	slot = svc_i3c_master_reserve_slot(master);
+	if (slot < 0)
+		return slot;
+
+	data = kzalloc(sizeof(*data), GFP_KERNEL);
+	if (!data) {
+		svc_i3c_master_release_slot(master, slot);
+		return -ENOMEM;
+	}
+
+	data->ibi = -1;
+	data->index = slot;
+	master->addrs[slot] = dev->info.dyn_addr ? dev->info.dyn_addr :
+						   dev->info.static_addr;
+	master->descs[slot] = dev;
+
+	i3c_dev_set_master_data(dev, data);
+
+	return 0;
+}
+
+static int svc_i3c_master_reattach_i3c_dev(struct i3c_dev_desc *dev,
+					   u8 old_dyn_addr)
+{
+	struct i3c_master_controller *m = i3c_dev_get_master(dev);
+	struct svc_i3c_master *master = to_svc_i3c_master(m);
+	struct svc_i3c_i2c_dev_data *data = i3c_dev_get_master_data(dev);
+
+	master->addrs[data->index] = dev->info.dyn_addr ? dev->info.dyn_addr :
+							  dev->info.static_addr;
+
+	return 0;
+}
+
+static void svc_i3c_master_detach_i3c_dev(struct i3c_dev_desc *dev)
+{
+	struct svc_i3c_i2c_dev_data *data = i3c_dev_get_master_data(dev);
+	struct i3c_master_controller *m = i3c_dev_get_master(dev);
+	struct svc_i3c_master *master = to_svc_i3c_master(m);
+
+	master->addrs[data->index] = 0;
+	svc_i3c_master_release_slot(master, data->index);
+
+	kfree(data);
+}
+
+static int svc_i3c_master_attach_i2c_dev(struct i2c_dev_desc *dev)
+{
+	struct i3c_master_controller *m = i2c_dev_get_master(dev);
+	struct svc_i3c_master *master = to_svc_i3c_master(m);
+	struct svc_i3c_i2c_dev_data *data;
+	int slot;
+
+	slot = svc_i3c_master_reserve_slot(master);
+	if (slot < 0)
+		return slot;
+
+	data = kzalloc(sizeof(*data), GFP_KERNEL);
+	if (!data) {
+		svc_i3c_master_release_slot(master, slot);
+		return -ENOMEM;
+	}
+
+	data->index = slot;
+	master->addrs[slot] = dev->addr;
+
+	i2c_dev_set_master_data(dev, data);
+
+	return 0;
+}
+
+static void svc_i3c_master_detach_i2c_dev(struct i2c_dev_desc *dev)
+{
+	struct svc_i3c_i2c_dev_data *data = i2c_dev_get_master_data(dev);
+	struct i3c_master_controller *m = i2c_dev_get_master(dev);
+	struct svc_i3c_master *master = to_svc_i3c_master(m);
+
+	svc_i3c_master_release_slot(master, data->index);
+
+	kfree(data);
+}
+
+static int svc_i3c_master_readb(struct svc_i3c_master *master, u8 *dst,
+				unsigned int len)
+{
+	int ret, i;
+	u32 reg;
+
+	for (i = 0; i < len; i++) {
+		ret = readl_poll_timeout(master->regs + SVC_I3C_MSTATUS, reg,
+					 SVC_I3C_MSTATUS_RXPEND(reg), 0, 1000);
+		if (ret)
+			return ret;
+
+		dst[i] = readl(master->regs + SVC_I3C_MRDATAB);
+	}
+
+	return 0;
+}
+
+static int svc_i3c_master_do_daa_locked(struct svc_i3c_master *master,
+					u8 *addrs, unsigned int *count)
+{
+	u64 prov_id[SVC_I3C_MAX_DEVS] = {}, nacking_prov_id = 0;
+	unsigned int dev_nb = 0, last_addr = 0;
+	u32 reg;
+	int ret, i;
+
+	while (true) {
+		/* Enter/proceed with DAA */
+		writel(SVC_I3C_MCTRL_REQUEST_PROC_DAA |
+		       SVC_I3C_MCTRL_TYPE_I3C |
+		       SVC_I3C_MCTRL_IBIRESP_NACK |
+		       SVC_I3C_MCTRL_DIR(SVC_I3C_MCTRL_DIR_WRITE),
+		       master->regs + SVC_I3C_MCTRL);
+
+		/*
+		 * Either one slave will send its ID, or the assignment process
+		 * is done.
+		 */
+		ret = readl_poll_timeout(master->regs + SVC_I3C_MSTATUS, reg,
+					 SVC_I3C_MSTATUS_RXPEND(reg) |
+					 SVC_I3C_MSTATUS_MCTRLDONE(reg),
+					 1, 1000);
+		if (ret)
+			return ret;
+
+		if (SVC_I3C_MSTATUS_RXPEND(reg)) {
+			u8 data[6];
+
+			/*
+			 * We only care about the 48-bit provisional ID yet to
+			 * be sure a device does not nack an address twice.
+			 * Otherwise, we would just need to flush the RX FIFO.
+			 */
+			ret = svc_i3c_master_readb(master, data, 6);
+			if (ret)
+				return ret;
+
+			for (i = 0; i < 6; i++)
+				prov_id[dev_nb] |= (u64)(data[i]) << (8 * (5 - i));
+
+			/* We do not care about the BCR and DCR yet */
+			ret = svc_i3c_master_readb(master, data, 2);
+			if (ret)
+				return ret;
+		} else if (SVC_I3C_MSTATUS_MCTRLDONE(reg)) {
+			if (SVC_I3C_MSTATUS_STATE_IDLE(reg) &&
+			    SVC_I3C_MSTATUS_COMPLETE(reg)) {
+				/*
+				 * All devices received and acked they dynamic
+				 * address, this is the natural end of the DAA
+				 * procedure.
+				 */
+				break;
+			} else if (SVC_I3C_MSTATUS_NACKED(reg)) {
+				/*
+				 * A slave device nacked the address, this is
+				 * allowed only once, DAA will be stopped and
+				 * then resumed. The same device is supposed to
+				 * answer again immediately and shall ack the
+				 * address this time.
+				 */
+				if (prov_id[dev_nb] == nacking_prov_id)
+					return -EIO;
+
+				dev_nb--;
+				nacking_prov_id = prov_id[dev_nb];
+				svc_i3c_master_emit_stop(master);
+
+				continue;
+			} else {
+				return -EIO;
+			}
+		}
+
+		/* Wait for the slave to be ready to receive its address */
+		ret = readl_poll_timeout(master->regs + SVC_I3C_MSTATUS, reg,
+					 SVC_I3C_MSTATUS_MCTRLDONE(reg) &&
+					 SVC_I3C_MSTATUS_STATE_DAA(reg) &&
+					 SVC_I3C_MSTATUS_BETWEEN(reg),
+					 0, 1000);
+		if (ret)
+			return ret;
+
+		/* Give the slave device a suitable dynamic address */
+		ret = i3c_master_get_free_addr(&master->base, last_addr + 1);
+		if (ret < 0)
+			return ret;
+
+		addrs[dev_nb] = ret;
+		dev_dbg(master->dev, "DAA: device %d assigned to 0x%02x\n",
+			dev_nb, addrs[dev_nb]);
+
+		writel(addrs[dev_nb], master->regs + SVC_I3C_MWDATAB);
+		last_addr = addrs[dev_nb++];
+	}
+
+	*count = dev_nb;
+
+	return 0;
+}
+
+static int svc_i3c_update_ibirules(struct svc_i3c_master *master)
+{
+	struct i3c_dev_desc *dev;
+	u32 reg_mbyte = 0, reg_nobyte = SVC_I3C_IBIRULES_NOBYTE;
+	unsigned int mbyte_addr_ok = 0, mbyte_addr_ko = 0, nobyte_addr_ok = 0,
+		nobyte_addr_ko = 0;
+	bool list_mbyte = false, list_nobyte = false;
+
+	/* Create the IBIRULES register for both cases */
+	i3c_bus_for_each_i3cdev(&master->base.bus, dev) {
+		if (I3C_BCR_DEVICE_ROLE(dev->info.bcr) == I3C_BCR_I3C_MASTER)
+			continue;
+
+		if (dev->info.bcr & I3C_BCR_IBI_PAYLOAD) {
+			reg_mbyte |= SVC_I3C_IBIRULES_ADDR(mbyte_addr_ok,
+							   dev->info.dyn_addr);
+
+			/* IBI rules cannot be applied to devices with MSb=1 */
+			if (dev->info.dyn_addr & BIT(7))
+				mbyte_addr_ko++;
+			else
+				mbyte_addr_ok++;
+		} else {
+			reg_nobyte |= SVC_I3C_IBIRULES_ADDR(nobyte_addr_ok,
+							    dev->info.dyn_addr);
+
+			/* IBI rules cannot be applied to devices with MSb=1 */
+			if (dev->info.dyn_addr & BIT(7))
+				nobyte_addr_ko++;
+			else
+				nobyte_addr_ok++;
+		}
+	}
+
+	/* Device list cannot be handled by hardware */
+	if (!mbyte_addr_ko && mbyte_addr_ok <= SVC_I3C_IBIRULES_ADDRS)
+		list_mbyte = true;
+
+	if (!nobyte_addr_ko && nobyte_addr_ok <= SVC_I3C_IBIRULES_ADDRS)
+		list_nobyte = true;
+
+	/* No list can be properly handled, return an error */
+	if (!list_mbyte && !list_nobyte)
+		return -ERANGE;
+
+	/* Pick the first list that can be handled by hardware, randomly */
+	if (list_mbyte)
+		writel(reg_mbyte, master->regs + SVC_I3C_IBIRULES);
+	else
+		writel(reg_nobyte, master->regs + SVC_I3C_IBIRULES);
+
+	return 0;
+}
+
+static int svc_i3c_master_do_daa(struct i3c_master_controller *m)
+{
+	struct svc_i3c_master *master = to_svc_i3c_master(m);
+	u8 addrs[SVC_I3C_MAX_DEVS];
+	unsigned long flags;
+	unsigned int dev_nb;
+	int ret, i;
+
+	spin_lock_irqsave(&master->xferqueue.lock, flags);
+	ret = svc_i3c_master_do_daa_locked(master, addrs, &dev_nb);
+	spin_unlock_irqrestore(&master->xferqueue.lock, flags);
+	if (ret)
+		goto emit_stop;
+
+	/* Register all devices who participated to the core */
+	for (i = 0; i < dev_nb; i++) {
+		ret = i3c_master_add_i3c_dev_locked(m, addrs[i]);
+		if (ret)
+			return ret;
+	}
+
+	/* Configure IBI auto-rules */
+	ret = svc_i3c_update_ibirules(master);
+	if (ret) {
+		dev_err(master->dev, "Cannot handle such a list of devices");
+		return ret;
+	}
+
+	return 0;
+
+emit_stop:
+	svc_i3c_master_emit_stop(master);
+	svc_i3c_master_clear_merrwarn(master);
+
+	return ret;
+}
+
+static int svc_i3c_master_read(struct svc_i3c_master *master,
+			       u8 *in, unsigned int len)
+{
+	int offset = 0, i, ret;
+	u32 mdctrl;
+
+	while (offset < len) {
+		unsigned int count;
+
+		ret = readl_poll_timeout(master->regs + SVC_I3C_MDATACTRL,
+					 mdctrl,
+					 !(mdctrl & SVC_I3C_MDATACTRL_RXEMPTY),
+					 0, 1000);
+		if (ret)
+			return ret;
+
+		count = SVC_I3C_MDATACTRL_RXCOUNT(mdctrl);
+		for (i = 0; i < count; i++)
+			in[offset + i] = readl(master->regs + SVC_I3C_MRDATAB);
+
+		offset += count;
+	}
+
+	return 0;
+}
+
+static int svc_i3c_master_write(struct svc_i3c_master *master,
+				const u8 *out, unsigned int len)
+{
+	int offset = 0, ret;
+	u32 mdctrl;
+
+	while (offset < len) {
+		ret = readl_poll_timeout(master->regs + SVC_I3C_MDATACTRL,
+					 mdctrl,
+					 !(mdctrl & SVC_I3C_MDATACTRL_TXFULL),
+					 0, 1000);
+		if (ret)
+			return ret;
+
+		/*
+		 * The last byte to be sent over the bus must either have the
+		 * "end" bit set or be written in MWDATABE.
+		 */
+		if (likely(offset < (len - 1)))
+			writel(out[offset++], master->regs + SVC_I3C_MWDATAB);
+		else
+			writel(out[offset++], master->regs + SVC_I3C_MWDATABE);
+	}
+
+	return 0;
+}
+
+static int svc_i3c_master_xfer(struct svc_i3c_master *master,
+			       bool rnw, unsigned int xfer_type, u8 addr,
+			       u8 *in, const u8 *out, unsigned int xfer_len,
+			       unsigned int read_len, bool continued)
+{
+	u32 reg;
+	int ret;
+
+	writel(SVC_I3C_MCTRL_REQUEST_START_ADDR |
+	       xfer_type |
+	       SVC_I3C_MCTRL_IBIRESP_NACK |
+	       SVC_I3C_MCTRL_DIR(rnw) |
+	       SVC_I3C_MCTRL_ADDR(addr) |
+	       SVC_I3C_MCTRL_RDTERM(read_len),
+	       master->regs + SVC_I3C_MCTRL);
+
+	ret = readl_poll_timeout(master->regs + SVC_I3C_MSTATUS, reg,
+				 SVC_I3C_MSTATUS_MCTRLDONE(reg), 0, 1000);
+	if (ret)
+		goto emit_stop;
+
+	if (rnw)
+		ret = svc_i3c_master_read(master, in, xfer_len);
+	else
+		ret = svc_i3c_master_write(master, out, xfer_len);
+	if (ret)
+		goto emit_stop;
+
+	ret = readl_poll_timeout(master->regs + SVC_I3C_MSTATUS, reg,
+				 SVC_I3C_MSTATUS_COMPLETE(reg), 0, 1000);
+	if (ret)
+		goto emit_stop;
+
+	if (!continued)
+		svc_i3c_master_emit_stop(master);
+
+	return 0;
+
+emit_stop:
+	svc_i3c_master_emit_stop(master);
+	svc_i3c_master_clear_merrwarn(master);
+
+	return ret;
+}
+
+static struct svc_i3c_xfer *
+svc_i3c_master_alloc_xfer(struct svc_i3c_master *master, unsigned int ncmds)
+{
+	struct svc_i3c_xfer *xfer;
+
+	xfer = kzalloc(struct_size(xfer, cmds, ncmds), GFP_KERNEL);
+	if (!xfer)
+		return NULL;
+
+	INIT_LIST_HEAD(&xfer->node);
+	xfer->ncmds = ncmds;
+	xfer->ret = -ETIMEDOUT;
+
+	return xfer;
+}
+
+static void svc_i3c_master_free_xfer(struct svc_i3c_xfer *xfer)
+{
+	kfree(xfer);
+}
+
+static void svc_i3c_master_dequeue_xfer_locked(struct svc_i3c_master *master,
+					       struct svc_i3c_xfer *xfer)
+{
+	if (master->xferqueue.cur == xfer)
+		master->xferqueue.cur = NULL;
+	else
+		list_del_init(&xfer->node);
+}
+
+static void svc_i3c_master_dequeue_xfer(struct svc_i3c_master *master,
+					struct svc_i3c_xfer *xfer)
+{
+	unsigned long flags;
+
+	spin_lock_irqsave(&master->xferqueue.lock, flags);
+	svc_i3c_master_dequeue_xfer_locked(master, xfer);
+	spin_unlock_irqrestore(&master->xferqueue.lock, flags);
+}
+
+static void svc_i3c_master_start_xfer_locked(struct svc_i3c_master *master)
+{
+	struct svc_i3c_xfer *xfer = master->xferqueue.cur;
+	int ret, i;
+
+	if (!xfer)
+		return;
+
+	for (i = 0; i < xfer->ncmds; i++) {
+		struct svc_i3c_cmd *cmd = &xfer->cmds[i];
+
+		ret = svc_i3c_master_xfer(master, cmd->rnw, xfer->type,
+					  cmd->addr, cmd->in, cmd->out,
+					  cmd->len, cmd->read_len,
+					  cmd->continued);
+		if (ret)
+			break;
+	}
+
+	xfer->ret = ret;
+	complete(&xfer->comp);
+
+	if (ret < 0)
+		svc_i3c_master_dequeue_xfer_locked(master, xfer);
+
+	xfer = list_first_entry_or_null(&master->xferqueue.list,
+					struct svc_i3c_xfer,
+					node);
+	if (xfer)
+		list_del_init(&xfer->node);
+
+	master->xferqueue.cur = xfer;
+	svc_i3c_master_start_xfer_locked(master);
+}
+
+static void svc_i3c_master_enqueue_xfer(struct svc_i3c_master *master,
+					struct svc_i3c_xfer *xfer)
+{
+	unsigned long flags;
+
+	init_completion(&xfer->comp);
+	spin_lock_irqsave(&master->xferqueue.lock, flags);
+	if (master->xferqueue.cur) {
+		list_add_tail(&xfer->node, &master->xferqueue.list);
+	} else {
+		master->xferqueue.cur = xfer;
+		svc_i3c_master_start_xfer_locked(master);
+	}
+	spin_unlock_irqrestore(&master->xferqueue.lock, flags);
+}
+
+static bool
+svc_i3c_master_supports_ccc_cmd(struct i3c_master_controller *master,
+				const struct i3c_ccc_cmd *cmd)
+{
+	/* No software support for CCC commands targeting more than one slave */
+	return (cmd->ndests == 1);
+}
+
+static int svc_i3c_master_send_bdcast_ccc_cmd(struct svc_i3c_master *master,
+					      struct i3c_ccc_cmd *ccc)
+{
+	unsigned int xfer_len = ccc->dests[0].payload.len + 1;
+	struct svc_i3c_xfer *xfer;
+	struct svc_i3c_cmd *cmd;
+	u8 *buf;
+	int ret;
+
+	xfer = svc_i3c_master_alloc_xfer(master, 1);
+	if (!xfer)
+		return -ENOMEM;
+
+	buf = kmalloc(xfer_len, GFP_KERNEL);
+	if (!buf) {
+		svc_i3c_master_free_xfer(xfer);
+		return -ENOMEM;
+	}
+
+	buf[0] = ccc->id;
+	memcpy(&buf[1], ccc->dests[0].payload.data, ccc->dests[0].payload.len);
+
+	xfer->type = SVC_I3C_MCTRL_TYPE_I3C;
+
+	cmd = &xfer->cmds[0];
+	cmd->addr = ccc->dests[0].addr;
+	cmd->rnw = ccc->rnw;
+	cmd->in = NULL;
+	cmd->out = buf;
+	cmd->len = xfer_len;
+	cmd->read_len = 0;
+	cmd->continued = false;
+
+	svc_i3c_master_enqueue_xfer(master, xfer);
+	if (!wait_for_completion_timeout(&xfer->comp, msecs_to_jiffies(1000)))
+		svc_i3c_master_dequeue_xfer(master, xfer);
+
+	ret = xfer->ret;
+	kfree(buf);
+	svc_i3c_master_free_xfer(xfer);
+
+	return ret;
+}
+
+static int svc_i3c_master_send_direct_ccc_cmd(struct svc_i3c_master *master,
+					      struct i3c_ccc_cmd *ccc)
+{
+	unsigned int xfer_len = ccc->dests[0].payload.len;
+	unsigned int read_len = ccc->rnw ? xfer_len : 0;
+	struct svc_i3c_xfer *xfer;
+	struct svc_i3c_cmd *cmd;
+	int ret;
+
+	xfer = svc_i3c_master_alloc_xfer(master, 2);
+	if (!xfer)
+		return -ENOMEM;
+
+	xfer->type = SVC_I3C_MCTRL_TYPE_I3C;
+
+	/* Broadcasted message */
+	cmd = &xfer->cmds[0];
+	cmd->addr = I3C_BROADCAST_ADDR;
+	cmd->rnw = 0;
+	cmd->in = NULL;
+	cmd->out = &ccc->id;
+	cmd->len = 1;
+	cmd->read_len = 0;
+	cmd->continued = true;
+
+	/* Directed message */
+	cmd = &xfer->cmds[1];
+	cmd->addr = ccc->dests[0].addr;
+	cmd->rnw = ccc->rnw;
+	cmd->in = ccc->rnw ? ccc->dests[0].payload.data : NULL;
+	cmd->out = ccc->rnw ? NULL : ccc->dests[0].payload.data,
+	cmd->len = xfer_len;
+	cmd->read_len = read_len;
+	cmd->continued = false;
+
+	svc_i3c_master_enqueue_xfer(master, xfer);
+	if (!wait_for_completion_timeout(&xfer->comp, msecs_to_jiffies(1000)))
+		svc_i3c_master_dequeue_xfer(master, xfer);
+
+	ret = xfer->ret;
+	svc_i3c_master_free_xfer(xfer);
+
+	return ret;
+}
+
+static int svc_i3c_master_send_ccc_cmd(struct i3c_master_controller *m,
+				       struct i3c_ccc_cmd *cmd)
+{
+	struct svc_i3c_master *master = to_svc_i3c_master(m);
+	bool broadcast = cmd->id < 0x80;
+
+	if (broadcast)
+		return svc_i3c_master_send_bdcast_ccc_cmd(master, cmd);
+	else
+		return svc_i3c_master_send_direct_ccc_cmd(master, cmd);
+}
+
+static int svc_i3c_master_priv_xfers(struct i3c_dev_desc *dev,
+				     struct i3c_priv_xfer *xfers,
+				     int nxfers)
+{
+	struct i3c_master_controller *m = i3c_dev_get_master(dev);
+	struct svc_i3c_master *master = to_svc_i3c_master(m);
+	struct svc_i3c_i2c_dev_data *data = i3c_dev_get_master_data(dev);
+	struct svc_i3c_xfer *xfer;
+	int ret, i;
+
+	xfer = svc_i3c_master_alloc_xfer(master, nxfers);
+	if (!xfer)
+		return -ENOMEM;
+
+	xfer->type = SVC_I3C_MCTRL_TYPE_I3C;
+
+	for (i = 0; i < nxfers; i++) {
+		struct svc_i3c_cmd *cmd = &xfer->cmds[i];
+
+		cmd->addr = master->addrs[data->index];
+		cmd->rnw = xfers[i].rnw;
+		cmd->in = xfers[i].rnw ? xfers[i].data.in : NULL;
+		cmd->out = xfers[i].rnw ? NULL : xfers[i].data.out;
+		cmd->len = xfers[i].len;
+		cmd->read_len = xfers[i].rnw ? xfers[i].len : 0;
+		cmd->continued = (i + 1) < nxfers;
+	}
+
+	svc_i3c_master_enqueue_xfer(master, xfer);
+	if (!wait_for_completion_timeout(&xfer->comp, msecs_to_jiffies(1000)))
+		svc_i3c_master_dequeue_xfer(master, xfer);
+
+	ret = xfer->ret;
+	svc_i3c_master_free_xfer(xfer);
+
+	return ret;
+}
+
+static int svc_i3c_master_i2c_xfers(struct i2c_dev_desc *dev,
+				    const struct i2c_msg *xfers,
+				    int nxfers)
+{
+	struct i3c_master_controller *m = i2c_dev_get_master(dev);
+	struct svc_i3c_master *master = to_svc_i3c_master(m);
+	struct svc_i3c_i2c_dev_data *data = i2c_dev_get_master_data(dev);
+	struct svc_i3c_xfer *xfer;
+	int ret, i;
+
+	xfer = svc_i3c_master_alloc_xfer(master, nxfers);
+	if (!xfer)
+		return -ENOMEM;
+
+	xfer->type = SVC_I3C_MCTRL_TYPE_I2C;
+
+	for (i = 0; i < nxfers; i++) {
+		struct svc_i3c_cmd *cmd = &xfer->cmds[i];
+
+		cmd->addr = master->addrs[data->index];
+		cmd->rnw = xfers[i].flags & I2C_M_RD;
+		cmd->in = cmd->rnw ? xfers[i].buf : NULL;
+		cmd->out = cmd->rnw ? NULL : xfers[i].buf;
+		cmd->len = xfers[i].len;
+		cmd->read_len = cmd->rnw ? xfers[i].len : 0;
+		cmd->continued = (i + 1 < nxfers);
+	}
+
+	svc_i3c_master_enqueue_xfer(master, xfer);
+	if (!wait_for_completion_timeout(&xfer->comp, msecs_to_jiffies(1000)))
+		svc_i3c_master_dequeue_xfer(master, xfer);
+
+	ret = xfer->ret;
+	svc_i3c_master_free_xfer(xfer);
+
+	return ret;
+}
+
+static int svc_i3c_master_request_ibi(struct i3c_dev_desc *dev,
+				      const struct i3c_ibi_setup *req)
+{
+	struct i3c_master_controller *m = i3c_dev_get_master(dev);
+	struct svc_i3c_master *master = to_svc_i3c_master(m);
+	struct svc_i3c_i2c_dev_data *data = i3c_dev_get_master_data(dev);
+	unsigned long flags;
+	unsigned int i;
+
+	if (dev->ibi->max_payload_len > SVC_I3C_FIFO_SIZE) {
+		dev_err(master->dev, "IBI max payload %d should be < %d\n",
+			dev->ibi->max_payload_len, SVC_I3C_FIFO_SIZE);
+		return -ERANGE;
+	}
+
+	data->ibi_pool = i3c_generic_ibi_alloc_pool(dev, req);
+	if (IS_ERR(data->ibi_pool))
+		return PTR_ERR(data->ibi_pool);
+
+	spin_lock_irqsave(&master->ibi.lock, flags);
+	for (i = 0; i < master->ibi.num_slots; i++) {
+		if (!master->ibi.slots[i]) {
+			data->ibi = i;
+			master->ibi.slots[i] = dev;
+			break;
+		}
+	}
+	spin_unlock_irqrestore(&master->ibi.lock, flags);
+
+	if (i < master->ibi.num_slots)
+		return 0;
+
+	i3c_generic_ibi_free_pool(data->ibi_pool);
+	data->ibi_pool = NULL;
+
+	return -ENOSPC;
+}
+
+static void svc_i3c_master_free_ibi(struct i3c_dev_desc *dev)
+{
+	struct i3c_master_controller *m = i3c_dev_get_master(dev);
+	struct svc_i3c_master *master = to_svc_i3c_master(m);
+	struct svc_i3c_i2c_dev_data *data = i3c_dev_get_master_data(dev);
+	unsigned long flags;
+
+	spin_lock_irqsave(&master->ibi.lock, flags);
+	master->ibi.slots[data->ibi] = NULL;
+	data->ibi = -1;
+	spin_unlock_irqrestore(&master->ibi.lock, flags);
+
+	i3c_generic_ibi_free_pool(data->ibi_pool);
+}
+
+static int svc_i3c_master_enable_ibi(struct i3c_dev_desc *dev)
+{
+	struct i3c_master_controller *m = i3c_dev_get_master(dev);
+
+	return i3c_master_enec_locked(m, dev->info.dyn_addr, I3C_CCC_EVENT_SIR);
+}
+
+static int svc_i3c_master_disable_ibi(struct i3c_dev_desc *dev)
+{
+	struct i3c_master_controller *m = i3c_dev_get_master(dev);
+
+	return i3c_master_disec_locked(m, dev->info.dyn_addr, I3C_CCC_EVENT_SIR);
+}
+
+static void svc_i3c_master_recycle_ibi_slot(struct i3c_dev_desc *dev,
+					    struct i3c_ibi_slot *slot)
+{
+	struct svc_i3c_i2c_dev_data *data = i3c_dev_get_master_data(dev);
+
+	i3c_generic_ibi_recycle_slot(data->ibi_pool, slot);
+}
+
+static const struct i3c_master_controller_ops svc_i3c_master_ops = {
+	.bus_init = svc_i3c_master_bus_init,
+	.bus_cleanup = svc_i3c_master_bus_cleanup,
+	.attach_i3c_dev = svc_i3c_master_attach_i3c_dev,
+	.detach_i3c_dev = svc_i3c_master_detach_i3c_dev,
+	.reattach_i3c_dev = svc_i3c_master_reattach_i3c_dev,
+	.attach_i2c_dev = svc_i3c_master_attach_i2c_dev,
+	.detach_i2c_dev = svc_i3c_master_detach_i2c_dev,
+	.do_daa = svc_i3c_master_do_daa,
+	.supports_ccc_cmd = svc_i3c_master_supports_ccc_cmd,
+	.send_ccc_cmd = svc_i3c_master_send_ccc_cmd,
+	.priv_xfers = svc_i3c_master_priv_xfers,
+	.i2c_xfers = svc_i3c_master_i2c_xfers,
+	.request_ibi = svc_i3c_master_request_ibi,
+	.free_ibi = svc_i3c_master_free_ibi,
+	.recycle_ibi_slot = svc_i3c_master_recycle_ibi_slot,
+	.enable_ibi = svc_i3c_master_enable_ibi,
+	.disable_ibi = svc_i3c_master_disable_ibi,
+};
+
+static void svc_i3c_master_reset(struct svc_i3c_master *master)
+{
+	u32 reg;
+
+	/* Clear pending warnings */
+	writel(readl(master->regs + SVC_I3C_MERRWARN),
+	       master->regs + SVC_I3C_MERRWARN);
+
+	/* Set RX and TX tigger levels, flush FIFOs */
+	reg = SVC_I3C_MDATACTRL_FLUSHTB |
+	      SVC_I3C_MDATACTRL_FLUSHRB |
+	      SVC_I3C_MDATACTRL_UNLOCK_TRIG |
+	      SVC_I3C_MDATACTRL_TXTRIG_FIFO_NOT_FULL |
+	      SVC_I3C_MDATACTRL_RXTRIG_FIFO_NOT_EMPTY;
+	writel(reg, master->regs + SVC_I3C_MDATACTRL);
+
+	svc_i3c_master_disable_interrupts(master);
+}
+
+static int svc_i3c_master_probe(struct platform_device *pdev)
+{
+	struct device *dev = &pdev->dev;
+	struct svc_i3c_master *master;
+	int ret;
+
+	master = devm_kzalloc(dev, sizeof(*master), GFP_KERNEL);
+	if (!master)
+		return -ENOMEM;
+
+	master->regs = devm_platform_ioremap_resource(pdev, 0);
+	if (IS_ERR(master->regs))
+		return PTR_ERR(master->regs);
+
+	master->pclk = devm_clk_get(dev, "pclk");
+	if (IS_ERR(master->pclk))
+		return PTR_ERR(master->pclk);
+
+	master->fclk = devm_clk_get(dev, "fast_clk");
+	if (IS_ERR(master->fclk))
+		return PTR_ERR(master->fclk);
+
+	master->sclk = devm_clk_get(dev, "slow_clk");
+	if (IS_ERR(master->sclk))
+		return PTR_ERR(master->sclk);
+
+	master->irq = platform_get_irq(pdev, 0);
+	if (master->irq <= 0)
+		return -ENOENT;
+
+	master->dev = dev;
+
+	svc_i3c_master_reset(master);
+
+	ret = clk_prepare_enable(master->pclk);
+	if (ret)
+		return ret;
+
+	ret = clk_prepare_enable(master->fclk);
+	if (ret)
+		goto err_disable_pclk;
+
+	ret = clk_prepare_enable(master->sclk);
+	if (ret)
+		goto err_disable_fclk;
+
+	INIT_WORK(&master->hj_work, svc_i3c_master_hj_work);
+	INIT_WORK(&master->ibi_work, svc_i3c_master_ibi_work);
+	ret = devm_request_irq(dev, master->irq, svc_i3c_master_irq_handler,
+			       IRQF_NO_SUSPEND, "svc-i3c-irq", master);
+	if (ret)
+		goto err_disable_sclk;
+
+	master->free_slots = GENMASK(SVC_I3C_MAX_DEVS - 1, 0);
+
+	spin_lock_init(&master->xferqueue.lock);
+	INIT_LIST_HEAD(&master->xferqueue.list);
+
+	spin_lock_init(&master->ibi.lock);
+	master->ibi.num_slots = SVC_I3C_MAX_DEVS;
+	master->ibi.slots = devm_kcalloc(&pdev->dev, master->ibi.num_slots,
+					 sizeof(*master->ibi.slots),
+					 GFP_KERNEL);
+	if (!master->ibi.slots) {
+		ret = -ENOMEM;
+		goto err_disable_sclk;
+	}
+
+	platform_set_drvdata(pdev, master);
+
+	/* Register the master */
+	ret = i3c_master_register(&master->base, &pdev->dev,
+				  &svc_i3c_master_ops, false);
+	if (ret)
+		goto err_disable_sclk;
+
+	return 0;
+
+err_disable_sclk:
+	clk_disable_unprepare(master->sclk);
+
+err_disable_fclk:
+	clk_disable_unprepare(master->fclk);
+
+err_disable_pclk:
+	clk_disable_unprepare(master->pclk);
+
+	return ret;
+}
+
+static int svc_i3c_master_remove(struct platform_device *pdev)
+{
+	struct svc_i3c_master *master = platform_get_drvdata(pdev);
+	int ret;
+
+	ret = i3c_master_unregister(&master->base);
+	if (ret)
+		return ret;
+
+	clk_disable_unprepare(master->pclk);
+	clk_disable_unprepare(master->fclk);
+	clk_disable_unprepare(master->sclk);
+
+	return 0;
+}
+
+static const struct of_device_id svc_i3c_master_of_match_tbl[] = {
+	{ .compatible = "silvaco,i3c-master" },
+	{ /* sentinel */ },
+};
+
+static struct platform_driver svc_i3c_master = {
+	.probe = svc_i3c_master_probe,
+	.remove = svc_i3c_master_remove,
+	.driver = {
+		.name = "silvaco-i3c-master",
+		.of_match_table = svc_i3c_master_of_match_tbl,
+	},
+};
+module_platform_driver(svc_i3c_master);
+
+MODULE_AUTHOR("Conor Culhane <conor.culhane@silvaco.com>");
+MODULE_AUTHOR("Miquel Raynal <miquel.raynal@bootlin.com>");
+MODULE_DESCRIPTION("Silvaco dual-role I3C master driver");
+MODULE_LICENSE("GPL v2");
diff --git a/drivers/i3c/mctp/Kconfig b/drivers/i3c/mctp/Kconfig
new file mode 100644
index 000000000000..fe635940138b
--- /dev/null
+++ b/drivers/i3c/mctp/Kconfig
@@ -0,0 +1,14 @@
+# SPDX-License-Identifier: GPL-2.0-only
+config I3C_MCTP
+    tristate "I3C Controller MCTP driver"
+    depends on I3C
+help
+    Say yes here to enable the I3C MCTP driver for I3C HW that is
+    configured as an I3C Controller Device on the I3C Bus.
+
+config I3C_TARGET_MCTP
+    tristate "I3C Target MCTP driver"
+    depends on I3C
+help
+    Say yes here to enable the I3C MCTP driver for I3C HW that is
+    configured as an I3C Target Device on the I3C Bus.
diff --git a/drivers/i3c/mctp/Makefile b/drivers/i3c/mctp/Makefile
new file mode 100644
index 000000000000..05eb78684843
--- /dev/null
+++ b/drivers/i3c/mctp/Makefile
@@ -0,0 +1,3 @@
+# SPDX-License-Identifier: GPL-2.0-only
+obj-$(CONFIG_I3C_MCTP)		+= i3c-mctp.o
+obj-$(CONFIG_I3C_TARGET_MCTP)	+= i3c-target-mctp.o
diff --git a/drivers/i3c/mctp/i3c-mctp.c b/drivers/i3c/mctp/i3c-mctp.c
new file mode 100644
index 000000000000..1bb4f4b31968
--- /dev/null
+++ b/drivers/i3c/mctp/i3c-mctp.c
@@ -0,0 +1,629 @@
+// SPDX-License-Identifier: GPL-2.0
+/* Copyright (C) 2022 Intel Corporation.*/
+
+#include <linux/cdev.h>
+#include <linux/fs.h>
+#include <linux/module.h>
+#include <linux/platform_device.h>
+#include <linux/poll.h>
+#include <linux/preempt.h>
+#include <linux/ptr_ring.h>
+#include <linux/slab.h>
+#include <linux/timer.h>
+#include <linux/types.h>
+#include <linux/workqueue.h>
+
+#include <linux/i3c/device.h>
+
+#include <linux/i3c/mctp/i3c-mctp.h>
+
+#define I3C_MCTP_MINORS				32
+#define CCC_DEVICE_STATUS_PENDING_INTR(x)	(((x) & GENMASK(3, 0)) >> 0)
+#define POLLING_TIMEOUT_MS			50
+#define MCTP_INTERRUPT_NUMBER			1
+#define RX_RING_COUNT				16
+#define I3C_MCTP_MIN_TRANSFER_SIZE		69
+#define I3C_MCTP_IBI_PAYLOAD_SIZE		2
+
+struct i3c_mctp {
+	struct i3c_device *i3c;
+	struct cdev cdev;
+	struct device *dev;
+	struct delayed_work polling_work;
+	struct platform_device *i3c_peci;
+	int id;
+	/*
+	 * Restrict an access to the /dev descriptor to one
+	 * user at a time.
+	 */
+	spinlock_t device_file_lock;
+	int device_open;
+	/* Currently only one userspace client is supported */
+	struct i3c_mctp_client *default_client;
+	struct i3c_mctp_client *peci_client;
+	u16 max_read_len;
+	u16 max_write_len;
+};
+
+struct i3c_mctp_client {
+	struct i3c_mctp *priv;
+	struct ptr_ring rx_queue;
+	wait_queue_head_t wait_queue;
+};
+
+static struct class *i3c_mctp_class;
+static dev_t i3c_mctp_devt;
+static DEFINE_IDA(i3c_mctp_ida);
+
+static struct kmem_cache *packet_cache;
+
+/**
+ * i3c_mctp_packet_alloc() - allocates i3c_mctp_packet
+ *
+ * @flags: the type of memory to allocate
+ *
+ * Allocates i3c_mctp_packet via slab allocation
+ * Return: pointer to the packet, NULL if some error occurred
+ */
+void *i3c_mctp_packet_alloc(gfp_t flags)
+{
+	return kmem_cache_alloc(packet_cache, flags);
+}
+EXPORT_SYMBOL_GPL(i3c_mctp_packet_alloc);
+
+/**
+ * i3c_mctp_packet_free() - frees i3c_mctp_packet
+ *
+ * @packet: pointer to the packet which should be freed
+ *
+ * Frees i3c_mctp_packet previously allocated via slab allocation
+ */
+void i3c_mctp_packet_free(void *packet)
+{
+	kmem_cache_free(packet_cache, packet);
+}
+EXPORT_SYMBOL_GPL(i3c_mctp_packet_free);
+
+static void i3c_mctp_client_free(struct i3c_mctp_client *client)
+{
+	ptr_ring_cleanup(&client->rx_queue, &i3c_mctp_packet_free);
+
+	kfree(client);
+}
+
+static struct i3c_mctp_client *i3c_mctp_client_alloc(struct i3c_mctp *priv)
+{
+	struct i3c_mctp_client *client;
+	int ret;
+
+	client = kzalloc(sizeof(*client), GFP_KERNEL);
+	if (!client)
+		goto out;
+
+	client->priv = priv;
+	ret = ptr_ring_init(&client->rx_queue, RX_RING_COUNT, GFP_KERNEL);
+	if (ret)
+		return ERR_PTR(ret);
+	init_waitqueue_head(&client->wait_queue);
+out:
+	return client;
+}
+
+static struct i3c_mctp_client *i3c_mctp_find_client(struct i3c_mctp *priv,
+						    struct i3c_mctp_packet *packet)
+{
+	u8 *msg_hdr = (u8 *)packet->data.payload;
+	u8 mctp_type = msg_hdr[MCTP_MSG_HDR_MSG_TYPE_OFFSET];
+	u16 vendor = (msg_hdr[MCTP_MSG_HDR_VENDOR_OFFSET] << 8
+		      | msg_hdr[MCTP_MSG_HDR_VENDOR_OFFSET + 1]);
+	u8 intel_msg_op_code = msg_hdr[MCTP_MSG_HDR_OPCODE_OFFSET];
+
+	if (priv->peci_client && mctp_type == MCTP_MSG_TYPE_VDM_PCI &&
+	    vendor == MCTP_VDM_PCI_INTEL_VENDOR_ID && intel_msg_op_code == MCTP_VDM_PCI_INTEL_PECI)
+		return priv->peci_client;
+
+	return priv->default_client;
+}
+
+static struct i3c_mctp_packet *i3c_mctp_read_packet(struct i3c_device *i3c)
+{
+	struct i3c_mctp *priv = dev_get_drvdata(i3cdev_to_dev(i3c));
+	struct i3c_mctp_packet *rx_packet;
+	struct i3c_priv_xfer xfers = {
+		.rnw = true,
+	};
+	int ret;
+
+	rx_packet = i3c_mctp_packet_alloc(GFP_KERNEL);
+	if (!rx_packet)
+		return ERR_PTR(-ENOMEM);
+
+	rx_packet->size = I3C_MCTP_PACKET_SIZE;
+	xfers.len = rx_packet->size;
+	xfers.data.in = &rx_packet->data;
+
+	/* Check against packet size + PEC byte to make sure that we always try to read max */
+	if (priv->max_read_len != xfers.len + 1) {
+		dev_dbg(i3cdev_to_dev(i3c), "Length mismatch. MRL = %d, xfers.len = %d",
+			priv->max_read_len, xfers.len);
+		i3c_mctp_packet_free(rx_packet);
+		return ERR_PTR(-EINVAL);
+	}
+
+	ret = i3c_device_do_priv_xfers(i3c, &xfers, 1);
+	if (ret) {
+		i3c_mctp_packet_free(rx_packet);
+		return ERR_PTR(ret);
+	}
+	rx_packet->size = xfers.len;
+
+	return rx_packet;
+}
+
+static void i3c_mctp_dispatch_packet(struct i3c_mctp *priv, struct i3c_mctp_packet *packet)
+{
+	struct i3c_mctp_client *client = i3c_mctp_find_client(priv, packet);
+	int ret;
+
+	ret = ptr_ring_produce(&client->rx_queue, packet);
+	if (ret)
+		i3c_mctp_packet_free(packet);
+	else
+		wake_up_all(&client->wait_queue);
+}
+
+static void i3c_mctp_polling_work(struct work_struct *work)
+{
+	struct i3c_mctp *priv = container_of(to_delayed_work(work), struct i3c_mctp, polling_work);
+	struct i3c_device *i3cdev = priv->i3c;
+	struct i3c_mctp_packet *rx_packet;
+	struct i3c_device_info info;
+	int ret;
+
+	i3c_device_get_info(i3cdev, &info);
+	ret = i3c_device_getstatus_ccc(i3cdev, &info);
+	if (ret)
+		return;
+
+	if (CCC_DEVICE_STATUS_PENDING_INTR(info.status) != MCTP_INTERRUPT_NUMBER)
+		return;
+
+	rx_packet = i3c_mctp_read_packet(i3cdev);
+	if (IS_ERR(rx_packet))
+		goto out;
+
+	i3c_mctp_dispatch_packet(priv, rx_packet);
+out:
+	schedule_delayed_work(&priv->polling_work, msecs_to_jiffies(POLLING_TIMEOUT_MS));
+}
+
+static ssize_t i3c_mctp_write(struct file *file, const char __user *buf, size_t count,
+			      loff_t *f_pos)
+{
+	struct i3c_mctp *priv = file->private_data;
+	struct i3c_device *i3c = priv->i3c;
+	struct i3c_priv_xfer xfers = {
+		.rnw = false,
+		.len = count,
+	};
+	u8 *data;
+	int ret;
+
+	/*
+	 * Check against packet size + PEC byte
+	 * to not send more data than it was set in the probe
+	 */
+	if (priv->max_write_len < xfers.len + 1) {
+		dev_dbg(i3cdev_to_dev(i3c), "Length mismatch. MWL = %d, xfers.len = %d",
+			priv->max_write_len, xfers.len);
+		return -EINVAL;
+	}
+
+	data = memdup_user(buf, count);
+	if (IS_ERR(data))
+		return PTR_ERR(data);
+
+	xfers.data.out = data;
+
+	ret = i3c_device_do_priv_xfers(i3c, &xfers, 1);
+	kfree(data);
+	return ret ?: count;
+}
+
+static ssize_t i3c_mctp_read(struct file *file, char __user *buf, size_t count, loff_t *f_pos)
+{
+	struct i3c_mctp *priv = file->private_data;
+	struct i3c_mctp_client *client = priv->default_client;
+	struct i3c_mctp_packet *rx_packet;
+
+	if (count > sizeof(rx_packet->data))
+		count = sizeof(rx_packet->data);
+
+	rx_packet = ptr_ring_consume(&client->rx_queue);
+	if (!rx_packet)
+		return -EAGAIN;
+
+	if (count > rx_packet->size)
+		count = rx_packet->size;
+
+	if (copy_to_user(buf, &rx_packet->data, count))
+		return -EFAULT;
+
+	i3c_mctp_packet_free(rx_packet);
+
+	return count;
+}
+
+static int i3c_mctp_open(struct inode *inode, struct file *file)
+{
+	struct i3c_mctp *priv = container_of(inode->i_cdev, struct i3c_mctp, cdev);
+
+	spin_lock(&priv->device_file_lock);
+	if (priv->device_open) {
+		spin_unlock(&priv->device_file_lock);
+		return -EBUSY;
+	}
+	priv->device_open++;
+	spin_unlock(&priv->device_file_lock);
+
+	file->private_data = priv;
+
+	return 0;
+}
+
+static int i3c_mctp_release(struct inode *inode, struct file *file)
+{
+	struct i3c_mctp *priv = file->private_data;
+
+	spin_lock(&priv->device_file_lock);
+	priv->device_open--;
+	spin_unlock(&priv->device_file_lock);
+
+	file->private_data = NULL;
+
+	return 0;
+}
+
+static __poll_t i3c_mctp_poll(struct file *file, struct poll_table_struct *pt)
+{
+	struct i3c_mctp *priv = file->private_data;
+	__poll_t ret = 0;
+
+	poll_wait(file, &priv->default_client->wait_queue, pt);
+
+	if (__ptr_ring_peek(&priv->default_client->rx_queue))
+		ret |= EPOLLIN;
+
+	return ret;
+}
+
+static const struct file_operations i3c_mctp_fops = {
+	.owner = THIS_MODULE,
+	.read = i3c_mctp_read,
+	.write = i3c_mctp_write,
+	.poll = i3c_mctp_poll,
+	.open = i3c_mctp_open,
+	.release = i3c_mctp_release,
+};
+
+/**
+ * i3c_mctp_add_peci_client() - registers PECI client
+ * @i3c: I3C device to get the PECI client for
+ *
+ * Return: pointer to PECI client, -ENOMEM - in case of client alloc fault
+ */
+struct i3c_mctp_client *i3c_mctp_add_peci_client(struct i3c_device *i3c)
+{
+	struct i3c_mctp *priv = dev_get_drvdata(i3cdev_to_dev(i3c));
+	struct i3c_mctp_client *client;
+
+	client = i3c_mctp_client_alloc(priv);
+	if (IS_ERR(client))
+		return ERR_PTR(-ENOMEM);
+
+	priv->peci_client = client;
+
+	return priv->peci_client;
+}
+EXPORT_SYMBOL_GPL(i3c_mctp_add_peci_client);
+
+/**
+ * i3c_mctp_remove_peci_client() - un-registers PECI client
+ * @client: i3c_mctp_client to be freed
+ */
+void i3c_mctp_remove_peci_client(struct i3c_mctp_client *client)
+{
+	struct i3c_mctp *priv = client->priv;
+
+	i3c_mctp_client_free(priv->peci_client);
+
+	priv->peci_client = NULL;
+}
+EXPORT_SYMBOL_GPL(i3c_mctp_remove_peci_client);
+
+static struct i3c_mctp *i3c_mctp_alloc(struct i3c_device *i3c)
+{
+	struct i3c_mctp *priv;
+	int id;
+
+	priv = devm_kzalloc(i3cdev_to_dev(i3c), sizeof(*priv), GFP_KERNEL);
+	if (!priv)
+		return ERR_PTR(-ENOMEM);
+
+	id = ida_alloc(&i3c_mctp_ida, GFP_KERNEL);
+	if (id < 0) {
+		pr_err("i3c_mctp: no minor number available!\n");
+		return ERR_PTR(id);
+	}
+
+	priv->id = id;
+	priv->i3c = i3c;
+
+	spin_lock_init(&priv->device_file_lock);
+
+	return priv;
+}
+
+static void i3c_mctp_ibi_handler(struct i3c_device *dev, const struct i3c_ibi_payload *payload)
+{
+	struct i3c_mctp *priv = dev_get_drvdata(i3cdev_to_dev(dev));
+	struct i3c_mctp_packet *rx_packet;
+
+	rx_packet = i3c_mctp_read_packet(dev);
+	if (IS_ERR(rx_packet))
+		return;
+
+	i3c_mctp_dispatch_packet(priv, rx_packet);
+}
+
+static int i3c_mctp_init(struct i3c_driver *drv)
+{
+	int ret;
+
+	packet_cache = kmem_cache_create_usercopy("mctp-i3c-packet",
+						  sizeof(struct i3c_mctp_packet), 0, 0, 0,
+						  sizeof(struct i3c_mctp_packet), NULL);
+	if (IS_ERR(packet_cache)) {
+		ret = PTR_ERR(packet_cache);
+		goto out;
+	}
+
+	/* Dynamically request unused major number */
+	ret = alloc_chrdev_region(&i3c_mctp_devt, 0, I3C_MCTP_MINORS, "i3c-mctp");
+	if (ret)
+		goto out;
+
+	/* Create a class to populate sysfs entries*/
+	i3c_mctp_class = class_create(THIS_MODULE, "i3c-mctp");
+	if (IS_ERR(i3c_mctp_class)) {
+		ret = PTR_ERR(i3c_mctp_class);
+		goto out_unreg_chrdev;
+	}
+
+	i3c_driver_register(drv);
+
+	return 0;
+
+out_unreg_chrdev:
+	unregister_chrdev_region(i3c_mctp_devt, I3C_MCTP_MINORS);
+out:
+	pr_err("i3c_mctp: driver initialisation failed\n");
+	return ret;
+}
+
+static void i3c_mctp_free(struct i3c_driver *drv)
+{
+	i3c_driver_unregister(drv);
+	class_destroy(i3c_mctp_class);
+	unregister_chrdev_region(i3c_mctp_devt, I3C_MCTP_MINORS);
+	kmem_cache_destroy(packet_cache);
+}
+
+static int i3c_mctp_enable_ibi(struct i3c_device *i3cdev)
+{
+	struct i3c_ibi_setup ibireq = {
+		.handler = i3c_mctp_ibi_handler,
+		.max_payload_len = 2,
+		.num_slots = 10,
+	};
+	int ret;
+
+	ret = i3c_device_request_ibi(i3cdev, &ibireq);
+	if (ret)
+		return ret;
+	ret = i3c_device_enable_ibi(i3cdev);
+	if (ret)
+		i3c_device_free_ibi(i3cdev);
+
+	return ret;
+}
+
+/**
+ * i3c_mctp_get_eid() - receive MCTP EID assigned to the device
+ *
+ * @client: client for the device to get the EID for
+ * @domain_id: requested domain ID
+ * @eid: pointer to store EID value
+ *
+ * Receive MCTP endpoint ID dynamically assigned by the MCTP Bus Owner
+ * Return: 0 in case of success, a negative error code otherwise.
+ */
+int i3c_mctp_get_eid(struct i3c_mctp_client *client, u8 domain_id, u8 *eid)
+{
+	/* TODO: Implement EID assignment basing on domain ID */
+	*eid = 1;
+	return 0;
+}
+EXPORT_SYMBOL_GPL(i3c_mctp_get_eid);
+
+/**
+ * i3c_mctp_send_packet() - send mctp packet
+ *
+ * @tx_packet: the allocated packet that needs to be send via I3C
+ * @i3c: i3c device to send the packet to
+ *
+ * Return: 0 in case of success, a negative error code otherwise.
+ */
+int i3c_mctp_send_packet(struct i3c_device *i3c, struct i3c_mctp_packet *tx_packet)
+{
+	struct i3c_priv_xfer xfers = {
+		.rnw = false,
+		.len = tx_packet->size,
+		.data.out = &tx_packet->data,
+	};
+
+	return i3c_device_do_priv_xfers(i3c, &xfers, 1);
+}
+EXPORT_SYMBOL_GPL(i3c_mctp_send_packet);
+
+/**
+ * i3c_mctp_receive_packet() - receive mctp packet
+ *
+ * @client: i3c_mctp_client to receive the packet from
+ * @timeout: timeout, in jiffies
+ *
+ * The function will sleep for up to @timeout if no packet is ready to read.
+ *
+ * Returns struct i3c_mctp_packet from or ERR_PTR in case of error or the
+ * timeout elapsed.
+ */
+struct i3c_mctp_packet *i3c_mctp_receive_packet(struct i3c_mctp_client *client,
+						unsigned long timeout)
+{
+	struct i3c_mctp_packet *rx_packet;
+	int ret;
+
+	ret = wait_event_interruptible_timeout(client->wait_queue,
+					       __ptr_ring_peek(&client->rx_queue), timeout);
+	if (ret < 0)
+		return ERR_PTR(ret);
+	else if (ret == 0)
+		return ERR_PTR(-ETIME);
+
+	rx_packet = ptr_ring_consume(&client->rx_queue);
+	if (!rx_packet)
+		return ERR_PTR(-EAGAIN);
+
+	return rx_packet;
+}
+EXPORT_SYMBOL_GPL(i3c_mctp_receive_packet);
+
+static int i3c_mctp_probe(struct i3c_device *i3cdev)
+{
+	int ibi_payload_size = I3C_MCTP_IBI_PAYLOAD_SIZE;
+	struct device *dev = i3cdev_to_dev(i3cdev);
+	struct i3c_device_info info;
+	struct i3c_mctp *priv;
+	int ret;
+
+	priv = i3c_mctp_alloc(i3cdev);
+	if (IS_ERR(priv))
+		return PTR_ERR(priv);
+
+	cdev_init(&priv->cdev, &i3c_mctp_fops);
+
+	priv->cdev.owner = THIS_MODULE;
+	ret = cdev_add(&priv->cdev, MKDEV(MAJOR(i3c_mctp_devt), priv->id), 1);
+	if (ret)
+		goto error_cdev;
+
+	/* register this i3c device with the driver core */
+	priv->dev = device_create(i3c_mctp_class, dev,
+				  MKDEV(MAJOR(i3c_mctp_devt), priv->id),
+				  NULL, "i3c-mctp-%d", priv->id);
+	if (IS_ERR(priv->dev)) {
+		ret = PTR_ERR(priv->dev);
+		goto error;
+	}
+
+	ret = i3c_device_control_pec(i3cdev, false);
+	if (ret)
+		goto error;
+
+	priv->default_client = i3c_mctp_client_alloc(priv);
+	if (IS_ERR(priv->default_client))
+		goto error;
+
+	dev_set_drvdata(i3cdev_to_dev(i3cdev), priv);
+
+	priv->i3c_peci = platform_device_register_data(i3cdev_to_dev(i3cdev), "peci-i3c", priv->id,
+						       NULL, 0);
+	if (IS_ERR(priv->i3c_peci))
+		dev_warn(priv->dev, "failed to register peci-i3c device\n");
+
+	if (i3c_mctp_enable_ibi(i3cdev)) {
+		INIT_DELAYED_WORK(&priv->polling_work, i3c_mctp_polling_work);
+		schedule_delayed_work(&priv->polling_work, msecs_to_jiffies(POLLING_TIMEOUT_MS));
+		ibi_payload_size = 0;
+	}
+
+	i3c_device_get_info(i3cdev, &info);
+
+	ret = i3c_device_getmrl_ccc(i3cdev, &info);
+	if (ret || info.max_read_len != I3C_MCTP_MIN_TRANSFER_SIZE)
+		ret = i3c_device_setmrl_ccc(i3cdev, &info, I3C_MCTP_MIN_TRANSFER_SIZE,
+					    ibi_payload_size);
+	if (ret && info.max_read_len != I3C_MCTP_MIN_TRANSFER_SIZE) {
+		dev_err(dev, "Failed to set MRL!, ret = %d\n", ret);
+		goto error_peci;
+	}
+	priv->max_read_len = info.max_read_len;
+
+	ret = i3c_device_getmwl_ccc(i3cdev, &info);
+	if (ret || info.max_write_len != I3C_MCTP_MIN_TRANSFER_SIZE)
+		ret = i3c_device_setmwl_ccc(i3cdev, &info, I3C_MCTP_MIN_TRANSFER_SIZE);
+	if (ret && info.max_write_len != I3C_MCTP_MIN_TRANSFER_SIZE) {
+		dev_err(dev, "Failed to set MWL!, ret = %d\n", ret);
+		goto error_peci;
+	}
+	priv->max_write_len = info.max_write_len;
+
+	return 0;
+
+error_peci:
+	platform_device_unregister(priv->i3c_peci);
+	i3c_device_disable_ibi(i3cdev);
+	i3c_device_free_ibi(i3cdev);
+error:
+	cdev_del(&priv->cdev);
+error_cdev:
+	put_device(dev);
+	return ret;
+}
+
+static void i3c_mctp_remove(struct i3c_device *i3cdev)
+{
+	struct i3c_mctp *priv = dev_get_drvdata(i3cdev_to_dev(i3cdev));
+
+	i3c_device_disable_ibi(i3cdev);
+	i3c_device_free_ibi(i3cdev);
+	i3c_mctp_client_free(priv->default_client);
+	priv->default_client = NULL;
+	platform_device_unregister(priv->i3c_peci);
+
+	device_destroy(i3c_mctp_class, MKDEV(MAJOR(i3c_mctp_devt), priv->id));
+	cdev_del(&priv->cdev);
+	ida_free(&i3c_mctp_ida, priv->id);
+}
+
+static const struct i3c_device_id i3c_mctp_ids[] = {
+	I3C_CLASS(0xCC, 0x0),
+	I3C_DEVICE(0x3f6, 0x0503, (void *)0),
+	I3C_DEVICE(0x3f6, 0x8000, (void *)0),
+	I3C_DEVICE(0x3f6, 0x8001, (void *)0),
+	I3C_DEVICE(0x3f6, 0xA001, (void *)0),
+	I3C_DEVICE(0x3f6, 0xA003, (void *)0),
+	{ },
+};
+
+static struct i3c_driver i3c_mctp_drv = {
+	.driver.name = "i3c-mctp",
+	.id_table = i3c_mctp_ids,
+	.probe = i3c_mctp_probe,
+	.remove = i3c_mctp_remove,
+};
+
+module_driver(i3c_mctp_drv, i3c_mctp_init, i3c_mctp_free);
+MODULE_AUTHOR("Oleksandr Shulzhenko <oleksandr.shulzhenko.viktorovych@intel.com>");
+MODULE_DESCRIPTION("I3C MCTP driver");
+MODULE_LICENSE("GPL");
diff --git a/drivers/i3c/mctp/i3c-target-mctp.c b/drivers/i3c/mctp/i3c-target-mctp.c
new file mode 100644
index 000000000000..d8c767f967fe
--- /dev/null
+++ b/drivers/i3c/mctp/i3c-target-mctp.c
@@ -0,0 +1,389 @@
+// SPDX-License-Identifier: GPL-2.0
+/* Copyright (C) 2022 Intel Corporation.*/
+
+#include <linux/cdev.h>
+#include <linux/idr.h>
+#include <linux/module.h>
+#include <linux/poll.h>
+#include <linux/ptr_ring.h>
+#include <linux/workqueue.h>
+
+#include <linux/i3c/device.h>
+
+#define I3C_TARGET_MCTP_MINORS	32
+#define RX_RING_COUNT		16
+
+static struct class *i3c_target_mctp_class;
+static dev_t i3c_target_mctp_devt;
+static DEFINE_IDA(i3c_target_mctp_ida);
+
+struct mctp_client;
+
+struct i3c_target_mctp {
+	struct i3c_device *i3cdev;
+	struct cdev cdev;
+	int id;
+	struct mctp_client *client;
+	spinlock_t client_lock; /* to protect client access */
+};
+
+struct mctp_client {
+	struct kref ref;
+	struct i3c_target_mctp *priv;
+	struct ptr_ring rx_queue;
+	wait_queue_head_t wait_queue;
+};
+
+struct mctp_packet {
+	u8 *data;
+	u16 count;
+};
+
+static void *i3c_target_mctp_packet_alloc(u16 count)
+{
+	struct mctp_packet *packet;
+	u8 *data;
+
+	packet = kzalloc(sizeof(*packet), GFP_ATOMIC);
+	if (!packet)
+		return NULL;
+
+	data = kzalloc(count, GFP_ATOMIC);
+	if (!data) {
+		kfree(packet);
+		return NULL;
+	}
+
+	packet->data = data;
+	packet->count = count;
+
+	return packet;
+}
+
+static void i3c_target_mctp_packet_free(void *data)
+{
+	struct mctp_packet *packet = data;
+
+	kfree(packet->data);
+	kfree(packet);
+}
+
+static struct mctp_client *i3c_target_mctp_client_alloc(struct i3c_target_mctp *priv)
+{
+	struct mctp_client *client;
+
+	client = kzalloc(sizeof(*client), GFP_KERNEL);
+	if (!client)
+		goto out;
+
+	kref_init(&client->ref);
+	client->priv = priv;
+	ptr_ring_init(&client->rx_queue, RX_RING_COUNT, GFP_KERNEL);
+out:
+	return client;
+}
+
+static void i3c_target_mctp_client_free(struct kref *ref)
+{
+	struct mctp_client *client = container_of(ref, typeof(*client), ref);
+
+	ptr_ring_cleanup(&client->rx_queue, &i3c_target_mctp_packet_free);
+
+	kfree(client);
+}
+
+static void i3c_target_mctp_client_get(struct mctp_client *client)
+{
+	kref_get(&client->ref);
+}
+
+static void i3c_target_mctp_client_put(struct mctp_client *client)
+{
+	kref_put(&client->ref, &i3c_target_mctp_client_free);
+}
+
+static void
+i3c_target_mctp_rx_packet_enqueue(struct i3c_device *i3cdev, const u8 *data, size_t count)
+{
+	struct i3c_target_mctp *priv = dev_get_drvdata(i3cdev_to_dev(i3cdev));
+	struct mctp_client *client;
+	struct mctp_packet *packet;
+	int ret;
+
+	spin_lock(&priv->client_lock);
+	client = priv->client;
+	if (client)
+		i3c_target_mctp_client_get(client);
+	spin_unlock(&priv->client_lock);
+
+	if (!client)
+		return;
+
+	packet = i3c_target_mctp_packet_alloc(count);
+	if (!packet)
+		goto err;
+
+	memcpy(packet->data, data, count);
+
+	ret = ptr_ring_produce(&client->rx_queue, packet);
+	if (ret)
+		i3c_target_mctp_packet_free(packet);
+	else
+		wake_up_all(&client->wait_queue);
+err:
+	i3c_target_mctp_client_put(client);
+}
+
+static struct mctp_client *i3c_target_mctp_create_client(struct i3c_target_mctp *priv)
+{
+	struct mctp_client *client;
+	int ret;
+
+	/* Currently, we support just one client. */
+	spin_lock_irq(&priv->client_lock);
+	ret = priv->client ? -EBUSY : 0;
+	spin_unlock_irq(&priv->client_lock);
+
+	if (ret)
+		return ERR_PTR(ret);
+
+	client = i3c_target_mctp_client_alloc(priv);
+	if (!client)
+		return ERR_PTR(-ENOMEM);
+
+	init_waitqueue_head(&client->wait_queue);
+
+	spin_lock_irq(&priv->client_lock);
+	priv->client = client;
+	spin_unlock_irq(&priv->client_lock);
+
+	return client;
+}
+
+static void i3c_target_mctp_delete_client(struct mctp_client *client)
+{
+	struct i3c_target_mctp *priv = client->priv;
+
+	spin_lock_irq(&priv->client_lock);
+	priv->client = NULL;
+	spin_unlock_irq(&priv->client_lock);
+
+	i3c_target_mctp_client_put(client);
+}
+
+static int i3c_target_mctp_open(struct inode *inode, struct file *file)
+{
+	struct i3c_target_mctp *priv = container_of(inode->i_cdev, struct i3c_target_mctp, cdev);
+	struct mctp_client *client;
+
+	client = i3c_target_mctp_create_client(priv);
+	if (IS_ERR(client))
+		return PTR_ERR(client);
+
+	file->private_data = client;
+
+	return 0;
+}
+
+static int i3c_target_mctp_release(struct inode *inode, struct file *file)
+{
+	struct mctp_client *client = file->private_data;
+
+	i3c_target_mctp_delete_client(client);
+
+	return 0;
+}
+
+static ssize_t i3c_target_mctp_read(struct file *file, char __user *buf,
+				    size_t count, loff_t *ppos)
+{
+	struct mctp_client *client = file->private_data;
+	struct mctp_packet *rx_packet;
+
+	rx_packet = ptr_ring_consume_irq(&client->rx_queue);
+	if (!rx_packet)
+		return -EAGAIN;
+
+	if (count < rx_packet->count) {
+		count = -EINVAL;
+		goto err_free;
+	}
+	if (count > rx_packet->count)
+		count = rx_packet->count;
+
+	if (copy_to_user(buf, rx_packet->data, count))
+		count = -EFAULT;
+err_free:
+	i3c_target_mctp_packet_free(rx_packet);
+
+	return count;
+}
+
+static ssize_t i3c_target_mctp_write(struct file *file, const char __user *buf,
+				     size_t count, loff_t *ppos)
+{
+	struct mctp_client *client = file->private_data;
+	struct i3c_target_mctp *priv = client->priv;
+	struct i3c_priv_xfer xfers[1] = {};
+	u8 *tx_data;
+	int ret;
+
+	tx_data = kzalloc(count, GFP_KERNEL);
+	if (!tx_data)
+		return -ENOMEM;
+
+	if (copy_from_user(tx_data, buf, count)) {
+		ret = -EFAULT;
+		goto out_packet;
+	}
+
+	xfers[0].data.out = tx_data;
+	xfers[0].len = count;
+
+	ret = i3c_device_do_priv_xfers(priv->i3cdev, xfers, ARRAY_SIZE(xfers));
+	if (ret)
+		goto out_packet;
+	ret = count;
+
+	/*
+	 * TODO: Add support for IBI generation - it should be done only if IBI
+	 * are enabled (the Active Controller may disabled them using CCC for
+	 * that). Otherwise (if IBIs are disabled), we should make sure that when
+	 * Active Controller issues GETSTATUS CCC the return value indicates
+	 * that data is ready.
+	 */
+out_packet:
+	kfree(tx_data);
+	return ret;
+}
+
+static __poll_t i3c_target_mctp_poll(struct file *file, struct poll_table_struct *pt)
+{
+	struct mctp_client *client = file->private_data;
+	__poll_t ret = 0;
+
+	poll_wait(file, &client->wait_queue, pt);
+
+	if (__ptr_ring_peek(&client->rx_queue))
+		ret |= EPOLLIN;
+
+	/*
+	 * TODO: Add support for "write" readiness.
+	 * DW-I3C has a hardware queue that has finite number of entries.
+	 * If we try to issue more writes that space in this queue allows for,
+	 * we're in trouble. This should be handled by error from write() and
+	 * poll() blocking for write events.
+	 */
+	return ret;
+}
+
+static const struct file_operations i3c_target_mctp_fops = {
+	.owner = THIS_MODULE,
+	.open = i3c_target_mctp_open,
+	.release = i3c_target_mctp_release,
+	.read = i3c_target_mctp_read,
+	.write = i3c_target_mctp_write,
+	.poll = i3c_target_mctp_poll,
+};
+
+static struct i3c_target_read_setup i3c_target_mctp_rx_packet_setup = {
+	.handler = i3c_target_mctp_rx_packet_enqueue,
+};
+
+static int i3c_target_mctp_probe(struct i3c_device *i3cdev)
+{
+	struct device *parent = i3cdev_to_dev(i3cdev);
+	struct i3c_target_mctp *priv;
+	struct device *dev;
+	int ret;
+
+	priv = devm_kzalloc(parent, sizeof(*priv), GFP_KERNEL);
+	if (!priv)
+		return -ENOMEM;
+
+	ret = ida_alloc(&i3c_target_mctp_ida, GFP_KERNEL);
+	if (ret < 0)
+		return ret;
+	priv->id = ret;
+
+	priv->i3cdev = i3cdev;
+	spin_lock_init(&priv->client_lock);
+
+	cdev_init(&priv->cdev, &i3c_target_mctp_fops);
+	priv->cdev.owner = THIS_MODULE;
+	ret = cdev_add(&priv->cdev, i3c_target_mctp_devt, 1);
+	if (ret) {
+		ida_free(&i3c_target_mctp_ida, priv->id);
+		return ret;
+	}
+
+	dev = device_create(i3c_target_mctp_class, parent, i3c_target_mctp_devt,
+			    NULL, "i3c-mctp-target-%d", priv->id);
+	if (IS_ERR(dev)) {
+		ret = PTR_ERR(dev);
+		goto err;
+	}
+
+	i3cdev_set_drvdata(i3cdev, priv);
+
+	i3c_target_read_register(i3cdev, &i3c_target_mctp_rx_packet_setup);
+
+	return 0;
+err:
+	cdev_del(&priv->cdev);
+	ida_free(&i3c_target_mctp_ida, priv->id);
+
+	return ret;
+}
+
+static void i3c_target_mctp_remove(struct i3c_device *i3cdev)
+{
+	struct i3c_target_mctp *priv = dev_get_drvdata(i3cdev_to_dev(i3cdev));
+
+	device_destroy(i3c_target_mctp_class, i3c_target_mctp_devt);
+	cdev_del(&priv->cdev);
+	ida_free(&i3c_target_mctp_ida, priv->id);
+}
+
+static const struct i3c_device_id i3c_target_mctp_ids[] = {
+	I3C_CLASS(0xcc, 0x0),
+	{ },
+};
+
+static struct i3c_driver i3c_target_mctp_drv = {
+	.driver.name = "i3c-target-mctp",
+	.id_table = i3c_target_mctp_ids,
+	.probe = i3c_target_mctp_probe,
+	.remove = i3c_target_mctp_remove,
+	.target = true,
+};
+
+static int i3c_target_mctp_init(struct i3c_driver *drv)
+{
+	int ret;
+
+	ret = alloc_chrdev_region(&i3c_target_mctp_devt, 0,
+				  I3C_TARGET_MCTP_MINORS, "i3c-target-mctp");
+	if (ret)
+		return ret;
+
+	i3c_target_mctp_class = class_create(THIS_MODULE, "i3c-target-mctp");
+	if (IS_ERR(i3c_target_mctp_class)) {
+		unregister_chrdev_region(i3c_target_mctp_devt, I3C_TARGET_MCTP_MINORS);
+		return PTR_ERR(i3c_target_mctp_class);
+	}
+
+	return i3c_driver_register(drv);
+}
+
+static void i3c_target_mctp_fini(struct i3c_driver *drv)
+{
+	i3c_driver_unregister(drv);
+	class_destroy(i3c_target_mctp_class);
+	unregister_chrdev_region(i3c_target_mctp_devt, I3C_TARGET_MCTP_MINORS);
+}
+
+module_driver(i3c_target_mctp_drv, i3c_target_mctp_init, i3c_target_mctp_fini);
+MODULE_AUTHOR("Iwona Winiarska <iwona.winiarska@intel.com>");
+MODULE_DESCRIPTION("I3C Target MCTP driver");
+MODULE_LICENSE("GPL");
diff --git a/drivers/misc/amd-apml/apml_sbtsi.c b/drivers/misc/amd-apml/apml_sbtsi.c
index 3b5a7e5aea68..36b736201a77 100644
--- a/drivers/misc/amd-apml/apml_sbtsi.c
+++ b/drivers/misc/amd-apml/apml_sbtsi.c
@@ -367,7 +367,7 @@ static int sbtsi_i2c_probe(struct i2c_client *client,
 	return create_misc_tsi_device(tsi_dev, dev, id);
 }

-static int sbtsi_i3c_remove(struct i3c_device *i3cdev)
+static void sbtsi_i3c_remove(struct i3c_device *i3cdev)
 {
 	struct apml_sbtsi_device *tsi_dev = dev_get_drvdata(&i3cdev->dev);

@@ -375,7 +375,7 @@ static int sbtsi_i3c_remove(struct i3c_device *i3cdev)
 		misc_deregister(&tsi_dev->sbtsi_misc_dev);

 	dev_info(&i3cdev->dev, "Removed sbtsi-i3c driver\n");
-	return 0;
+    return;
 }

 static int sbtsi_i2c_remove(struct i2c_client *client)
diff --git a/drivers/misc/amd-apml/sbrmi.c b/drivers/misc/amd-apml/sbrmi.c
index e18a16309016..47d3087f014f 100644
--- a/drivers/misc/amd-apml/sbrmi.c
+++ b/drivers/misc/amd-apml/sbrmi.c
@@ -742,13 +742,13 @@ static int sbrmi_i2c_remove(struct i2c_client *client)
 	return 0;
 }

-static int sbrmi_i3c_remove(struct i3c_device *i3cdev)
+static void sbrmi_i3c_remove(struct i3c_device *i3cdev)
 {
 	struct device *dev = &i3cdev->dev;
 	struct apml_sbrmi_device *rmi_dev = dev_get_drvdata(&i3cdev->dev);

 	if (!rmi_dev)
-		return 0;
+		return;
 	/*
 	 * Set the no_new_trans so no new transaction can
 	 * occur in sbrmi_ioctl
@@ -772,7 +772,7 @@ static int sbrmi_i3c_remove(struct i3c_device *i3cdev)
 		devm_kfree(dev, dimm_id);

 	dev_info(&i3cdev->dev, "Removed sbrmi_i3c driver\n");
-	return 0;
+	return;
 }

 static const struct i2c_device_id sbrmi_id[] = {
diff --git a/include/linux/i3c/ccc.h b/include/linux/i3c/ccc.h
index a7a19ebe6b6d..dd2f18f5e10f 100644
--- a/include/linux/i3c/ccc.h
+++ b/include/linux/i3c/ccc.h
@@ -255,6 +255,33 @@ struct i3c_ccc_setbrgtgt {
 struct i3c_ccc_sethid {
 	u8 hid;
 };
+
+union devctrl_ctrl {
+	u8 value;
+	struct {
+		u8 reg_mod : 1;
+		u8 pec_bl : 2;
+		u8 st_offset : 2;
+		u8 addr_mask : 3;
+	} fields;
+};
+
+/**
+ * struct i3c_ccc_devctrl - payload passed to DEVCTRL CCC
+ *
+ * @ctrl: using to control the format of the following data
+ * @dev_addr: device address
+ * @datax: 0~3 data
+ */
+struct i3c_ccc_devctrl {
+	union devctrl_ctrl ctrl;
+	u8 dev_addr;
+	u8 data0;
+	u8 data1;
+	u8 data2;
+	u8 data3;
+} __packed;
+
 /**
  * enum i3c_sdr_max_data_rate - max data rate values for private SDR transfers
  */
@@ -381,6 +408,8 @@ struct i3c_ccc_cmd_dest {
  * @rnw: true if the CCC should retrieve data from the device. Only valid for
  *	 unicast commands
  * @id: CCC command id
+ * @dbp: true if the defining byte present
+ * @db: the defining byte
  * @ndests: number of destinations. Should always be one for broadcast commands
  * @dests: array of destinations and associated payload for this CCC. Most of
  *	   the time, only one destination is provided
@@ -389,6 +418,8 @@ struct i3c_ccc_cmd_dest {
 struct i3c_ccc_cmd {
 	u8 rnw;
 	u8 id;
+	u8 dbp;
+	u8 db;
 	unsigned int ndests;
 	struct i3c_ccc_cmd_dest *dests;
 	enum i3c_error_code err;
diff --git a/include/linux/i3c/device.h b/include/linux/i3c/device.h
index ad18deff6574..06334606fa28 100644
--- a/include/linux/i3c/device.h
+++ b/include/linux/i3c/device.h
@@ -49,6 +49,27 @@ enum i3c_hdr_mode {
 	I3C_HDR_TSL,
 };

+/**
+ * struct i3c_hdr_cmd - I3C HDR command
+ * @mode: HDR mode selected for this command
+ * @code: command opcode
+ * @addr: I3C dynamic address
+ * @ndatawords: number of data words (a word is 16bits wide)
+ * @data: input/output buffer
+ * @err: I3C error code
+ */
+struct i3c_hdr_cmd {
+	enum i3c_hdr_mode mode;
+	u8 code;
+	u8 addr;
+	int ndatawords;
+	union {
+		void *in;
+		const void *out;
+	} data;
+	enum i3c_error_code err;
+};
+
 /**
  * struct i3c_priv_xfer - I3C SDR private transfer
  * @rnw: encodes the transfer direction. true for a read, false for a write
@@ -71,11 +92,26 @@ struct i3c_priv_xfer {
 /**
  * enum i3c_dcr - I3C DCR values
  * @I3C_DCR_GENERIC_DEVICE: generic I3C device
+ * @I3C_DCR_HUB: I3C HUB device
  */
 enum i3c_dcr {
 	I3C_DCR_GENERIC_DEVICE = 0,
+	I3C_DCR_HUB = 194,
+	I3C_DCR_JESD403_BEGIN = 208,
+	I3C_DCR_THERMAL_SENSOR_FIRST = 210,
+	I3C_DCR_THERMAL_SENSOR_SECOND = 214,
+	I3C_DCR_PMIC_SECOND = 216,
+	I3C_DCR_PMIC_FIRST = 217,
+	I3C_DCR_SPD_HUB = 218,
+	I3C_DCR_RCD = 219,
+	I3C_DCR_PMIC_THIRD = 220,
+	I3C_DCR_JESD403_END = 223,
+	I3C_DCR_MAX = 228,
 };

+#define I3C_DCR_IS_JESD403_COMPLIANT(dcr)                                      \
+	(dcr >= I3C_DCR_JESD403_BEGIN && dcr <= I3C_DCR_JESD403_END)
+
 #define I3C_PID_MANUF_ID(pid)		(((pid) & GENMASK_ULL(47, 33)) >> 33)
 #define I3C_PID_RND_LOWER_32BITS(pid)	(!!((pid) & BIT_ULL(32)))
 #define I3C_PID_RND_VAL(pid)		((pid) & GENMASK_ULL(31, 0))
@@ -93,6 +129,22 @@ enum i3c_dcr {
 #define I3C_BCR_IBI_REQ_CAP		BIT(1)
 #define I3C_BCR_MAX_DATA_SPEED_LIM	BIT(0)

+/*
+ * MIPI I3C MDB definition
+ * see https://www.mipi.org/MIPI_I3C_mandatory_data_byte_values_public
+ */
+#define IBI_MDB_ID(grp, id)                                                    \
+	((((grp) << 5) & GENMASK(7, 5)) | ((id)&GENMASK(4, 0)))
+#define IBI_MDB_GET_GRP(m) (((m)&GENMASK(7, 5)) >> 5)
+#define IBI_MDB_GET_ID(m) ((m)&GENMASK(4, 0))
+
+#define IBI_MDB_GRP_PENDING_READ_NOTIF 0x5
+#define IS_MDB_PENDING_READ_NOTIFY(m)                                          \
+	(IBI_MDB_GET_GRP(m) == IBI_MDB_GRP_PENDING_READ_NOTIF)
+#define IBI_MDB_MIPI_DBGDATAREADY                                              \
+	IBI_MDB_ID(IBI_MDB_GRP_PENDING_READ_NOTIF, 0xd)
+#define IBI_MDB_MCTP IBI_MDB_ID(IBI_MDB_GRP_PENDING_READ_NOTIF, 0xe)
+
 /**
  * struct i3c_device_info - I3C device information
  * @pid: Provisional ID
@@ -107,6 +159,8 @@ enum i3c_dcr {
  * @max_read_turnaround: max read turn-around time in micro-seconds
  * @max_read_len: max private SDR read length in bytes
  * @max_write_len: max private SDR write length in bytes
+ * @pec: flag telling whether PEC (Packet Error Check) generation and verification for read
+ *       and write transaction is enabled
  *
  * These are all basic information that should be advertised by an I3C device.
  * Some of them are optional depending on the device type and device
@@ -128,6 +182,8 @@ struct i3c_device_info {
 	u32 max_read_turnaround;
 	u16 max_read_len;
 	u16 max_write_len;
+	u8 pec;
+	__be16 status;
 };

 /*
@@ -176,8 +232,9 @@ struct i3c_device;
 struct i3c_driver {
 	struct device_driver driver;
 	int (*probe)(struct i3c_device *dev);
-	int (*remove)(struct i3c_device *dev);
+	void (*remove)(struct i3c_device *dev);
 	const struct i3c_device_id *id_table;
+	bool target;
 };

 static inline struct i3c_driver *drv_to_i3cdrv(struct device_driver *drv)
@@ -287,13 +344,19 @@ static inline void i3c_i2c_driver_unregister(struct i3c_driver *i3cdrv,
 #define module_i3c_i2c_driver(__i3cdrv, __i2cdrv)	\
 	module_driver(__i3cdrv,				\
 		      i3c_i2c_driver_register,		\
-		      i3c_i2c_driver_unregister,	\
-		      __i2cdrv)
+		      i3c_i2c_driver_unregister,    \
+              __i2cdrv)

 int i3c_device_do_priv_xfers(struct i3c_device *dev,
 			     struct i3c_priv_xfer *xfers,
 			     int nxfers);

+int i3c_device_send_hdr_cmds(struct i3c_device *dev,
+			     struct i3c_hdr_cmd *cmds,
+			     int ncmds);
+
+int i3c_device_generate_ibi(struct i3c_device *dev, const u8 *data, int len);
+
 void i3c_device_get_info(struct i3c_device *dev, struct i3c_device_info *info);

 struct i3c_ibi_payload {
@@ -332,5 +395,21 @@ int i3c_device_request_ibi(struct i3c_device *dev,
 void i3c_device_free_ibi(struct i3c_device *dev);
 int i3c_device_enable_ibi(struct i3c_device *dev);
 int i3c_device_disable_ibi(struct i3c_device *dev);
+int i3c_device_send_ccc_cmd(struct i3c_device *dev, u8 ccc_id);
+
+int i3c_device_getstatus_ccc(struct i3c_device *dev, struct i3c_device_info *info);
+int i3c_device_setmrl_ccc(struct i3c_device *dev, struct i3c_device_info *info, u16 read_len,
+			  u8 ibi_len);
+int i3c_device_setmwl_ccc(struct i3c_device *dev, struct i3c_device_info *info, u16 write_len);
+int i3c_device_getmrl_ccc(struct i3c_device *dev, struct i3c_device_info *info);
+int i3c_device_getmwl_ccc(struct i3c_device *dev, struct i3c_device_info *info);
+
+struct i3c_target_read_setup {
+	void (*handler)(struct i3c_device *dev, const u8 *data, size_t len);
+};
+
+int i3c_target_read_register(struct i3c_device *dev, const struct i3c_target_read_setup *setup);
+
+int i3c_device_control_pec(struct i3c_device *dev, bool pec);

 #endif /* I3C_DEV_H */
diff --git a/include/linux/i3c/master.h b/include/linux/i3c/master.h
index daf80ed69c3b..03fe3377d993 100644
--- a/include/linux/i3c/master.h
+++ b/include/linux/i3c/master.h
@@ -22,10 +22,13 @@
 #define I3C_BROADCAST_ADDR		0x7e
 #define I3C_MAX_ADDR			GENMASK(6, 0)

+struct i3c_target_ops;
 struct i3c_master_controller;
 struct i3c_bus;
 struct i2c_device;
 struct i3c_device;
+struct i3c_slave_setup;
+struct i3c_slave_payload;

 /**
  * struct i3c_i2c_dev_desc - Common part of the I3C/I2C device descriptor
@@ -85,7 +88,6 @@ struct i2c_dev_boardinfo {
  */
 struct i2c_dev_desc {
 	struct i3c_i2c_dev_desc common;
-	const struct i2c_dev_boardinfo *boardinfo;
 	struct i2c_client *dev;
 	u16 addr;
 	u8 lvr;
@@ -181,14 +183,26 @@ struct i3c_dev_boardinfo {
 	u8 init_dyn_addr;
 	u8 static_addr;
 	u64 pid;
+	u8 bcr;
+	u8 dcr;
 	struct device_node *of_node;
 };

+/**
+ * struct i3c_target_info - target information attached to a specific device
+ * @read handler: handler specified at i3c_target_read_register() call time.
+ */
+
+struct i3c_target_info {
+	void (*read_handler)(struct i3c_device *dev, const u8 *data, size_t len);
+};
+
 /**
  * struct i3c_dev_desc - I3C device descriptor
  * @common: common part of the I3C device descriptor
  * @info: I3C device information. Will be automatically filled when you create
  *	  your device with i3c_master_add_i3c_dev_locked()
+ * @target_info: I3C target information.
  * @ibi_lock: lock used to protect the &struct_i3c_device->ibi
  * @ibi: IBI info attached to a device. Should be NULL until
  *	 i3c_device_request_ibi() is called
@@ -207,6 +221,7 @@ struct i3c_dev_boardinfo {
 struct i3c_dev_desc {
 	struct i3c_i2c_dev_desc common;
 	struct i3c_device_info info;
+	struct i3c_target_info target_info;
 	struct mutex ibi_lock;
 	struct i3c_device_ibi_info *ibi;
 	struct i3c_device *dev;
@@ -384,6 +399,9 @@ struct i3c_bus {
  *		      all CCC commands are supported.
  * @send_ccc_cmd: send a CCC command
  *		  This method is mandatory.
+ * @send_hdr_cmds: send one or several HDR commands. If there is more than one
+ *		   command, they should ideally be sent in the same HDR
+ *		   transaction
  * @priv_xfers: do one or several private I3C SDR transfers
  *		This method is mandatory.
  * @attach_i2c_dev: called every time an I2C device is attached to the bus.
@@ -430,6 +448,7 @@ struct i3c_bus {
 struct i3c_master_controller_ops {
 	int (*bus_init)(struct i3c_master_controller *master);
 	void (*bus_cleanup)(struct i3c_master_controller *master);
+	void (*bus_reset)(struct i3c_master_controller *master);
 	int (*attach_i3c_dev)(struct i3c_dev_desc *dev);
 	int (*reattach_i3c_dev)(struct i3c_dev_desc *dev, u8 old_dyn_addr);
 	void (*detach_i3c_dev)(struct i3c_dev_desc *dev);
@@ -438,6 +457,9 @@ struct i3c_master_controller_ops {
 				 const struct i3c_ccc_cmd *cmd);
 	int (*send_ccc_cmd)(struct i3c_master_controller *master,
 			    struct i3c_ccc_cmd *cmd);
+	int (*send_hdr_cmds)(struct i3c_master_controller *master,
+			     struct i3c_hdr_cmd *cmds,
+			     int ncmds);
 	int (*priv_xfers)(struct i3c_dev_desc *dev,
 			  struct i3c_priv_xfer *xfers,
 			  int nxfers);
@@ -452,6 +474,14 @@ struct i3c_master_controller_ops {
 	int (*disable_ibi)(struct i3c_dev_desc *dev);
 	void (*recycle_ibi_slot)(struct i3c_dev_desc *dev,
 				 struct i3c_ibi_slot *slot);
+	int (*register_slave)(struct i3c_master_controller *master,
+			      const struct i3c_slave_setup *req);
+	int (*unregister_slave)(struct i3c_master_controller *master);
+	int (*send_sir)(struct i3c_master_controller *master,
+			struct i3c_slave_payload *payload);
+	int (*put_read_data)(struct i3c_master_controller *master,
+			     struct i3c_slave_payload *data,
+			     struct i3c_slave_payload *ibi_notify);
 };

 /**
@@ -463,6 +493,8 @@ struct i3c_master_controller_ops {
  *	 registered to the I2C subsystem to be as transparent as possible to
  *	 existing I2C drivers
  * @ops: master operations. See &struct i3c_master_controller_ops
+ * @target_ops: target operations. See &struct i3c_target_ops
+ * @target: true if the underlying I3C device acts as a target on I3C bus
  * @secondary: true if the master is a secondary master
  * @init_done: true when the bus initialization is done
  * @boardinfo.i3c: list of I3C  boardinfo objects
@@ -485,10 +517,12 @@ struct i3c_master_controller {
 	struct i3c_dev_desc *this;
 	struct i2c_adapter i2c;
 	const struct i3c_master_controller_ops *ops;
+	const struct i3c_target_ops *target_ops;
+	unsigned int pec_supported : 1;
+	unsigned int target : 1;
 	unsigned int secondary : 1;
 	unsigned int init_done : 1;
 	unsigned int jdec_spd : 1;
-	unsigned int set_dasa : 1;
 	struct {
 		struct list_head i3c;
 		struct list_head i2c;
@@ -527,15 +561,20 @@ int i3c_master_disec_locked(struct i3c_master_controller *master, u8 addr,
 			    u8 evts);
 int i3c_master_enec_locked(struct i3c_master_controller *master, u8 addr,
 			   u8 evts);
+int i3c_master_setmrl_locked(struct i3c_master_controller *master,
+			     struct i3c_device_info *info, u16 read_len,
+			     u8 ibi_len);
 int i3c_master_entdaa_locked(struct i3c_master_controller *master);
 int i3c_master_defslvs_locked(struct i3c_master_controller *master);
-
+int i3c_master_rstdaa_locked(struct i3c_master_controller *master,
+				    u8 addr);
 int i3c_master_get_free_addr(struct i3c_master_controller *master,
 			     u8 start_addr);

 int i3c_master_add_i3c_dev_locked(struct i3c_master_controller *master,
 				  u8 addr);
 int i3c_master_do_daa(struct i3c_master_controller *master);
+int i3c_master_enable_hj(struct i3c_master_controller *master);

 int i3c_master_set_info(struct i3c_master_controller *master,
 			const struct i3c_device_info *info);
@@ -546,6 +585,13 @@ int i3c_master_register(struct i3c_master_controller *master,
 			bool secondary);
 int i3c_master_unregister(struct i3c_master_controller *master);

+int i3c_register(struct i3c_master_controller *master,
+		 struct device *parent,
+		 const struct i3c_master_controller_ops *master_ops,
+		 const struct i3c_target_ops *target_ops,
+		 bool secondary);
+int i3c_unregister(struct i3c_master_controller *master);
+
 /**
  * i3c_dev_get_master_data() - get master private data attached to an I3C
  *			       device descriptor
@@ -638,6 +684,18 @@ i3c_master_get_bus(struct i3c_master_controller *master)
 	return &master->bus;
 }

+struct i3c_slave_payload {
+	unsigned int len;
+	const void *data;
+};
+
+struct i3c_slave_setup {
+	unsigned int max_payload_len;
+	unsigned int num_slots;
+	void (*handler)(struct i3c_master_controller *m,
+			const struct i3c_slave_payload *payload);
+};
+
 struct i3c_generic_ibi_pool;

 struct i3c_generic_ibi_pool *
@@ -654,4 +712,32 @@ void i3c_master_queue_ibi(struct i3c_dev_desc *dev, struct i3c_ibi_slot *slot);

 struct i3c_ibi_slot *i3c_master_get_free_ibi_slot(struct i3c_dev_desc *dev);

+int i3c_master_register_slave(struct i3c_master_controller *master,
+			      const struct i3c_slave_setup *req);
+int i3c_master_unregister_slave(struct i3c_master_controller *master);
+int i3c_master_send_sir(struct i3c_master_controller *master,
+			struct i3c_slave_payload *payload);
+int i3c_master_send_hdr_cmds(struct i3c_master_controller *master,
+			     struct i3c_hdr_cmd *cmds, int ncmds);
+/**
+ * i3c_master_put_read_data() - put read data and optionally notify primary master
+ * @master: master object in slave mode
+ * @data: data structure to be read
+ * @ibi_notify: IBI data (including MDB) to notify primary master device
+ */
+int i3c_master_put_read_data(struct i3c_master_controller *master,
+			     struct i3c_slave_payload *data,
+			     struct i3c_slave_payload *ibi_notify);
+/*
+ * Slave message queue driver API
+ */
+#ifdef CONFIG_I3C_SLAVE_MQUEUE
+int i3c_slave_mqueue_probe(struct i3c_master_controller *master);
+int i3c_slave_mqueue_remove(struct i3c_master_controller *master);
+#endif
+
+#ifdef CONFIG_I3C_SLAVE_EEPROM
+int i3c_slave_eeprom_probe(struct i3c_master_controller *master);
+int i3c_slave_eeprom_remove(struct i3c_master_controller *master);
+#endif
 #endif /* I3C_MASTER_H */
diff --git a/include/linux/i3c/mctp/i3c-mctp.h b/include/linux/i3c/mctp/i3c-mctp.h
new file mode 100644
index 000000000000..dd20750d79d8
--- /dev/null
+++ b/include/linux/i3c/mctp/i3c-mctp.h
@@ -0,0 +1,50 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/* Copyright (C) 2022 Intel Corporation.*/
+
+#ifndef I3C_MCTP_H
+#define I3C_MCTP_H
+
+#define I3C_MCTP_PACKET_SIZE	68
+#define I3C_MCTP_PAYLOAD_SIZE	64
+#define I3C_MCTP_HDR_SIZE	4
+
+/* PECI MCTP Intel VDM definitions */
+#define MCTP_MSG_TYPE_VDM_PCI		0x7E
+#define MCTP_VDM_PCI_INTEL_VENDOR_ID	0x8086
+#define MCTP_VDM_PCI_INTEL_PECI		0x2
+
+/* MCTP message header offsets */
+#define MCTP_MSG_HDR_MSG_TYPE_OFFSET	0
+#define MCTP_MSG_HDR_VENDOR_OFFSET	1
+#define MCTP_MSG_HDR_OPCODE_OFFSET	4
+
+struct i3c_mctp_client;
+
+struct mctp_protocol_hdr {
+	u8 ver;
+	u8 dest;
+	u8 src;
+	u8 flags_seq_tag;
+} __packed;
+
+struct i3c_mctp_packet_data {
+	u8 protocol_hdr[I3C_MCTP_HDR_SIZE];
+	u8 payload[I3C_MCTP_PAYLOAD_SIZE];
+};
+
+struct i3c_mctp_packet {
+	struct i3c_mctp_packet_data data;
+	u32 size;
+};
+
+void *i3c_mctp_packet_alloc(gfp_t flags);
+void i3c_mctp_packet_free(void *packet);
+
+int i3c_mctp_get_eid(struct i3c_mctp_client *client, u8 domain_id, u8 *eid);
+int i3c_mctp_send_packet(struct i3c_device *i3c, struct i3c_mctp_packet *tx_packet);
+struct i3c_mctp_packet *i3c_mctp_receive_packet(struct i3c_mctp_client *client,
+						unsigned long timeout);
+struct i3c_mctp_client *i3c_mctp_add_peci_client(struct i3c_device *i3c);
+void i3c_mctp_remove_peci_client(struct i3c_mctp_client *client);
+
+#endif /* I3C_MCTP_H */
diff --git a/include/linux/i3c/target.h b/include/linux/i3c/target.h
new file mode 100644
index 000000000000..9e71124b5325
--- /dev/null
+++ b/include/linux/i3c/target.h
@@ -0,0 +1,23 @@
+/* SPDX-License-Identifier: GPL-2.0 */
+/* Copyright (c) 2022, Intel Corporation */
+
+#ifndef I3C_TARGET_H
+#define I3C_TARGET_H
+
+#include <linux/device.h>
+#include <linux/i3c/device.h>
+
+struct i3c_master_controller;
+
+struct i3c_target_ops {
+	int (*bus_init)(struct i3c_master_controller *master);
+	void (*bus_cleanup)(struct i3c_master_controller *master);
+	int (*priv_xfers)(struct i3c_dev_desc *dev, struct i3c_priv_xfer *xfers, int nxfers);
+	int (*generate_ibi)(struct i3c_dev_desc *dev, const u8 *data, int len);
+};
+
+int i3c_target_register(struct i3c_master_controller *master, struct device *parent,
+			const struct i3c_target_ops *ops);
+int i3c_target_unregister(struct i3c_master_controller *master);
+
+#endif
--
2.25.1

